{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    model_idx    method  cutoff_low  cuttoff_high  labeled_0  labeled_1  \\\n0           0  mean_all           7             8       53.0       48.0   \n1           0  mean_all           7             8       53.0       48.0   \n2           1  mean_all           7             8       53.0       48.0   \n3           1  mean_all           7             8       53.0       48.0   \n4           2  mean_all           7             8       53.0       48.0   \n5           2  mean_all           7             8       53.0       48.0   \n6           3  mean_all           7             8       53.0       48.0   \n7           3  mean_all           7             8       53.0       48.0   \n8           4  mean_all           7             8       53.0       48.0   \n9           4  mean_all           7             8       53.0       48.0   \n10          5  mean_all           7             8       53.0       48.0   \n11          5  mean_all           7             8       53.0       48.0   \n12          6  mean_all           7             8       53.0       48.0   \n13          6  mean_all           7             8       53.0       48.0   \n14          7  mean_all           7             8       53.0       48.0   \n15          7  mean_all           7             8       53.0       48.0   \n16          0  mean_all           7             8       53.0       48.0   \n17          0  mean_all           7             8       53.0       48.0   \n18          1  mean_all           7             8       53.0       48.0   \n19          1  mean_all           7             8       53.0       48.0   \n20          2  mean_all           7             8       53.0       48.0   \n21          2  mean_all           7             8       53.0       48.0   \n22          3  mean_all           7             8       53.0       48.0   \n23          3  mean_all           7             8       53.0       48.0   \n24          4  mean_all           7             8       53.0       48.0   \n25          4  mean_all           7             8       53.0       48.0   \n26          5  mean_all           7             8       53.0       48.0   \n27          5  mean_all           7             8       53.0       48.0   \n28          6  mean_all           7             8       53.0       48.0   \n29          6  mean_all           7             8       53.0       48.0   \n30          7  mean_all           7             8       53.0       48.0   \n31          7  mean_all           7             8       53.0       48.0   \n\n    local_scaler                                                 tr  \\\n0   MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n1   MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n2   MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n3   MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n4   MinMaxScaler                                  SelectKBest(k=90)   \n5   MinMaxScaler                                  SelectKBest(k=90)   \n6   MinMaxScaler                                  SelectKBest(k=90)   \n7   MinMaxScaler                                  SelectKBest(k=90)   \n8           None  FastICA(max_iter=500, n_components=25, random_...   \n9           None  FastICA(max_iter=500, n_components=25, random_...   \n10          None  FastICA(max_iter=500, n_components=25, random_...   \n11          None  FastICA(max_iter=500, n_components=25, random_...   \n12          None                                  SelectKBest(k=90)   \n13          None                                  SelectKBest(k=90)   \n14          None                                  SelectKBest(k=90)   \n15          None                                  SelectKBest(k=90)   \n16  MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n17  MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n18  MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n19  MinMaxScaler  FastICA(max_iter=500, n_components=25, random_...   \n20  MinMaxScaler                                  SelectKBest(k=90)   \n21  MinMaxScaler                                  SelectKBest(k=90)   \n22  MinMaxScaler                                  SelectKBest(k=90)   \n23  MinMaxScaler                                  SelectKBest(k=90)   \n24          None  FastICA(max_iter=500, n_components=25, random_...   \n25          None  FastICA(max_iter=500, n_components=25, random_...   \n26          None  FastICA(max_iter=500, n_components=25, random_...   \n27          None  FastICA(max_iter=500, n_components=25, random_...   \n28          None                                  SelectKBest(k=90)   \n29          None                                  SelectKBest(k=90)   \n30          None                                  SelectKBest(k=90)   \n31          None                                  SelectKBest(k=90)   \n\n                                                  cls        f1  ...  \\\n0   ExtraTreesClassifier(n_estimators=300, random_...  0.549402  ...   \n1   ExtraTreesClassifier(n_estimators=300, random_...  0.626923  ...   \n2   RandomForestClassifier(n_estimators=300, rando...  0.508941  ...   \n3   RandomForestClassifier(n_estimators=300, rando...  0.564568  ...   \n4   ExtraTreesClassifier(n_estimators=300, random_...  0.507892  ...   \n5   ExtraTreesClassifier(n_estimators=300, random_...  0.606604  ...   \n6   RandomForestClassifier(n_estimators=300, rando...  0.501852  ...   \n7   RandomForestClassifier(n_estimators=300, rando...  0.606285  ...   \n8   ExtraTreesClassifier(n_estimators=300, random_...  0.524064  ...   \n9   ExtraTreesClassifier(n_estimators=300, random_...  0.623604  ...   \n10  RandomForestClassifier(n_estimators=300, rando...  0.515520  ...   \n11  RandomForestClassifier(n_estimators=300, rando...  0.607236  ...   \n12  ExtraTreesClassifier(n_estimators=300, random_...  0.517743  ...   \n13  ExtraTreesClassifier(n_estimators=300, random_...  0.595104  ...   \n14  RandomForestClassifier(n_estimators=300, rando...  0.496255  ...   \n15  RandomForestClassifier(n_estimators=300, rando...  0.583374  ...   \n16  ExtraTreesClassifier(n_estimators=300, random_...  0.533909  ...   \n17  ExtraTreesClassifier(n_estimators=300, random_...  0.615682  ...   \n18  RandomForestClassifier(n_estimators=300, rando...  0.505396  ...   \n19  RandomForestClassifier(n_estimators=300, rando...  0.593989  ...   \n20  ExtraTreesClassifier(n_estimators=300, random_...  0.515647  ...   \n21  ExtraTreesClassifier(n_estimators=300, random_...  0.597306  ...   \n22  RandomForestClassifier(n_estimators=300, rando...  0.518045  ...   \n23  RandomForestClassifier(n_estimators=300, rando...  0.564447  ...   \n24  ExtraTreesClassifier(n_estimators=300, random_...  0.525483  ...   \n25  ExtraTreesClassifier(n_estimators=300, random_...  0.609041  ...   \n26  RandomForestClassifier(n_estimators=300, rando...  0.506925  ...   \n27  RandomForestClassifier(n_estimators=300, rando...  0.630261  ...   \n28  ExtraTreesClassifier(n_estimators=300, random_...  0.515053  ...   \n29  ExtraTreesClassifier(n_estimators=300, random_...  0.554217  ...   \n30  RandomForestClassifier(n_estimators=300, rando...  0.503458  ...   \n31  RandomForestClassifier(n_estimators=300, rando...  0.589914  ...   \n\n    A_acc_PERM  B_acc_PERM  C_acc_PERM  D_acc_PERM  F_acc_PERM  mode_PERM  \\\n0       0.4991      0.5495      0.5013      0.5130      0.4823   snapshot   \n1       0.4991      0.5495      0.5013      0.5130      0.4823   snapshot   \n2       0.4728      0.5408      0.4966      0.5086      0.4640   snapshot   \n3       0.4728      0.5408      0.4966      0.5086      0.4640   snapshot   \n4       0.5266      0.4989      0.5382      0.4842      0.4504   snapshot   \n5       0.5266      0.4989      0.5382      0.4842      0.4504   snapshot   \n6       0.5203      0.4975      0.5495      0.4791      0.4278   snapshot   \n7       0.5203      0.4975      0.5495      0.4791      0.4278   snapshot   \n8       0.5205      0.5334      0.4963      0.4966      0.4809   snapshot   \n9       0.5205      0.5334      0.4963      0.4966      0.4809   snapshot   \n10      0.5041      0.5255      0.4908      0.4818      0.4835   snapshot   \n11      0.5041      0.5255      0.4908      0.4818      0.4835   snapshot   \n12      0.5261      0.5104      0.5440      0.4938      0.4472   snapshot   \n13      0.5261      0.5104      0.5440      0.4938      0.4472   snapshot   \n14      0.5216      0.4904      0.5438      0.4939      0.4246   snapshot   \n15      0.5216      0.4904      0.5438      0.4939      0.4246   snapshot   \n16      0.4974      0.5520      0.5060      0.5148      0.4637   snapshot   \n17      0.4974      0.5520      0.5060      0.5148      0.4637   snapshot   \n18      0.4775      0.5495      0.4952      0.5122      0.4661   snapshot   \n19      0.4775      0.5495      0.4952      0.5122      0.4661   snapshot   \n20      0.5058      0.5069      0.5620      0.4873      0.4192   snapshot   \n21      0.5058      0.5069      0.5620      0.4873      0.4192   snapshot   \n22      0.4972      0.5001      0.5802      0.4864      0.4101   snapshot   \n23      0.4972      0.5001      0.5802      0.4864      0.4101   snapshot   \n24      0.5255      0.5233      0.5133      0.4952      0.4787   snapshot   \n25      0.5255      0.5233      0.5133      0.4952      0.4787   snapshot   \n26      0.5081      0.5239      0.4992      0.4784      0.4653   snapshot   \n27      0.5081      0.5239      0.4992      0.4784      0.4653   snapshot   \n28      0.5059      0.5051      0.5518      0.4841      0.4246   snapshot   \n29      0.5059      0.5051      0.5518      0.4841      0.4246   snapshot   \n30      0.5092      0.4998      0.5799      0.4795      0.4106   snapshot   \n31      0.5092      0.4998      0.5799      0.4795      0.4106   snapshot   \n\n    num_folds_PERM                                               temp  \\\n0             1000  [0.4, 0.5, 0.6, 0.2, 0.3, 0.5, 0.6, 0.3, 0.5, ...   \n1             1000  [0.4, 0.5, 0.6, 0.2, 0.3, 0.5, 0.6, 0.3, 0.5, ...   \n2             1000  [0.1, 0.2, 0.6, 0.6, 0.6, 0.6, 0.5, 0.4, 0.3, ...   \n3             1000  [0.1, 0.2, 0.6, 0.6, 0.6, 0.6, 0.5, 0.4, 0.3, ...   \n4             1000  [0.7, 0.3, 0.8, 0.5, 0.3, 0.5, 0.5, 0.1, 0.8, ...   \n5             1000  [0.7, 0.3, 0.8, 0.5, 0.3, 0.5, 0.5, 0.1, 0.8, ...   \n6             1000  [0.4, 0.5, 0.3, 0.8, 0.5, 0.5, 0.5, 0.3, 0.3, ...   \n7             1000  [0.4, 0.5, 0.3, 0.8, 0.5, 0.5, 0.5, 0.3, 0.3, ...   \n8             1000  [0.5, 0.6, 0.5, 0.5, 0.4, 0.3, 0.5, 0.5, 0.5, ...   \n9             1000  [0.5, 0.6, 0.5, 0.5, 0.4, 0.3, 0.5, 0.5, 0.5, ...   \n10            1000  [0.6, 0.4, 0.5, 0.6, 0.3, 0.4, 0.6, 0.2, 0.4, ...   \n11            1000  [0.6, 0.4, 0.5, 0.6, 0.3, 0.4, 0.6, 0.2, 0.4, ...   \n12            1000  [0.6, 0.3, 0.6, 0.3, 0.3, 0.3, 0.2, 0.5, 0.5, ...   \n13            1000  [0.6, 0.3, 0.6, 0.3, 0.3, 0.3, 0.2, 0.5, 0.5, ...   \n14            1000  [0.4, 0.4, 0.3, 0.3, 0.6, 0.3, 0.5, 0.7, 0.7, ...   \n15            1000  [0.4, 0.4, 0.3, 0.3, 0.6, 0.3, 0.5, 0.7, 0.7, ...   \n16            1000  [0.7, 0.4, 0.6, 0.8, 0.3, 0.6, 0.4, 0.3, 0.4, ...   \n17            1000  [0.7, 0.4, 0.6, 0.8, 0.3, 0.6, 0.4, 0.3, 0.4, ...   \n18            1000  [0.6, 0.4, 0.4, 0.6, 0.3, 0.7, 0.7, 0.6, 0.4, ...   \n19            1000  [0.6, 0.4, 0.4, 0.6, 0.3, 0.7, 0.7, 0.6, 0.4, ...   \n20            1000  [0.6, 0.5, 0.3, 0.3, 0.3, 0.5, 0.4, 0.5, 0.5, ...   \n21            1000  [0.6, 0.5, 0.3, 0.3, 0.3, 0.5, 0.4, 0.5, 0.5, ...   \n22            1000  [0.4, 0.6, 0.8, 0.5, 0.7, 0.5, 0.5, 0.4, 0.4, ...   \n23            1000  [0.4, 0.6, 0.8, 0.5, 0.7, 0.5, 0.5, 0.4, 0.4, ...   \n24            1000  [0.4, 0.5, 0.6, 0.4, 0.4, 0.4, 0.6, 0.5, 0.4, ...   \n25            1000  [0.4, 0.5, 0.6, 0.4, 0.4, 0.4, 0.6, 0.5, 0.4, ...   \n26            1000  [0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...   \n27            1000  [0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...   \n28            1000  [0.6, 0.4, 0.4, 0.2, 0.5, 0.3, 0.4, 0.4, 0.6, ...   \n29            1000  [0.6, 0.4, 0.4, 0.2, 0.5, 0.3, 0.4, 0.4, 0.6, ...   \n30            1000  [0.3, 0.4, 0.5, 0.4, 0.6, 0.7, 0.3, 0.5, 0.3, ...   \n31            1000  [0.3, 0.4, 0.5, 0.4, 0.6, 0.7, 0.3, 0.5, 0.3, ...   \n\n    classifier_rank  classifier_pval  \n0               522             5.22  \n1               112             1.12  \n2               569             5.69  \n3               344             3.44  \n4               519             5.19  \n5               273             2.73  \n6               512             5.12  \n7               262             2.62  \n8               561             5.61  \n9               127             1.27  \n10              568             5.68  \n11              138             1.38  \n12              513             5.13  \n13              272             2.72  \n14              492             4.92  \n15              264             2.64  \n16              522             5.22  \n17              116             1.16  \n18              548             5.48  \n19              125             1.25  \n20              557             5.57  \n21              296             2.96  \n22              531             5.31  \n23              296             2.96  \n24              515             5.15  \n25              106             1.06  \n26              562             5.62  \n27              118             1.18  \n28              543             5.43  \n29              321             3.21  \n30              517             5.17  \n31              289             2.89  \n\n[32 rows x 59 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_idx</th>\n      <th>method</th>\n      <th>cutoff_low</th>\n      <th>cuttoff_high</th>\n      <th>labeled_0</th>\n      <th>labeled_1</th>\n      <th>local_scaler</th>\n      <th>tr</th>\n      <th>cls</th>\n      <th>f1</th>\n      <th>...</th>\n      <th>A_acc_PERM</th>\n      <th>B_acc_PERM</th>\n      <th>C_acc_PERM</th>\n      <th>D_acc_PERM</th>\n      <th>F_acc_PERM</th>\n      <th>mode_PERM</th>\n      <th>num_folds_PERM</th>\n      <th>temp</th>\n      <th>classifier_rank</th>\n      <th>classifier_pval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.549402</td>\n      <td>...</td>\n      <td>0.4991</td>\n      <td>0.5495</td>\n      <td>0.5013</td>\n      <td>0.5130</td>\n      <td>0.4823</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.5, 0.6, 0.2, 0.3, 0.5, 0.6, 0.3, 0.5, ...</td>\n      <td>522</td>\n      <td>5.22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.626923</td>\n      <td>...</td>\n      <td>0.4991</td>\n      <td>0.5495</td>\n      <td>0.5013</td>\n      <td>0.5130</td>\n      <td>0.4823</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.5, 0.6, 0.2, 0.3, 0.5, 0.6, 0.3, 0.5, ...</td>\n      <td>112</td>\n      <td>1.12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.508941</td>\n      <td>...</td>\n      <td>0.4728</td>\n      <td>0.5408</td>\n      <td>0.4966</td>\n      <td>0.5086</td>\n      <td>0.4640</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.1, 0.2, 0.6, 0.6, 0.6, 0.6, 0.5, 0.4, 0.3, ...</td>\n      <td>569</td>\n      <td>5.69</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.564568</td>\n      <td>...</td>\n      <td>0.4728</td>\n      <td>0.5408</td>\n      <td>0.4966</td>\n      <td>0.5086</td>\n      <td>0.4640</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.1, 0.2, 0.6, 0.6, 0.6, 0.6, 0.5, 0.4, 0.3, ...</td>\n      <td>344</td>\n      <td>3.44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.507892</td>\n      <td>...</td>\n      <td>0.5266</td>\n      <td>0.4989</td>\n      <td>0.5382</td>\n      <td>0.4842</td>\n      <td>0.4504</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.7, 0.3, 0.8, 0.5, 0.3, 0.5, 0.5, 0.1, 0.8, ...</td>\n      <td>519</td>\n      <td>5.19</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.606604</td>\n      <td>...</td>\n      <td>0.5266</td>\n      <td>0.4989</td>\n      <td>0.5382</td>\n      <td>0.4842</td>\n      <td>0.4504</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.7, 0.3, 0.8, 0.5, 0.3, 0.5, 0.5, 0.1, 0.8, ...</td>\n      <td>273</td>\n      <td>2.73</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.501852</td>\n      <td>...</td>\n      <td>0.5203</td>\n      <td>0.4975</td>\n      <td>0.5495</td>\n      <td>0.4791</td>\n      <td>0.4278</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.5, 0.3, 0.8, 0.5, 0.5, 0.5, 0.3, 0.3, ...</td>\n      <td>512</td>\n      <td>5.12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.606285</td>\n      <td>...</td>\n      <td>0.5203</td>\n      <td>0.4975</td>\n      <td>0.5495</td>\n      <td>0.4791</td>\n      <td>0.4278</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.5, 0.3, 0.8, 0.5, 0.5, 0.5, 0.3, 0.3, ...</td>\n      <td>262</td>\n      <td>2.62</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.524064</td>\n      <td>...</td>\n      <td>0.5205</td>\n      <td>0.5334</td>\n      <td>0.4963</td>\n      <td>0.4966</td>\n      <td>0.4809</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.5, 0.6, 0.5, 0.5, 0.4, 0.3, 0.5, 0.5, 0.5, ...</td>\n      <td>561</td>\n      <td>5.61</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.623604</td>\n      <td>...</td>\n      <td>0.5205</td>\n      <td>0.5334</td>\n      <td>0.4963</td>\n      <td>0.4966</td>\n      <td>0.4809</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.5, 0.6, 0.5, 0.5, 0.4, 0.3, 0.5, 0.5, 0.5, ...</td>\n      <td>127</td>\n      <td>1.27</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.515520</td>\n      <td>...</td>\n      <td>0.5041</td>\n      <td>0.5255</td>\n      <td>0.4908</td>\n      <td>0.4818</td>\n      <td>0.4835</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.4, 0.5, 0.6, 0.3, 0.4, 0.6, 0.2, 0.4, ...</td>\n      <td>568</td>\n      <td>5.68</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.607236</td>\n      <td>...</td>\n      <td>0.5041</td>\n      <td>0.5255</td>\n      <td>0.4908</td>\n      <td>0.4818</td>\n      <td>0.4835</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.4, 0.5, 0.6, 0.3, 0.4, 0.6, 0.2, 0.4, ...</td>\n      <td>138</td>\n      <td>1.38</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>6</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.517743</td>\n      <td>...</td>\n      <td>0.5261</td>\n      <td>0.5104</td>\n      <td>0.5440</td>\n      <td>0.4938</td>\n      <td>0.4472</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.3, 0.6, 0.3, 0.3, 0.3, 0.2, 0.5, 0.5, ...</td>\n      <td>513</td>\n      <td>5.13</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>6</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.595104</td>\n      <td>...</td>\n      <td>0.5261</td>\n      <td>0.5104</td>\n      <td>0.5440</td>\n      <td>0.4938</td>\n      <td>0.4472</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.3, 0.6, 0.3, 0.3, 0.3, 0.2, 0.5, 0.5, ...</td>\n      <td>272</td>\n      <td>2.72</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.496255</td>\n      <td>...</td>\n      <td>0.5216</td>\n      <td>0.4904</td>\n      <td>0.5438</td>\n      <td>0.4939</td>\n      <td>0.4246</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.4, 0.3, 0.3, 0.6, 0.3, 0.5, 0.7, 0.7, ...</td>\n      <td>492</td>\n      <td>4.92</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>7</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.583374</td>\n      <td>...</td>\n      <td>0.5216</td>\n      <td>0.4904</td>\n      <td>0.5438</td>\n      <td>0.4939</td>\n      <td>0.4246</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.4, 0.3, 0.3, 0.6, 0.3, 0.5, 0.7, 0.7, ...</td>\n      <td>264</td>\n      <td>2.64</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.533909</td>\n      <td>...</td>\n      <td>0.4974</td>\n      <td>0.5520</td>\n      <td>0.5060</td>\n      <td>0.5148</td>\n      <td>0.4637</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.7, 0.4, 0.6, 0.8, 0.3, 0.6, 0.4, 0.3, 0.4, ...</td>\n      <td>522</td>\n      <td>5.22</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.615682</td>\n      <td>...</td>\n      <td>0.4974</td>\n      <td>0.5520</td>\n      <td>0.5060</td>\n      <td>0.5148</td>\n      <td>0.4637</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.7, 0.4, 0.6, 0.8, 0.3, 0.6, 0.4, 0.3, 0.4, ...</td>\n      <td>116</td>\n      <td>1.16</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.505396</td>\n      <td>...</td>\n      <td>0.4775</td>\n      <td>0.5495</td>\n      <td>0.4952</td>\n      <td>0.5122</td>\n      <td>0.4661</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.4, 0.4, 0.6, 0.3, 0.7, 0.7, 0.6, 0.4, ...</td>\n      <td>548</td>\n      <td>5.48</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.593989</td>\n      <td>...</td>\n      <td>0.4775</td>\n      <td>0.5495</td>\n      <td>0.4952</td>\n      <td>0.5122</td>\n      <td>0.4661</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.4, 0.4, 0.6, 0.3, 0.7, 0.7, 0.6, 0.4, ...</td>\n      <td>125</td>\n      <td>1.25</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.515647</td>\n      <td>...</td>\n      <td>0.5058</td>\n      <td>0.5069</td>\n      <td>0.5620</td>\n      <td>0.4873</td>\n      <td>0.4192</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.5, 0.3, 0.3, 0.3, 0.5, 0.4, 0.5, 0.5, ...</td>\n      <td>557</td>\n      <td>5.57</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.597306</td>\n      <td>...</td>\n      <td>0.5058</td>\n      <td>0.5069</td>\n      <td>0.5620</td>\n      <td>0.4873</td>\n      <td>0.4192</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.5, 0.3, 0.3, 0.3, 0.5, 0.4, 0.5, 0.5, ...</td>\n      <td>296</td>\n      <td>2.96</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>3</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.518045</td>\n      <td>...</td>\n      <td>0.4972</td>\n      <td>0.5001</td>\n      <td>0.5802</td>\n      <td>0.4864</td>\n      <td>0.4101</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.6, 0.8, 0.5, 0.7, 0.5, 0.5, 0.4, 0.4, ...</td>\n      <td>531</td>\n      <td>5.31</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>MinMaxScaler</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.564447</td>\n      <td>...</td>\n      <td>0.4972</td>\n      <td>0.5001</td>\n      <td>0.5802</td>\n      <td>0.4864</td>\n      <td>0.4101</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.6, 0.8, 0.5, 0.7, 0.5, 0.5, 0.4, 0.4, ...</td>\n      <td>296</td>\n      <td>2.96</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.525483</td>\n      <td>...</td>\n      <td>0.5255</td>\n      <td>0.5233</td>\n      <td>0.5133</td>\n      <td>0.4952</td>\n      <td>0.4787</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.5, 0.6, 0.4, 0.4, 0.4, 0.6, 0.5, 0.4, ...</td>\n      <td>515</td>\n      <td>5.15</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>4</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.609041</td>\n      <td>...</td>\n      <td>0.5255</td>\n      <td>0.5233</td>\n      <td>0.5133</td>\n      <td>0.4952</td>\n      <td>0.4787</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.4, 0.5, 0.6, 0.4, 0.4, 0.4, 0.6, 0.5, 0.4, ...</td>\n      <td>106</td>\n      <td>1.06</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>5</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.506925</td>\n      <td>...</td>\n      <td>0.5081</td>\n      <td>0.5239</td>\n      <td>0.4992</td>\n      <td>0.4784</td>\n      <td>0.4653</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...</td>\n      <td>562</td>\n      <td>5.62</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>5</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.630261</td>\n      <td>...</td>\n      <td>0.5081</td>\n      <td>0.5239</td>\n      <td>0.4992</td>\n      <td>0.4784</td>\n      <td>0.4653</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...</td>\n      <td>118</td>\n      <td>1.18</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>6</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.515053</td>\n      <td>...</td>\n      <td>0.5059</td>\n      <td>0.5051</td>\n      <td>0.5518</td>\n      <td>0.4841</td>\n      <td>0.4246</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.4, 0.4, 0.2, 0.5, 0.3, 0.4, 0.4, 0.6, ...</td>\n      <td>543</td>\n      <td>5.43</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>6</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>ExtraTreesClassifier(n_estimators=300, random_...</td>\n      <td>0.554217</td>\n      <td>...</td>\n      <td>0.5059</td>\n      <td>0.5051</td>\n      <td>0.5518</td>\n      <td>0.4841</td>\n      <td>0.4246</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.6, 0.4, 0.4, 0.2, 0.5, 0.3, 0.4, 0.4, 0.6, ...</td>\n      <td>321</td>\n      <td>3.21</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>7</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.503458</td>\n      <td>...</td>\n      <td>0.5092</td>\n      <td>0.4998</td>\n      <td>0.5799</td>\n      <td>0.4795</td>\n      <td>0.4106</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.3, 0.4, 0.5, 0.4, 0.6, 0.7, 0.3, 0.5, 0.3, ...</td>\n      <td>517</td>\n      <td>5.17</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>7</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>SelectKBest(k=90)</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.589914</td>\n      <td>...</td>\n      <td>0.5092</td>\n      <td>0.4998</td>\n      <td>0.5799</td>\n      <td>0.4795</td>\n      <td>0.4106</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.3, 0.4, 0.5, 0.4, 0.6, 0.7, 0.3, 0.5, 0.3, ...</td>\n      <td>289</td>\n      <td>2.89</td>\n    </tr>\n  </tbody>\n</table>\n<p>32 rows × 59 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "res_dir_ts = \"1649676762\"\n",
    "res_path = \"/Users/orenkobo/Desktop/PhD/Aim1/Analysis_artifacts\"\n",
    "res_fn = f\"{res_path}/{res_dir_ts}/{res_dir_ts}_all_res_df_with_perm7-8_iterall_20.0subjectsout_standard_scaled_perm_iter_normalized_perm_iter_standard_scaled_regr_iter_normalized_regr_iter.csv\"\n",
    "res_df = pd.read_csv(res_fn, index_col=None)\n",
    "res_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    actual_mean_success_across_folds  model_idx\n0                             0.4915          0\n1                             0.6120          0\n2                             0.4645          1\n3                             0.5920          1\n4                             0.4700          2\n5                             0.5830          2\n6                             0.4620          3\n7                             0.5740          3\n8                             0.4660          4\n9                             0.6125          4\n10                            0.4615          5\n11                            0.6255          5\n12                            0.4700          6\n13                            0.5700          6\n14                            0.4620          7\n15                            0.5715          7\n16                            0.4605          0\n17                            0.6030          0\n18                            0.4500          1\n19                            0.6015          1\n20                            0.4815          2\n21                            0.5665          2\n22                            0.4725          3\n23                            0.5455          3\n24                            0.4600          4\n25                            0.6065          4\n26                            0.4660          5\n27                            0.6310          5\n28                            0.4765          6\n29                            0.5560          6\n30                            0.4615          7\n31                            0.5690          7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual_mean_success_across_folds</th>\n      <th>model_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.4915</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.6120</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.4645</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5920</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.4700</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.5830</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.4620</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.5740</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.4660</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.6125</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.4615</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.6255</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.4700</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.5700</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.4620</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.5715</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.4605</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.6030</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.4500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.6015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.4815</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.5665</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.4725</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.5455</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.4600</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.6065</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.4660</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.6310</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.4765</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.5560</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.4615</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.5690</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[['actual_mean_success_across_folds','model_idx']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    model_idx    method  cutoff_low  cuttoff_high  labeled_0  labeled_1  \\\n26          5  mean_all           7             8       53.0       48.0   \n27          5  mean_all           7             8       53.0       48.0   \n\n   local_scaler                                                 tr  \\\n26         None  FastICA(max_iter=500, n_components=25, random_...   \n27         None  FastICA(max_iter=500, n_components=25, random_...   \n\n                                                  cls        f1  ...  \\\n26  RandomForestClassifier(n_estimators=300, rando...  0.506925  ...   \n27  RandomForestClassifier(n_estimators=300, rando...  0.630261  ...   \n\n    A_acc_PERM  B_acc_PERM  C_acc_PERM  D_acc_PERM  F_acc_PERM  mode_PERM  \\\n26      0.5081      0.5239      0.4992      0.4784      0.4653   snapshot   \n27      0.5081      0.5239      0.4992      0.4784      0.4653   snapshot   \n\n    num_folds_PERM                                               temp  \\\n26            1000  [0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...   \n27            1000  [0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...   \n\n    classifier_rank  classifier_pval  \n26              562             5.62  \n27              118             1.18  \n\n[2 rows x 59 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_idx</th>\n      <th>method</th>\n      <th>cutoff_low</th>\n      <th>cuttoff_high</th>\n      <th>labeled_0</th>\n      <th>labeled_1</th>\n      <th>local_scaler</th>\n      <th>tr</th>\n      <th>cls</th>\n      <th>f1</th>\n      <th>...</th>\n      <th>A_acc_PERM</th>\n      <th>B_acc_PERM</th>\n      <th>C_acc_PERM</th>\n      <th>D_acc_PERM</th>\n      <th>F_acc_PERM</th>\n      <th>mode_PERM</th>\n      <th>num_folds_PERM</th>\n      <th>temp</th>\n      <th>classifier_rank</th>\n      <th>classifier_pval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>5</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.506925</td>\n      <td>...</td>\n      <td>0.5081</td>\n      <td>0.5239</td>\n      <td>0.4992</td>\n      <td>0.4784</td>\n      <td>0.4653</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...</td>\n      <td>562</td>\n      <td>5.62</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>5</td>\n      <td>mean_all</td>\n      <td>7</td>\n      <td>8</td>\n      <td>53.0</td>\n      <td>48.0</td>\n      <td>None</td>\n      <td>FastICA(max_iter=500, n_components=25, random_...</td>\n      <td>RandomForestClassifier(n_estimators=300, rando...</td>\n      <td>0.630261</td>\n      <td>...</td>\n      <td>0.5081</td>\n      <td>0.5239</td>\n      <td>0.4992</td>\n      <td>0.4784</td>\n      <td>0.4653</td>\n      <td>snapshot</td>\n      <td>1000</td>\n      <td>[0.5, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.2, 0.2, ...</td>\n      <td>118</td>\n      <td>1.18</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 59 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_indices = [26,27]\n",
    "conf_df = res_df.iloc[selected_indices]\n",
    "conf_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466\n",
      "0.6309999999999999\n"
     ]
    }
   ],
   "source": [
    "shuffled_cond_scores = eval(conf_df.iloc[0].per_fold_score)\n",
    "regular_cond_scores = eval(conf_df.iloc[1].per_fold_score)\n",
    "print(np.mean(shuffled_cond_scores))\n",
    "print(np.mean(regular_cond_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.45,\n 0.35,\n 0.6,\n 0.45,\n 0.5,\n 0.5,\n 0.3,\n 0.45,\n 0.6,\n 0.5,\n 0.6,\n 0.5,\n 0.45,\n 0.35,\n 0.5,\n 0.4,\n 0.6,\n 0.7,\n 0.35,\n 0.45,\n 0.45,\n 0.6,\n 0.45,\n 0.55,\n 0.45,\n 0.5,\n 0.4,\n 0.5,\n 0.45,\n 0.45,\n 0.4,\n 0.45,\n 0.4,\n 0.4,\n 0.3,\n 0.6,\n 0.6,\n 0.3,\n 0.55,\n 0.5,\n 0.4,\n 0.5,\n 0.35,\n 0.45,\n 0.35,\n 0.55,\n 0.6,\n 0.4,\n 0.5,\n 0.45,\n 0.4,\n 0.45,\n 0.4,\n 0.55,\n 0.5,\n 0.3,\n 0.45,\n 0.45,\n 0.5,\n 0.4,\n 0.4,\n 0.4,\n 0.5,\n 0.5,\n 0.45,\n 0.45,\n 0.55,\n 0.5,\n 0.55,\n 0.4,\n 0.5,\n 0.6,\n 0.75,\n 0.45,\n 0.5,\n 0.35,\n 0.45,\n 0.45,\n 0.45,\n 0.5,\n 0.6,\n 0.45,\n 0.5,\n 0.3,\n 0.5,\n 0.4,\n 0.45,\n 0.45,\n 0.5,\n 0.6,\n 0.35,\n 0.6,\n 0.2,\n 0.5,\n 0.4,\n 0.45,\n 0.45,\n 0.4,\n 0.5,\n 0.45]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_cond_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'whiskers': [<matplotlib.lines.Line2D at 0x7ffa445268b0>,\n  <matplotlib.lines.Line2D at 0x7ffa44526b80>,\n  <matplotlib.lines.Line2D at 0x7ffa4454a190>,\n  <matplotlib.lines.Line2D at 0x7ffa4454a520>],\n 'caps': [<matplotlib.lines.Line2D at 0x7ffa44526f10>,\n  <matplotlib.lines.Line2D at 0x7ffa4453c2e0>,\n  <matplotlib.lines.Line2D at 0x7ffa4454a8b0>,\n  <matplotlib.lines.Line2D at 0x7ffa4454ac40>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7ffa44526460>,\n  <matplotlib.lines.Line2D at 0x7ffa4453cdc0>],\n 'medians': [<matplotlib.lines.Line2D at 0x7ffa4453c670>,\n  <matplotlib.lines.Line2D at 0x7ffa4454afd0>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7ffa4453ca00>,\n  <matplotlib.lines.Line2D at 0x7ffa445523a0>],\n 'means': []}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPE0lEQVR4nO3df4jk913H8eermwuB2tYcWaHkLr1DrrrHtRgdUqGL9GoKlwiXQkFui2Jg7SF4Z7UiRrakaWT/sEIVwgmebvAHds9SRU48ib9WZKUtN9fG6t2Sepy2uVjotl2NImku5e0ft4mTzdztbDK7k/3s8wED+/1+PzfzXhie+WZm5zupKiRJ298bRj2AJGk4DLokNcKgS1IjDLokNcKgS1IjbhnVA99xxx21b9++UT28JG1LFy5c+EZVjfc7NrKg79u3j263O6qHl6RtKclXbnTMl1wkqREGXZIaYdAlqREGXZIaYdAlqREDBT3JkSRPJbmc5KE+x+9KspDki0m+lOT+4Y8qSbqZdYOeZAw4BdwHHASmkhxcs+yjwKer6m7gGPBbwx5UknRzg5yh3wNcrqorVfU8cAZ4YM2aAt68+vNbgP8Y3oiSpEEM8sGiO4Gne7avAu9as+YR4K+SnATeCNzb746SHAeOA9x1110bnVXS61iSDf8bv49huIb1pugU8HtVtQe4H/jDJK+476o6XVWdquqMj/f95Kqkbaqq+t7WO6bhGSTozwB7e7b3rO7rNQ18GqCqPgvcBtwxjAElSYMZJOjngQNJ9ie5letvep5ds+arwI8CJJngetCXhzmoJOnm1g16Vb0AnACeAJa4/tcsF5M8muTo6rJfBD6U5J+AeeDB8v+nJGlLDXS1xao6B5xbs+/hnp8vAe8e7miSpI3wk6KS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOjb3Pz8PIcOHWJsbIxDhw4xPz8/6pEkjchAnxTV69P8/DwzMzPMzc0xOTnJ4uIi09PTAExNTY14OklbzTP0bWx2dpa5uTkOHz7Mrl27OHz4MHNzc8zOzo56NEkjkFFdQ6vT6VS32x3JY7dibGyM5557jl27dr2079q1a9x222185zvfGeFk0v9L4rXPhyjJharq9DvmGfo2NjExweLi4sv2LS4uMjExMaKJJI2SQd/GZmZmmJ6eZmFhgWvXrrGwsMD09DQzMzOjHk3SCPim6Db24hufJ0+eZGlpiYmJCWZnZ31DVNqhfA1d0qbyNfTh8jV0SdoBDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNWKgoCc5kuSpJJeTPNTn+G8keXL19uUk/zn0SdWX10OX9KJ1P/qfZAw4BbwPuAqcT3K2qi69uKaqfqFn/Ung7k2YVWt4PXRJvQY5Q78HuFxVV6rqeeAM8MBN1k8BniZuAa+HLqnXIEG/E3i6Z/vq6r5XSPI2YD/wdzc4fjxJN0l3eXl5o7NqjaWlJSYnJ1+2b3JykqWlpRFNpJ1g9+7dJBn4BmxofRJ279494t9yexr2m6LHgM9UVd9vV6iq01XVqarO+Pj4kB965/F66BqFlZUVqmpTbysrK6P+NbelQYL+DLC3Z3vP6r5+juHLLVvG66FL6jXI9dDPAweS7Od6yI8BH1y7KMn3A7cDnx3qhLohr4cuqde6Qa+qF5KcAJ4AxoDHq+pikkeBblWdXV16DDhTXvh4S01NTRlwScCA31hUVeeAc2v2Pbxm+5HhjSVJ2ig/KSpJjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjRjoWi6S9KL62Jvhkbds/mNowwy6pA3Jx59lsy+qmgQv97dxvuQiSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0YKOhJjiR5KsnlJA/dYM2PJ7mU5GKSTw13TEnSeta9OFeSMeAU8D7gKnA+ydmqutSz5gDwK8C7q2olyfds1sCSpP4GOUO/B7hcVVeq6nngDPDAmjUfAk5V1QpAVX19uGNKktYzSNDvBJ7u2b66uq/X24G3J/nHJJ9LcqTfHSU5nqSbpLu8vPzqJt7Bkryqm6SdYVhvit4CHADeA0wBv5Pku9cuqqrTVdWpqs74+PiQHnrnqKob3m52XNLOMEjQnwH29mzvWd3X6ypwtqquVdW/AV/meuAlSVtkkKCfBw4k2Z/kVuAYcHbNmj/j+tk5Se7g+kswV4Y3piRpPesGvapeAE4ATwBLwKer6mKSR5McXV32BPDNJJeABeCXquqbmzW0JOmVMqrXWDudTnW73ZE8douS+Hq5tsRWPNd8Pt9YkgtV1el3zE+KSlIjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1Ij1v0KOklaa7O/OOX222/f1PtvlUGXtCEbvWiWF9raOr7kIkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNGCjoSY4keSrJ5SQP9Tn+YJLlJE+u3n56+KNKkm5m3YtzJRkDTgHvA64C55OcrapLa5b+cVWd2IQZJUkDGOQM/R7gclVdqarngTPAA5s7liRpowYJ+p3A0z3bV1f3rfWBJF9K8pkke/vdUZLjSbpJusvLy69i3J1h9+7dJNnQDdjQ+t27d4/4t5Q0bMN6U/TPgX1V9U7gr4Hf77eoqk5XVaeqOuPj40N66PasrKxQVZt6W1lZGfWvKWnIBgn6M0DvGfee1X0vqapvVtW3Vzd/F/ih4YwnSRrUIEE/DxxIsj/JrcAx4GzvgiRv7dk8CiwNb0RJ0iDW/SuXqnohyQngCWAMeLyqLiZ5FOhW1Vng55IcBV4AvgU8uIkzS5L6yKi+66/T6VS32x3JY7/ebcV3MPo9j9oqPteGK8mFqur0O+YnRSWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEetenEtbrz72ZnjkLZv/GJKaYtBfh/LxZ7fm4lyPbOpDSNpivuQiSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0YKOhJjiR5KsnlJA/dZN0HklSSzvBGlCQNYt2gJxkDTgH3AQeBqSQH+6x7E/Bh4PPDHlKStL5BztDvAS5X1ZWqeh44AzzQZ92vAr8GPDfE+SRJAxok6HcCT/dsX13d95IkPwjsraq/uNkdJTmepJuku7y8vOFhd5Ikm3q7/fbbR/0rqjE3eq6td0zD85qvh57kDcAngQfXW1tVp4HTAJ1OZ3Mv+L2NvZproSfZ9GuoSzfj82/0BjlDfwbY27O9Z3Xfi94EHAL+Psm/Az8MnPWNUUnaWoME/TxwIMn+JLcCx4CzLx6sqv+qqjuqal9V7QM+Bxytqu6mTCxJ6mvdoFfVC8AJ4AlgCfh0VV1M8miSo5s9oCRpMAO9hl5V54Bza/Y9fIO173ntY0mSNspPikpSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDVioKAnOZLkqSSXkzzU5/jPJPnnJE8mWUxycPijSpJuZt2gJxkDTgH3AQeBqT7B/lRVvaOqfgD4BPDJYQ8qSbq5Qc7Q7wEuV9WVqnoeOAM80Lugqp7t2XwjUMMbUZI0iFsGWHMn8HTP9lXgXWsXJflZ4CPArcB7+91RkuPAcYC77rpro7PueEle1fEq//sq7QRDe1O0qk5V1fcCvwx89AZrTldVp6o64+Pjw3roHaOqXtVN0s4wSNCfAfb2bO9Z3XcjZ4D3v4aZJEmvwiBBPw8cSLI/ya3AMeBs74IkB3o2fwz41+GNKEkaxLqvoVfVC0lOAE8AY8DjVXUxyaNAt6rOAieS3AtcA1aAn9rMoSVJrzTIm6JU1Tng3Jp9D/f8/OEhzyVJ2iA/KSpJjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktSIgYKe5EiSp5JcTvJQn+MfSXIpyZeS/G2Stw1/VPUzPz/PoUOHGBsb49ChQ8zPz496JEkjsm7Qk4wBp4D7gIPAVJKDa5Z9EehU1TuBzwCfGPageqX5+XlmZmZ47LHHeO6553jssceYmZkx6tIONcgZ+j3A5aq6UlXPA2eAB3oXVNVCVf3v6ubngD3DHVP9zM7OMjc3x+HDh9m1axeHDx9mbm6O2dnZUY8maQQGCfqdwNM921dX993INPCX/Q4kOZ6km6S7vLw8+JTqa2lpicnJyZftm5ycZGlpaUQTSRqlob4pmuQngA7w6/2OV9XpqupUVWd8fHyYD70jTUxMsLi4+LJ9i4uLTExMjGgiSaM0SNCfAfb2bO9Z3fcySe4FZoCjVfXt4Yynm5mZmWF6epqFhQWuXbvGwsIC09PTzMzMjHo0SSNwywBrzgMHkuznesiPAR/sXZDkbuC3gSNV9fWhT6m+pqamADh58iRLS0tMTEwwOzv70n5JO0uqav1Fyf3AbwJjwONVNZvkUaBbVWeT/A3wDuBrq//kq1V19Gb32el0qtvtvqbhJWmnSXKhqjr9jg1yhk5VnQPOrdn3cM/P976mCSVJr5mfFJWkRhh0SWqEQZekRhh0SWrEQH/lsikPnCwDXxnJg7fpDuAbox5C6sPn5nC9rar6fjJzZEHXcCXp3uhPmaRR8rm5dXzJRZIaYdAlqREGvR2nRz2AdAM+N7eIr6FLUiM8Q5ekRhh0SWqEQd/mkjye5OtJ/mXUs0i9kuxNsrD6BfIXk3x41DO1ztfQt7kkPwL8D/AHVXVo1PNIL0ryVuCtVfWFJG8CLgDvr6pLIx6tWZ6hb3NV9Q/At0Y9h7RWVX2tqr6w+vN/A0vc/PuI9RoZdEmbLsk+4G7g8yMepWkGXdKmSvJdwJ8AP19Vz456npYZdEmbJskursf8j6rqT0c9T+sMuqRNkSTAHLBUVZ8c9Tw7gUHf5pLMA58Fvi/J1STTo55JWvVu4CeB9yZ5cvV2/6iHapl/tihJjfAMXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIa8X/isAkn1ojdbwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot([shuffled_cond_scores, regular_cond_scores])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import scipy.stats\n",
    "from palettable.colorbrewer.qualitative import Set2_7\n",
    "import seaborn as sns\n",
    "def draw_stars_box(regr_acc_l, rand_acc_l):\n",
    "    #https://github.com/jbmouret/matplotlib_for_papers\n",
    "    fig = figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    bp = ax.boxplot([regr_acc_l, rand_acc_l])\n",
    "    params = {\n",
    "        'axes.labelsize': 8,\n",
    "        'font.size': 8,\n",
    "        'legend.fontsize': 10,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'text.usetex': False,\n",
    "        'figure.figsize': [5, 8]\n",
    "    }\n",
    "    rcParams.update(params)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.tick_params(axis='x', direction='out', size=15)\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    ax.grid(axis='y', color=\"0.9\", linestyle='-', linewidth=1)\n",
    "    ax.set_axisbelow(True)\n",
    "    # colors, as before\n",
    "    colors = Set2_7.mpl_colors\n",
    "\n",
    "    for i in range(0, len(bp['boxes'])):\n",
    "        bp['boxes'][i].set_color(colors[i])\n",
    "        # we have two whiskers!\n",
    "        bp['whiskers'][i*2].set_color(colors[i])\n",
    "        bp['whiskers'][i*2 + 1].set_color(colors[i])\n",
    "        bp['whiskers'][i*2].set_linewidth(2)\n",
    "        bp['whiskers'][i*2 + 1].set_linewidth(2)\n",
    "        # fliers\n",
    "        # (set allows us to set many parameters at once)\n",
    "        bp['fliers'][i].set(markerfacecolor=colors[i],\n",
    "                            marker='o', alpha=0.75, markersize=6,\n",
    "                            markeredgecolor='none')\n",
    "        bp['medians'][i].set_color('black')\n",
    "        bp['medians'][i].set_linewidth(3)\n",
    "        # and 4 caps to remove\n",
    "        for c in bp['caps']:\n",
    "            c.set_linewidth(0)\n",
    "    for i in range(len(bp['boxes'])):\n",
    "        box = bp['boxes'][i]\n",
    "        box.set_linewidth(0)\n",
    "        boxX = []\n",
    "        boxY = []\n",
    "        for j in range(5):\n",
    "            boxX.append(box.get_xdata()[j])\n",
    "            boxY.append(box.get_ydata()[j])\n",
    "            boxCoords = list(zip(boxX,boxY))\n",
    "            boxPolygon = Polygon(boxCoords, facecolor = colors[i], linewidth=0)\n",
    "            ax.add_patch(boxPolygon)\n",
    "    ax.set_xticklabels(['Actual','Shuffled'], fontsize=15)\n",
    "\n",
    "\n",
    "    def stars(p):\n",
    "        if p < 0.0001:\n",
    "            return \"****\"\n",
    "        elif (p < 0.001):\n",
    "            return \"***\"\n",
    "        elif (p < 0.01):\n",
    "            return \"**\"\n",
    "        elif (p < 0.05):\n",
    "            return \"*\"\n",
    "        else:\n",
    "            return \"-\"\n",
    "\n",
    "\n",
    "    z, p = scipy.stats.mannwhitneyu(regr_acc_l, rand_acc_l)\n",
    "\n",
    "    p_value = p * 2\n",
    "    s = stars(p)\n",
    "    y_max = np.max(np.concatenate((regr_acc_l, rand_acc_l)))\n",
    "    y_min = np.min(np.concatenate((regr_acc_l, rand_acc_l)))\n",
    "\n",
    "    ax.annotate(\"\", xy=(1, y_max), xycoords='data',\n",
    "                xytext=(2, y_max), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-\", ec='#aaaaaa',\n",
    "                                connectionstyle=\"bar,fraction=0.2\"))\n",
    "    ax.text(1.5, y_max + abs(y_max - y_min)*0.1, stars(p_value),\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center')\n",
    "    plt.suptitle(\"Per iteration accuracy \", fontsize = 12)\n",
    "    fig.subplots_adjust(left=0.2)\n",
    "\n",
    "    plt.show()\n",
    "    print(f\"mannwhitneyu: z = {z} , p = {p} \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mannwhitneyu: z = 8863.0 , p = 1.9540084212350138e-21 \n"
     ]
    }
   ],
   "source": [
    "draw_stars_box(regular_cond_scores, shuffled_cond_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6309999999999999 0.09766780431646857\n",
      "0.466 0.08940917178902846\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(regular_cond_scores), np.std(regular_cond_scores))\n",
    "print(np.mean(shuffled_cond_scores), np.std(shuffled_cond_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.8,\n 0.65,\n 0.7,\n 0.5,\n 0.7,\n 0.6,\n 0.65,\n 0.6,\n 0.55,\n 0.7,\n 0.8,\n 0.7,\n 0.75,\n 0.65,\n 0.6,\n 0.6,\n 0.7,\n 0.7,\n 0.65,\n 0.55,\n 0.7,\n 0.75,\n 0.75,\n 0.45,\n 0.5,\n 0.55,\n 0.8,\n 0.65,\n 0.7,\n 0.55,\n 0.75,\n 0.65,\n 0.65,\n 0.65,\n 0.7,\n 0.6,\n 0.5,\n 0.5,\n 0.55,\n 0.6,\n 0.7,\n 0.75,\n 0.5,\n 0.7,\n 0.8,\n 0.7,\n 0.55,\n 0.45,\n 0.7,\n 0.65,\n 0.8,\n 0.6,\n 0.5,\n 0.5,\n 0.55,\n 0.65,\n 0.5,\n 0.75,\n 0.6,\n 0.75,\n 0.7,\n 0.7,\n 0.7,\n 0.6,\n 0.65,\n 0.65,\n 0.65,\n 0.75,\n 0.7,\n 0.75,\n 0.6,\n 0.75,\n 0.55,\n 0.4,\n 0.65,\n 0.6,\n 0.4,\n 0.75,\n 0.45,\n 0.6,\n 0.7,\n 0.65,\n 0.6,\n 0.65,\n 0.55,\n 0.75,\n 0.55,\n 0.5,\n 0.4,\n 0.5,\n 0.65,\n 0.7,\n 0.6,\n 0.65,\n 0.55,\n 0.75,\n 0.6,\n 0.65,\n 0.55,\n 0.55]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compare_dict(regr_dict, rand_dict, n_iters = 500):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    regr_acc_l = [regr_dict['res_dict'][x]['subj_level_acc'] for x in range(n_iters)]\n",
    "    rand_acc_l = [rand_dict['res_dict'][x]['subj_level_acc'] for x in range(n_iters)]\n",
    "    sns.distplot(regr_acc_l, color = 'b',bins= 10, hist_kws={ \"alpha\": 0.1});\n",
    "    sns.distplot(rand_acc_l, color = 'r',bins= 10, hist_kws={ \"alpha\": 0.1});\n",
    "    plt.title(\"Per iteration accuracy\", fontsize=17);\n",
    "    plt.legend(['Actual','Shuffled'], fontsize=15)\n",
    "    plt.xlabel(\"Accuracy\", fontsize=15);\n",
    "    plt.ylabel(\"Percent\", fontsize=15);\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.boxplot([regr_acc_l, rand_acc_l]);\n",
    "    plt.xticks(ticks = [1,2], labels = [\"Actual\",\"Shuffled\"],fontsize=14);\n",
    "    plt.title(\"LSTM with condition embedding layer\");\n",
    "    plt.show()\n",
    "\n",
    "    res_df = pd.DataFrame(columns = [\"Actual\",\"Shuffled\"])\n",
    "    res_df[\"Actual\"] = regr_acc_l\n",
    "    res_df[\"Shuffled\"] = rand_acc_l\n",
    "    res_df[\"Iter_num\"] = res_df.index\n",
    "    melted_res_df = pd.melt(res_df, id_vars = 'Iter_num', value_name = \"acc\", var_name = \"iter_type\");\n",
    "    sns.relplot(x=\"Iter_num\", y=\"acc\", hue=\"iter_type\", kind=\"line\", data=melted_res_df);\n",
    "    plt.show()\n",
    "\n",
    "    draw_stars_box(regr_acc_l, rand_acc_l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}