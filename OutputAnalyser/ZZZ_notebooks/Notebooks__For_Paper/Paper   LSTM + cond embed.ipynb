{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/orenkobo/Desktop/PhD/Aim1/Aim1/OutputsAnalyser/ZZZ_notebooks/Notebooks __For_Paper\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "!pwd\n",
    "#10 mins training time (local cpu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-07 10:35:19.447564\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 10:35:30.765787: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.keras import backend as K\n",
    "print(K._get_available_gpus())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "scale_col = \"x_gaze_location_standard_scaled\"\n",
    "\n",
    "def apply_phq_cutoff(df , neg_phq_cutoff, pos_phq_cutoff):\n",
    "    df[\"phq_binary_label\"] = [0.0 if x <= neg_phq_cutoff else 1.0 if x >= pos_phq_cutoff else \"other\" for x in df.phq_score]\n",
    "    df = df[df.phq_binary_label!= 'other']\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_timecols_df_for_DL(fn =\"/Users/orenkobo/Desktop/PhD_new/repos/HebLingStudy/notebooks/df.csv\",\n",
    "                           scale_col = scale_col):\n",
    "\n",
    "    import string, re\n",
    "    print(f\"{datetime.datetime.now()} Reading csv from {fn}\")\n",
    "    df = pd.read_csv(fn,\n",
    "                     index_col=None,\n",
    "                     converters={#'alephbert_enc': eval,\n",
    "                         scale_col : eval,\n",
    "                         # 'x_gaze_location_minmax_scaled' : eval,\n",
    "                         # 'x_gaze_location_standard_scaled' : eval,\n",
    "                         # 'target_word_x_range' : eval\n",
    "                         # 'phq_label': bool\n",
    "                     })\n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "    df = df[df.Sentence_type != 'F'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    id_cols = [\"phq_score\",\"phq_group\",\"Subject\", \"Sentence_type\",\n",
    "               \"sentence_pupil_diameter_mean\",\"set_num\"]\n",
    "    # vec_size = 3500\n",
    "    # new_colname = f\"x_gaze_location_{vec_size}\"\n",
    "    cols = [f\"timepoint#{i}\" for i in range(875)]\n",
    "    # df[new_colname] = df[\"x_gaze_location_standard_scaled\"].apply(lambda x : x[:vec_size])\n",
    "    timeseries_df = pd.DataFrame(data = df[scale_col].to_list() , columns = cols)\n",
    "    timeseries_df[id_cols] = df[id_cols]\n",
    "    timeseries_df = timeseries_df.iloc[:,200:]\n",
    "    cols = [x for x in timeseries_df.columns if \"timepoint\" in x]\n",
    "    return timeseries_df, cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-07 10:35:33.760801 Reading csv from /Users/orenkobo/Desktop/PhD/HebLingStudy/ts_data/Artifacts2/df_new_full__unsegmented_alldata_new_FINAL.csv\n",
      "(9696, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      timepoint#200  timepoint#201  timepoint#202  timepoint#203  \\\n0          1.249265       1.243258       1.251267       1.258274   \n1         -0.605616      -0.604615      -0.602613      -0.590601   \n2          0.127175       0.133185       0.121164       0.099127   \n3         -1.144817      -1.155843      -1.149829      -1.117755   \n4         -1.554761      -1.571787      -1.577796      -1.608843   \n...             ...            ...            ...            ...   \n3227      -1.686295      -1.706332      -1.697315      -2.352532   \n3228       0.986135       0.998149       0.987137       0.977125   \n3229       1.003421       1.015438       0.504710       0.345483   \n3230       1.746672       1.754684       1.759692       1.738660   \n3231       0.598087       0.606101       0.585063       0.581056   \n\n      timepoint#204  timepoint#205  timepoint#206  timepoint#207  \\\n0          1.247262       1.240255       1.239254       1.251267   \n1         -1.061078      -1.648674      -1.700727      -1.695722   \n2          0.104136       0.115154       0.122166       0.124169   \n3         -1.106730      -1.129783      -1.135797      -1.111741   \n4         -1.600831      -1.571787      -1.558767      -1.560770   \n...             ...            ...            ...            ...   \n3227      -2.500808      -2.447709      -2.421661      -2.419657   \n3228       0.984133       0.992142       0.991141       0.995146   \n3229       0.339475       0.340476       0.351492       0.363509   \n3230       1.737658       1.736657       1.737658       1.742666   \n3231       0.590072       0.594080       0.608105       0.594080   \n\n      timepoint#208  timepoint#209  ...  Subject  Sentence_type  \\\n0          1.243258       1.240255  ...        3              A   \n1         -1.703730      -1.710737  ...        3              B   \n2          0.135188       0.161232  ...        3              D   \n3         -1.109737      -1.127778  ...        3              A   \n4         -1.565778      -1.573790  ...        3              B   \n...             ...            ...  ...      ...            ...   \n3227      -2.425668      -2.450715  ...      139              D   \n3228       0.976124       0.978126  ...      139              D   \n3229       0.364510       0.377529  ...      139              A   \n3230       1.323024       1.368093  ...      139              C   \n3231       0.600091       0.603096  ...      139              C   \n\n      sentence_pupil_diameter_mean  set_num  phq_binary_label  A  B  C  D  \\\n0                      5110.630668       17               0.0  1  0  0  0   \n1                      4974.146741        5               0.0  0  1  0  0   \n2                      4739.278462       12               0.0  0  0  0  1   \n3                      4775.260020        6               0.0  1  0  0  0   \n4                      4746.720839       26               0.0  0  1  0  0   \n...                            ...      ...               ... .. .. .. ..   \n3227                   5117.994088        0               1.0  0  0  0  1   \n3228                   4995.187626       15               1.0  0  0  0  1   \n3229                   4934.199434       27               1.0  1  0  0  0   \n3230                   5056.427875        4               1.0  0  0  1  0   \n3231                   5069.907967       13               1.0  0  0  1  0   \n\n      encoded_cond  \n0                0  \n1                1  \n2                3  \n3                0  \n4                1  \n...            ...  \n3227             3  \n3228             3  \n3229             0  \n3230             2  \n3231             2  \n\n[3232 rows x 687 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timepoint#200</th>\n      <th>timepoint#201</th>\n      <th>timepoint#202</th>\n      <th>timepoint#203</th>\n      <th>timepoint#204</th>\n      <th>timepoint#205</th>\n      <th>timepoint#206</th>\n      <th>timepoint#207</th>\n      <th>timepoint#208</th>\n      <th>timepoint#209</th>\n      <th>...</th>\n      <th>Subject</th>\n      <th>Sentence_type</th>\n      <th>sentence_pupil_diameter_mean</th>\n      <th>set_num</th>\n      <th>phq_binary_label</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>encoded_cond</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.249265</td>\n      <td>1.243258</td>\n      <td>1.251267</td>\n      <td>1.258274</td>\n      <td>1.247262</td>\n      <td>1.240255</td>\n      <td>1.239254</td>\n      <td>1.251267</td>\n      <td>1.243258</td>\n      <td>1.240255</td>\n      <td>...</td>\n      <td>3</td>\n      <td>A</td>\n      <td>5110.630668</td>\n      <td>17</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.605616</td>\n      <td>-0.604615</td>\n      <td>-0.602613</td>\n      <td>-0.590601</td>\n      <td>-1.061078</td>\n      <td>-1.648674</td>\n      <td>-1.700727</td>\n      <td>-1.695722</td>\n      <td>-1.703730</td>\n      <td>-1.710737</td>\n      <td>...</td>\n      <td>3</td>\n      <td>B</td>\n      <td>4974.146741</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.127175</td>\n      <td>0.133185</td>\n      <td>0.121164</td>\n      <td>0.099127</td>\n      <td>0.104136</td>\n      <td>0.115154</td>\n      <td>0.122166</td>\n      <td>0.124169</td>\n      <td>0.135188</td>\n      <td>0.161232</td>\n      <td>...</td>\n      <td>3</td>\n      <td>D</td>\n      <td>4739.278462</td>\n      <td>12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.144817</td>\n      <td>-1.155843</td>\n      <td>-1.149829</td>\n      <td>-1.117755</td>\n      <td>-1.106730</td>\n      <td>-1.129783</td>\n      <td>-1.135797</td>\n      <td>-1.111741</td>\n      <td>-1.109737</td>\n      <td>-1.127778</td>\n      <td>...</td>\n      <td>3</td>\n      <td>A</td>\n      <td>4775.260020</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.554761</td>\n      <td>-1.571787</td>\n      <td>-1.577796</td>\n      <td>-1.608843</td>\n      <td>-1.600831</td>\n      <td>-1.571787</td>\n      <td>-1.558767</td>\n      <td>-1.560770</td>\n      <td>-1.565778</td>\n      <td>-1.573790</td>\n      <td>...</td>\n      <td>3</td>\n      <td>B</td>\n      <td>4746.720839</td>\n      <td>26</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3227</th>\n      <td>-1.686295</td>\n      <td>-1.706332</td>\n      <td>-1.697315</td>\n      <td>-2.352532</td>\n      <td>-2.500808</td>\n      <td>-2.447709</td>\n      <td>-2.421661</td>\n      <td>-2.419657</td>\n      <td>-2.425668</td>\n      <td>-2.450715</td>\n      <td>...</td>\n      <td>139</td>\n      <td>D</td>\n      <td>5117.994088</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3228</th>\n      <td>0.986135</td>\n      <td>0.998149</td>\n      <td>0.987137</td>\n      <td>0.977125</td>\n      <td>0.984133</td>\n      <td>0.992142</td>\n      <td>0.991141</td>\n      <td>0.995146</td>\n      <td>0.976124</td>\n      <td>0.978126</td>\n      <td>...</td>\n      <td>139</td>\n      <td>D</td>\n      <td>4995.187626</td>\n      <td>15</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3229</th>\n      <td>1.003421</td>\n      <td>1.015438</td>\n      <td>0.504710</td>\n      <td>0.345483</td>\n      <td>0.339475</td>\n      <td>0.340476</td>\n      <td>0.351492</td>\n      <td>0.363509</td>\n      <td>0.364510</td>\n      <td>0.377529</td>\n      <td>...</td>\n      <td>139</td>\n      <td>A</td>\n      <td>4934.199434</td>\n      <td>27</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3230</th>\n      <td>1.746672</td>\n      <td>1.754684</td>\n      <td>1.759692</td>\n      <td>1.738660</td>\n      <td>1.737658</td>\n      <td>1.736657</td>\n      <td>1.737658</td>\n      <td>1.742666</td>\n      <td>1.323024</td>\n      <td>1.368093</td>\n      <td>...</td>\n      <td>139</td>\n      <td>C</td>\n      <td>5056.427875</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3231</th>\n      <td>0.598087</td>\n      <td>0.606101</td>\n      <td>0.585063</td>\n      <td>0.581056</td>\n      <td>0.590072</td>\n      <td>0.594080</td>\n      <td>0.608105</td>\n      <td>0.594080</td>\n      <td>0.600091</td>\n      <td>0.603096</td>\n      <td>...</td>\n      <td>139</td>\n      <td>C</td>\n      <td>5069.907967</td>\n      <td>13</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>3232 rows × 687 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {}\n",
    "# df_fn = \"/export/home/orenkobo/Aim1/paper_analysis/Artifacts/df_new_full__unsegmented_alldata_new_FINAL_paparanalysis.csv\"\n",
    "df_fn = \"/Users/orenkobo/Desktop/PhD/HebLingStudy/ts_data/Artifacts2/df_new_full__unsegmented_alldata_new_FINAL.csv\"\n",
    "# et_scale_col = \"x_gaze_location_rescaled\"\n",
    "et_scale_col = \"x_gaze_location_standard_scaled\"\n",
    "override_cutoff = [7,8]\n",
    "df, timepoint_cols = get_timecols_df_for_DL(fn =df_fn, scale_col = scale_col)\n",
    "df = apply_phq_cutoff(df,\n",
    "                      neg_phq_cutoff = override_cutoff[0],\n",
    "                      pos_phq_cutoff = override_cutoff[1])\n",
    "\n",
    "\n",
    "cond_df = pd.get_dummies(df['Sentence_type'])\n",
    "cond_cols = cond_df.columns.tolist()\n",
    "df = pd.concat([df, cond_df],axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df['encoded_cond'] = LabelEncoder().fit_transform(df['Sentence_type'])\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3232, 675)\n",
      "(1427, 675)\n",
      "(3232, 675)\n"
     ]
    }
   ],
   "source": [
    "print(df[timepoint_cols].shape)\n",
    "print(df[timepoint_cols].dropna().shape)\n",
    "df[timepoint_cols] = df[timepoint_cols].ffill()\n",
    "print(df[timepoint_cols].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def generate_3d_ds(df, feats = timepoint_cols):\n",
    "    data_3d = []\n",
    "\n",
    "    labels = []\n",
    "    # print(f\"{datetime.datetime.now()} - DS generated Start\")\n",
    "    for idx , row in df.iterrows():\n",
    "        # if (idx % 500) == 0:\n",
    "        #     print(idx)\n",
    "        l = []\n",
    "        for col in feats:\n",
    "            l.append([row[col]] + [row['encoded_cond']])\n",
    "        data_3d.append(l)\n",
    "        labels.append(row[\"phq_binary_label\"])\n",
    "    X_input = np.asarray(data_3d)\n",
    "    X_input_reshaped = np.swapaxes(X_input,1,2)\n",
    "    # print(f\"{datetime.datetime.now()} - DS generated Done\")\n",
    "\n",
    "    return X_input_reshaped, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def calc_per_subj_pred(pred, n=32):\n",
    "    if type(pred) != list:\n",
    "        pred = [x[0] for x in pred]\n",
    "    c = [pred[i * n:(i + 1) * n] for i in range((len(pred) + n - 1) // n )]\n",
    "    l = pd.DataFrame(c).mean(axis=1)\n",
    "    return l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=16, restore_best_weights=True)]\n",
    "\n",
    "def train_fold(X_train, y_train, X_val, y_val, voc_size=4):\n",
    "\n",
    "    inp1 = layers.Input(shape=(1, 675))  # TensorShape([None, 2, 100])\n",
    "    inp2 = layers.Input(shape=(1, 675))  # TensorShape([None, 1, 100])\n",
    "    x2 = layers.Embedding(input_dim=voc_size, output_dim=8)(inp2)  # TensorShape([None, 1, 100, 8])\n",
    "    x2_reshaped = tf.transpose(tf.squeeze(x2, axis=1), [0, 2, 1])  # TensorShape([None, 8, 100])\n",
    "    x = layers.concatenate([inp1, x2_reshaped], axis=1)\n",
    "    x = layers.LSTM(32, activation='relu',\n",
    "                    # kernel_regularizer=tf.keras.regularizers.l1(0.001),\n",
    "                    activity_regularizer=tf.keras.regularizers.l1(0.01)\n",
    "                    )(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(8, activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                    activity_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "                    )(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=[x])\n",
    "\n",
    "    print(\"A1 : \", datetime.datetime.now())\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['acc']\n",
    "    )\n",
    "\n",
    "    train_inp_gaze = X_train[:, :1, :]\n",
    "    train_inp_cond = X_train[:, 1:, :]\n",
    "    val_inp_gaze = X_val[:, :1, :]\n",
    "    val_inp_cond = X_val[:, 1:, :]\n",
    "\n",
    "\n",
    "\n",
    "    his = model.fit(epochs=20,\n",
    "              x=[train_inp_gaze, train_inp_cond], y=np.array(y_train).astype('float'),\n",
    "              validation_data = ([val_inp_gaze, val_inp_cond], np.array(y_val).astype('float')),\n",
    "                    callbacks = callbacks)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "\n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupShuffleSplit, LeavePGroupsOut\n",
    "num_iters = 500\n",
    "n_test_subjs = 10\n",
    "\n",
    "def rl(df):\n",
    "    ids = df[\"Subject\"].unique()\n",
    "    random.shuffle(ids)\n",
    "    df = df.set_index(\"Subject\").loc[ids].reset_index()\n",
    "    return df\n",
    "\n",
    "def run_model(df, randomize_labels = False):\n",
    "    # lpgo1 = LeavePGroupsOut(n_groups=10)\n",
    "    res_dict = {}\n",
    "    i = 0\n",
    "\n",
    "    lpgo1 = GroupShuffleSplit(n_splits=num_iters, test_size=n_test_subjs, random_state=7)\n",
    "    print(f\"{datetime.datetime.now()} : Start\")\n",
    "\n",
    "    if randomize_labels:\n",
    "        df = rl(df)\n",
    "    groups1 = df['Subject']\n",
    "\n",
    "    for tmp_index, test_index in lpgo1.split(X = df[timepoint_cols] , y = df['phq_binary_label'], groups = groups1):\n",
    "        if i==num_iters:\n",
    "            break\n",
    "        res_dict[i] = {}\n",
    "\n",
    "        lpgo2 = LeavePGroupsOut(n_groups=n_test_subjs)\n",
    "        # q = lpgo2.get_n_splits(groups = df.Subject)\n",
    "        # print(q)\n",
    "        # return\n",
    "        # lpgo2 = GroupShuffleSplit(n_splits=num_iters, test_size=n_test_subjs, random_state=i)\n",
    "        test_subjects = list(np.unique(groups1.iloc[test_index]))\n",
    "        test_df = df.iloc[test_index]\n",
    "        tmp_df = df.iloc[tmp_index]\n",
    "        groups2 = tmp_df['Subject']\n",
    "        # print(f\"{groups1.iloc[tmp_index].nunique()} temp subjects :  {list(np.unique(groups1.iloc[tmp_index]))}\")\n",
    "        # folds = list(lpgo2.split(X = tmp_df[timepoint_cols] ,\n",
    "        #                     y = tmp_df['phq_binary_label'],\n",
    "        #                     groups = groups2))\n",
    "        # X_shuffled, y_shuffled, groups_shuffled = shuffle(tmp_df[timepoint_cols] ,\n",
    "        #                                                   tmp_df['phq_binary_label'] ,\n",
    "        #                                                   groups2, random_state=0)\n",
    "        # folds = lpgo2.split(X = X_shuffled[timepoint_cols] ,\n",
    "        #                     y = y_shuffled,\n",
    "        #                     groups = groups_shuffled)\n",
    "        folds = lpgo2.split(X = tmp_df[timepoint_cols] ,\n",
    "                            y = tmp_df['phq_binary_label'],\n",
    "                            groups = groups2)\n",
    "        print(\"a\")\n",
    "        train_index, val_index = next(folds)\n",
    "        train_subjects = list(np.unique(groups2.iloc[train_index]))\n",
    "        val_subjects = list(np.unique(groups2.iloc[val_index]))\n",
    "        train_df = tmp_df.iloc[train_index]\n",
    "        val_df = tmp_df.iloc[val_index]\n",
    "        # for fold_i, (train_index, val_index) in enumerate(folds):\n",
    "            # train_subjects = list(np.unique(groups2.iloc[train_index]))\n",
    "            # val_subjects = list(np.unique(groups2.iloc[val_index]))\n",
    "            # train_df = tmp_df.iloc[train_index]\n",
    "            # val_df = tmp_df.iloc[val_index]\n",
    "            # break\n",
    "        X_train, y_train = generate_3d_ds(train_df)\n",
    "        X_test, y_test = generate_3d_ds(test_df)\n",
    "        X_val, y_val = generate_3d_ds(val_df)\n",
    "\n",
    "        print(f\"{datetime.datetime.now(): Train Fold #{i}}\")\n",
    "        assert ( len(list(set(train_subjects) & set(test_subjects))) == 0)\n",
    "        assert ( len(list(set(val_subjects) & set(test_subjects))) == 0)\n",
    "        assert ( len(list(set(val_subjects) & set(train_subjects))) == 0)\n",
    "        fold_model = train_fold(X_train, y_train, X_val, y_val)\n",
    "        fold_eval = fold_model.evaluate([X_test[:, :1, :], X_test[:, 1:, :]], np.array(y_test).astype('float'))\n",
    "        fold_test_pred = fold_model.predict([X_test[:, :1, :], X_test[:, 1:, :]])\n",
    "        print(\"Test eval is \" , fold_eval)\n",
    "        res_dict[i][\"eval\"] = fold_eval[1]\n",
    "        res_dict[i][\"test_subjects\"] = test_subjects\n",
    "        res_dict[i][\"train_subjects\"] = train_subjects\n",
    "        res_dict[i][\"val_subjects\"] = val_subjects\n",
    "        res_dict[i][\"test_pred\"] = [x[0] for x in fold_test_pred]\n",
    "        res_dict[i][\"test_true\"] = list(np.array(y_test).astype('float'))\n",
    "        print(\"Shape of pred is \" , fold_test_pred.shape)\n",
    "        res_dict[i][\"per_subject_mean_pred\"] = calc_per_subj_pred(fold_test_pred)\n",
    "        print(\"Shape of per_subject_mean_pred\" , res_dict[i][\"per_subject_mean_pred\"].shape)\n",
    "        res_dict[i][\"per_subject_mean_label\"] = calc_per_subj_pred(y_test)\n",
    "        res_dict[i][\"per_subject_is_success\"] = [True if round(p)==round(t) else False for p,t in\n",
    "                                                 zip(res_dict[i][\"per_subject_mean_pred\"],\n",
    "                                                     res_dict[i][\"per_subject_mean_label\"])]\n",
    "        res_dict[i][\"subj_level_acc\"] = sum(res_dict[i][\"per_subject_is_success\"]) / len(res_dict[i][\"per_subject_is_success\"])\n",
    "        print(f\"{datetime.datetime.now()}: Finished Train Fold #{i}/{num_iters} - thus far subj acc is \"\n",
    "              f\"{np.mean([res_dict[x]['subj_level_acc'] for x in range(i)])} and regular acc is\"\n",
    "              f\"{np.mean([res_dict[x]['eval'] for x in range(i)])}\\n Randomize Labels = {randomize_labels}\")\n",
    "        i+=1\n",
    "    return res_dict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-07 21:45:18.076710 : Start\n",
      "a\n",
      " Train Fold #0\n",
      "A1 :  2022-04-07 21:45:42.884899\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.8018 - acc: 0.5170 - val_loss: 0.7701 - val_acc: 0.5031\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7480 - acc: 0.5305 - val_loss: 0.7350 - val_acc: 0.4469\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7186 - acc: 0.5463 - val_loss: 0.7220 - val_acc: 0.4437\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6884 - acc: 0.5829 - val_loss: 0.7463 - val_acc: 0.4625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6672 - acc: 0.6161 - val_loss: 0.8169 - val_acc: 0.4375\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6409 - acc: 0.6582 - val_loss: 0.7793 - val_acc: 0.4875\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6256 - acc: 0.6647 - val_loss: 0.8294 - val_acc: 0.5031\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5967 - acc: 0.7072 - val_loss: 0.8765 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5702 - acc: 0.7184 - val_loss: 0.8915 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5569 - acc: 0.7458 - val_loss: 1.0005 - val_acc: 0.4812\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5157 - acc: 0.7805 - val_loss: 1.1152 - val_acc: 0.4938\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4881 - acc: 0.7928 - val_loss: 1.2348 - val_acc: 0.4750\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4702 - acc: 0.8175 - val_loss: 1.1943 - val_acc: 0.5094\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4622 - acc: 0.8187 - val_loss: 1.2306 - val_acc: 0.4844\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4214 - acc: 0.8492 - val_loss: 1.2611 - val_acc: 0.5031\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4130 - acc: 0.8615 - val_loss: 1.2020 - val_acc: 0.4906\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4087 - acc: 0.8615 - val_loss: 1.2347 - val_acc: 0.5094\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3830 - acc: 0.8746 - val_loss: 1.4348 - val_acc: 0.4812\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3713 - acc: 0.8881 - val_loss: 1.3532 - val_acc: 0.4938\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7128 - acc: 0.6500\n",
      "Test eval is  [0.712788462638855, 0.6499999761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:45:56.121147: Finished Train Fold #0/500 - thus far subj acc is nan and regular acc isnan\n",
      " Randomize Labels = False\n",
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orenkobo/Desktop/PhD/Aim1/Aim1/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/orenkobo/Desktop/PhD/Aim1/Aim1/venv/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Fold #1\n",
      "A1 :  2022-04-07 21:46:20.570563\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7848 - acc: 0.5405 - val_loss: 0.7610 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7326 - acc: 0.5432 - val_loss: 0.7363 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7024 - acc: 0.5421 - val_loss: 0.7248 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6844 - acc: 0.5436 - val_loss: 0.7254 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6719 - acc: 0.5517 - val_loss: 0.7133 - val_acc: 0.4719\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6612 - acc: 0.6030 - val_loss: 0.7246 - val_acc: 0.5094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6441 - acc: 0.6454 - val_loss: 0.7398 - val_acc: 0.5406\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.6304 - acc: 0.6686 - val_loss: 0.7461 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6161 - acc: 0.6937 - val_loss: 0.7445 - val_acc: 0.5156\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5967 - acc: 0.7176 - val_loss: 0.7807 - val_acc: 0.4625\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5883 - acc: 0.7288 - val_loss: 0.7636 - val_acc: 0.5656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5667 - acc: 0.7539 - val_loss: 0.7800 - val_acc: 0.5281\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5507 - acc: 0.7720 - val_loss: 0.7746 - val_acc: 0.5531\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5312 - acc: 0.7836 - val_loss: 0.7894 - val_acc: 0.5562\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5286 - acc: 0.7921 - val_loss: 0.8494 - val_acc: 0.5750\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5125 - acc: 0.7998 - val_loss: 0.8142 - val_acc: 0.5656\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5127 - acc: 0.7886 - val_loss: 0.9650 - val_acc: 0.5406\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5130 - acc: 0.7878 - val_loss: 0.9566 - val_acc: 0.5562\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4905 - acc: 0.8005 - val_loss: 0.9551 - val_acc: 0.5375\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4937 - acc: 0.8125 - val_loss: 1.0472 - val_acc: 0.5625\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4946 - acc: 0.4531\n",
      "Test eval is  [1.494581937789917, 0.453125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:46:34.646023: Finished Train Fold #1/500 - thus far subj acc is 0.7 and regular acc is0.6499999761581421\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #2\n",
      "A1 :  2022-04-07 21:46:58.430885\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7941 - acc: 0.5332 - val_loss: 0.7642 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7413 - acc: 0.5563 - val_loss: 0.7296 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7132 - acc: 0.5610 - val_loss: 0.7123 - val_acc: 0.4969\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6942 - acc: 0.5930 - val_loss: 0.7098 - val_acc: 0.4688\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6810 - acc: 0.5995 - val_loss: 0.7216 - val_acc: 0.4750\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6717 - acc: 0.6107 - val_loss: 0.7337 - val_acc: 0.4719\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6629 - acc: 0.6350 - val_loss: 0.7634 - val_acc: 0.5063\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6497 - acc: 0.6505 - val_loss: 0.7842 - val_acc: 0.4750\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6394 - acc: 0.6613 - val_loss: 0.8612 - val_acc: 0.4938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6316 - acc: 0.6701 - val_loss: 0.8605 - val_acc: 0.4844\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6258 - acc: 0.6705 - val_loss: 0.8990 - val_acc: 0.5125\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6014 - acc: 0.7037 - val_loss: 0.8846 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5990 - acc: 0.7052 - val_loss: 0.8641 - val_acc: 0.4844\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5866 - acc: 0.7253 - val_loss: 0.9257 - val_acc: 0.4812\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5670 - acc: 0.7384 - val_loss: 1.0939 - val_acc: 0.4906\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5516 - acc: 0.7577 - val_loss: 0.9194 - val_acc: 0.4844\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5485 - acc: 0.7627 - val_loss: 1.1230 - val_acc: 0.4656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5231 - acc: 0.7816 - val_loss: 1.0970 - val_acc: 0.4531\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5069 - acc: 0.7955 - val_loss: 1.1105 - val_acc: 0.5063\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4801 - acc: 0.8148 - val_loss: 1.1158 - val_acc: 0.4500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7417 - acc: 0.2906\n",
      "Test eval is  [0.7417057156562805, 0.2906250059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:47:11.828341: Finished Train Fold #2/500 - thus far subj acc is 0.55 and regular acc is0.551562488079071\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #3\n",
      "A1 :  2022-04-07 21:47:36.907022\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7832 - acc: 0.5444 - val_loss: 0.7569 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7352 - acc: 0.5432 - val_loss: 0.7277 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7041 - acc: 0.5432 - val_loss: 0.7114 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6892 - acc: 0.5432 - val_loss: 0.7026 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6722 - acc: 0.5432 - val_loss: 0.6973 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6546 - acc: 0.5505 - val_loss: 0.7206 - val_acc: 0.5281\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6384 - acc: 0.6478 - val_loss: 0.7195 - val_acc: 0.5469\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6193 - acc: 0.6782 - val_loss: 0.7338 - val_acc: 0.5219\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6057 - acc: 0.7022 - val_loss: 0.7364 - val_acc: 0.5375\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5797 - acc: 0.7353 - val_loss: 0.7532 - val_acc: 0.5625\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5617 - acc: 0.7635 - val_loss: 0.7676 - val_acc: 0.5656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5409 - acc: 0.7789 - val_loss: 0.7812 - val_acc: 0.5375\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5248 - acc: 0.7882 - val_loss: 0.7931 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5167 - acc: 0.7921 - val_loss: 0.8155 - val_acc: 0.5562\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4866 - acc: 0.8241 - val_loss: 0.9041 - val_acc: 0.5469\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4778 - acc: 0.8275 - val_loss: 0.8345 - val_acc: 0.5625\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4563 - acc: 0.8441 - val_loss: 0.8136 - val_acc: 0.5625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4498 - acc: 0.8434 - val_loss: 0.9379 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4478 - acc: 0.8434 - val_loss: 0.8702 - val_acc: 0.5406\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4434 - acc: 0.8434 - val_loss: 0.9427 - val_acc: 0.5500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0736 - acc: 0.5437\n",
      "Test eval is  [1.0735887289047241, 0.543749988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:47:50.055427: Finished Train Fold #3/500 - thus far subj acc is 0.46666666666666673 and regular acc is0.46458332737286884\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #4\n",
      "A1 :  2022-04-07 21:48:13.304051\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7994 - acc: 0.5505 - val_loss: 0.7726 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7421 - acc: 0.5556 - val_loss: 0.7369 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7070 - acc: 0.5556 - val_loss: 0.7174 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6829 - acc: 0.5556 - val_loss: 0.7092 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6631 - acc: 0.5648 - val_loss: 0.7402 - val_acc: 0.4781\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6440 - acc: 0.5976 - val_loss: 0.7561 - val_acc: 0.5219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6250 - acc: 0.6694 - val_loss: 0.7453 - val_acc: 0.4938\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5979 - acc: 0.7049 - val_loss: 0.7700 - val_acc: 0.5437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5765 - acc: 0.7303 - val_loss: 0.8162 - val_acc: 0.5344\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5451 - acc: 0.7631 - val_loss: 0.8290 - val_acc: 0.5219\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5095 - acc: 0.8036 - val_loss: 0.8288 - val_acc: 0.5500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4986 - acc: 0.8121 - val_loss: 0.8826 - val_acc: 0.5813\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4694 - acc: 0.8302 - val_loss: 0.8805 - val_acc: 0.5437\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4472 - acc: 0.8492 - val_loss: 0.8729 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4316 - acc: 0.8542 - val_loss: 1.0593 - val_acc: 0.5375\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4184 - acc: 0.8592 - val_loss: 0.9723 - val_acc: 0.5156\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4083 - acc: 0.8677 - val_loss: 1.0509 - val_acc: 0.4750\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3869 - acc: 0.8877 - val_loss: 1.0871 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3734 - acc: 0.8920 - val_loss: 1.1339 - val_acc: 0.5125\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3771 - acc: 0.8862 - val_loss: 1.0692 - val_acc: 0.5094\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7436 - acc: 0.3000\n",
      "Test eval is  [0.7435722351074219, 0.30000001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:48:26.674916: Finished Train Fold #4/500 - thus far subj acc is 0.45000000000000007 and regular acc is0.4843749925494194\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #5\n",
      "A1 :  2022-04-07 21:48:49.647529\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7930 - acc: 0.5336 - val_loss: 0.7682 - val_acc: 0.3750\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7389 - acc: 0.5505 - val_loss: 0.7420 - val_acc: 0.3875\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7080 - acc: 0.5621 - val_loss: 0.7448 - val_acc: 0.3625\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6862 - acc: 0.5883 - val_loss: 0.7733 - val_acc: 0.3562\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6712 - acc: 0.5895 - val_loss: 0.8300 - val_acc: 0.3750\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6515 - acc: 0.6262 - val_loss: 0.8126 - val_acc: 0.3750\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6355 - acc: 0.6435 - val_loss: 0.8443 - val_acc: 0.4375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6100 - acc: 0.6682 - val_loss: 0.8359 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5806 - acc: 0.7076 - val_loss: 0.9153 - val_acc: 0.4844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5440 - acc: 0.7315 - val_loss: 0.9281 - val_acc: 0.4781\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5176 - acc: 0.7566 - val_loss: 1.0497 - val_acc: 0.4500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4774 - acc: 0.7936 - val_loss: 1.0535 - val_acc: 0.4750\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4579 - acc: 0.8202 - val_loss: 1.0417 - val_acc: 0.4812\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4155 - acc: 0.8372 - val_loss: 1.1587 - val_acc: 0.4812\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4068 - acc: 0.8546 - val_loss: 1.2386 - val_acc: 0.4906\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3760 - acc: 0.8715 - val_loss: 1.2153 - val_acc: 0.4875\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3613 - acc: 0.8746 - val_loss: 1.3561 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3531 - acc: 0.8827 - val_loss: 1.1518 - val_acc: 0.5375\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 0.6125\n",
      "Test eval is  [0.7294542193412781, 0.612500011920929]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:49:01.872302: Finished Train Fold #5/500 - thus far subj acc is 0.42000000000000004 and regular acc is0.4474999964237213\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #6\n",
      "A1 :  2022-04-07 21:49:24.801311\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7834 - acc: 0.5336 - val_loss: 0.7567 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7367 - acc: 0.5494 - val_loss: 0.7290 - val_acc: 0.4969\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7081 - acc: 0.5783 - val_loss: 0.7447 - val_acc: 0.4187\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6896 - acc: 0.5806 - val_loss: 0.7648 - val_acc: 0.4344\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6730 - acc: 0.6127 - val_loss: 0.7981 - val_acc: 0.4563\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6551 - acc: 0.6327 - val_loss: 0.8562 - val_acc: 0.4688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6427 - acc: 0.6562 - val_loss: 0.8229 - val_acc: 0.4563\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6088 - acc: 0.6860 - val_loss: 0.8388 - val_acc: 0.5437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5855 - acc: 0.7157 - val_loss: 0.8926 - val_acc: 0.5312\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5528 - acc: 0.7477 - val_loss: 0.9602 - val_acc: 0.5125\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5418 - acc: 0.7596 - val_loss: 0.9884 - val_acc: 0.5156\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5043 - acc: 0.7975 - val_loss: 1.0323 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4791 - acc: 0.8175 - val_loss: 0.9738 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4516 - acc: 0.8360 - val_loss: 1.0077 - val_acc: 0.5125\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4217 - acc: 0.8580 - val_loss: 1.0129 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4092 - acc: 0.8696 - val_loss: 1.0649 - val_acc: 0.5406\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3859 - acc: 0.8792 - val_loss: 1.1882 - val_acc: 0.5250\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3668 - acc: 0.8904 - val_loss: 1.2811 - val_acc: 0.5094\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7331 - acc: 0.4437\n",
      "Test eval is  [0.733142077922821, 0.4437499940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:49:36.755495: Finished Train Fold #6/500 - thus far subj acc is 0.45 and regular acc is0.47499999900658924\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #7\n",
      "A1 :  2022-04-07 21:49:59.694421\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7838 - acc: 0.5212 - val_loss: 0.7573 - val_acc: 0.4969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7375 - acc: 0.5231 - val_loss: 0.7263 - val_acc: 0.4844\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7067 - acc: 0.5826 - val_loss: 0.7405 - val_acc: 0.4750\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6870 - acc: 0.5880 - val_loss: 0.7358 - val_acc: 0.4844\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6615 - acc: 0.6273 - val_loss: 0.7177 - val_acc: 0.4938\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6321 - acc: 0.6620 - val_loss: 0.7374 - val_acc: 0.5469\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6142 - acc: 0.6767 - val_loss: 0.7633 - val_acc: 0.5656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5780 - acc: 0.7103 - val_loss: 0.8201 - val_acc: 0.5531\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5348 - acc: 0.7415 - val_loss: 0.8607 - val_acc: 0.5188\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5230 - acc: 0.7550 - val_loss: 0.8917 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4874 - acc: 0.7917 - val_loss: 0.9062 - val_acc: 0.5656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4560 - acc: 0.8121 - val_loss: 0.9716 - val_acc: 0.5094\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4225 - acc: 0.8306 - val_loss: 1.0374 - val_acc: 0.4750\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4052 - acc: 0.8410 - val_loss: 1.0077 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3939 - acc: 0.8565 - val_loss: 1.2229 - val_acc: 0.4750\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3677 - acc: 0.8665 - val_loss: 1.1229 - val_acc: 0.4688\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3439 - acc: 0.8881 - val_loss: 1.1122 - val_acc: 0.5281\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3321 - acc: 0.8920 - val_loss: 1.1817 - val_acc: 0.5188\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3002 - acc: 0.9032 - val_loss: 1.4875 - val_acc: 0.4656\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3183 - acc: 0.9032 - val_loss: 1.2897 - val_acc: 0.5063\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2734 - acc: 0.5063\n",
      "Test eval is  [1.2733848094940186, 0.5062500238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:50:13.406251: Finished Train Fold #7/500 - thus far subj acc is 0.4428571428571429 and regular acc is0.4705357125827244\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #8\n",
      "A1 :  2022-04-07 21:50:37.358630\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7966 - acc: 0.5212 - val_loss: 0.7683 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7425 - acc: 0.5309 - val_loss: 0.7296 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7070 - acc: 0.5301 - val_loss: 0.7152 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6865 - acc: 0.5278 - val_loss: 0.7051 - val_acc: 0.5531\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6673 - acc: 0.6030 - val_loss: 0.6969 - val_acc: 0.5344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6571 - acc: 0.6204 - val_loss: 0.6936 - val_acc: 0.5437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6439 - acc: 0.6624 - val_loss: 0.7258 - val_acc: 0.5094\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6238 - acc: 0.6879 - val_loss: 0.7556 - val_acc: 0.4688\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6060 - acc: 0.7079 - val_loss: 0.8179 - val_acc: 0.4812\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5843 - acc: 0.7207 - val_loss: 0.8012 - val_acc: 0.5031\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5707 - acc: 0.7407 - val_loss: 0.8555 - val_acc: 0.4656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5529 - acc: 0.7535 - val_loss: 0.8769 - val_acc: 0.5063\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5289 - acc: 0.7674 - val_loss: 0.8807 - val_acc: 0.4875\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5229 - acc: 0.7774 - val_loss: 0.9729 - val_acc: 0.4781\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4986 - acc: 0.7940 - val_loss: 1.0919 - val_acc: 0.4594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4830 - acc: 0.8071 - val_loss: 0.9870 - val_acc: 0.4969\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4576 - acc: 0.8268 - val_loss: 1.2111 - val_acc: 0.4750\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4618 - acc: 0.8233 - val_loss: 0.9784 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4518 - acc: 0.8345 - val_loss: 1.1186 - val_acc: 0.4781\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4352 - acc: 0.8449 - val_loss: 1.1773 - val_acc: 0.4969\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0952 - acc: 0.5125\n",
      "Test eval is  [1.0952084064483643, 0.512499988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:50:51.279285: Finished Train Fold #8/500 - thus far subj acc is 0.425 and regular acc is0.4750000014901161\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #9\n",
      "A1 :  2022-04-07 21:51:14.419604\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7934 - acc: 0.5262 - val_loss: 0.7682 - val_acc: 0.3750\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7432 - acc: 0.5409 - val_loss: 0.7344 - val_acc: 0.4187\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7117 - acc: 0.5725 - val_loss: 0.7119 - val_acc: 0.5844\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6842 - acc: 0.6003 - val_loss: 0.7118 - val_acc: 0.5531\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6624 - acc: 0.6381 - val_loss: 0.7101 - val_acc: 0.5656\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6376 - acc: 0.6655 - val_loss: 0.7195 - val_acc: 0.5875\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5980 - acc: 0.7033 - val_loss: 0.7778 - val_acc: 0.5375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5781 - acc: 0.7137 - val_loss: 0.8311 - val_acc: 0.5125\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5475 - acc: 0.7519 - val_loss: 0.8337 - val_acc: 0.5219\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5215 - acc: 0.7701 - val_loss: 0.8254 - val_acc: 0.5688\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5076 - acc: 0.7894 - val_loss: 0.8126 - val_acc: 0.5688\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4656 - acc: 0.8187 - val_loss: 0.9698 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4429 - acc: 0.8306 - val_loss: 0.9823 - val_acc: 0.5437\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4279 - acc: 0.8418 - val_loss: 0.8575 - val_acc: 0.5938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4063 - acc: 0.8603 - val_loss: 1.0274 - val_acc: 0.5344\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3727 - acc: 0.8762 - val_loss: 1.1062 - val_acc: 0.5750\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3533 - acc: 0.8924 - val_loss: 1.2044 - val_acc: 0.5063\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3463 - acc: 0.8951 - val_loss: 1.1109 - val_acc: 0.5469\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3532 - acc: 0.8862 - val_loss: 1.1778 - val_acc: 0.5375\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3152 - acc: 0.9186 - val_loss: 1.2974 - val_acc: 0.5031\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3320 - acc: 0.4531\n",
      "Test eval is  [1.3319551944732666, 0.453125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:51:27.799398: Finished Train Fold #9/500 - thus far subj acc is 0.43333333333333335 and regular acc is0.4791666666666667\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #10\n",
      "A1 :  2022-04-07 21:51:50.745715\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7884 - acc: 0.5679 - val_loss: 0.7840 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7340 - acc: 0.5679 - val_loss: 0.7538 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7009 - acc: 0.5679 - val_loss: 0.7341 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6798 - acc: 0.5679 - val_loss: 0.7215 - val_acc: 0.4000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6573 - acc: 0.5679 - val_loss: 0.7194 - val_acc: 0.4000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6336 - acc: 0.5679 - val_loss: 0.7337 - val_acc: 0.4000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6149 - acc: 0.6590 - val_loss: 0.7368 - val_acc: 0.5375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5978 - acc: 0.7033 - val_loss: 0.7171 - val_acc: 0.5719\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5778 - acc: 0.7299 - val_loss: 0.7339 - val_acc: 0.5813\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5502 - acc: 0.7635 - val_loss: 0.8130 - val_acc: 0.5750\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5319 - acc: 0.7878 - val_loss: 0.7981 - val_acc: 0.5688\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5148 - acc: 0.7978 - val_loss: 0.9216 - val_acc: 0.5656\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4929 - acc: 0.8113 - val_loss: 0.8285 - val_acc: 0.6000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4852 - acc: 0.8117 - val_loss: 0.8927 - val_acc: 0.5562\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4750 - acc: 0.8125 - val_loss: 1.1115 - val_acc: 0.5562\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4716 - acc: 0.8160 - val_loss: 0.8865 - val_acc: 0.5406\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4431 - acc: 0.8457 - val_loss: 1.0169 - val_acc: 0.5531\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4313 - acc: 0.8476 - val_loss: 0.9361 - val_acc: 0.5719\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4024 - acc: 0.8684 - val_loss: 0.9764 - val_acc: 0.5688\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4235 - acc: 0.8549 - val_loss: 0.9515 - val_acc: 0.5656\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5536 - acc: 0.4313\n",
      "Test eval is  [1.5536129474639893, 0.4312500059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:52:04.104915: Finished Train Fold #10/500 - thus far subj acc is 0.44000000000000006 and regular acc is0.4765625\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #11\n",
      "A1 :  2022-04-07 21:52:27.069893\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7960 - acc: 0.5332 - val_loss: 0.7684 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7393 - acc: 0.5386 - val_loss: 0.7445 - val_acc: 0.4781\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7026 - acc: 0.5818 - val_loss: 0.7315 - val_acc: 0.5219\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6673 - acc: 0.6397 - val_loss: 0.7980 - val_acc: 0.4531\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6312 - acc: 0.6593 - val_loss: 0.7942 - val_acc: 0.4719\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5926 - acc: 0.7311 - val_loss: 0.8909 - val_acc: 0.4625\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5690 - acc: 0.7396 - val_loss: 0.8889 - val_acc: 0.4844\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5252 - acc: 0.7731 - val_loss: 0.8676 - val_acc: 0.5437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4975 - acc: 0.8009 - val_loss: 1.0025 - val_acc: 0.5594\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4739 - acc: 0.8252 - val_loss: 1.0195 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4351 - acc: 0.8422 - val_loss: 1.0132 - val_acc: 0.5063\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4017 - acc: 0.8742 - val_loss: 1.0516 - val_acc: 0.5594\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3908 - acc: 0.8754 - val_loss: 1.1710 - val_acc: 0.5562\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3617 - acc: 0.8927 - val_loss: 1.0795 - val_acc: 0.5625\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3594 - acc: 0.8881 - val_loss: 1.0944 - val_acc: 0.5594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3333 - acc: 0.9051 - val_loss: 1.1321 - val_acc: 0.5063\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.3306 - acc: 0.9035 - val_loss: 1.1050 - val_acc: 0.5375\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.3087 - acc: 0.9174 - val_loss: 1.2102 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3037 - acc: 0.9167 - val_loss: 1.2159 - val_acc: 0.5031\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7612 - acc: 0.4875\n",
      "Test eval is  [0.7612417936325073, 0.48750001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:52:40.053362: Finished Train Fold #11/500 - thus far subj acc is 0.43636363636363645 and regular acc is0.47244318236004224\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #12\n",
      "A1 :  2022-04-07 21:53:03.078892\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7863 - acc: 0.5332 - val_loss: 0.7569 - val_acc: 0.5031\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7372 - acc: 0.5328 - val_loss: 0.7320 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7106 - acc: 0.5606 - val_loss: 0.7151 - val_acc: 0.5312\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6826 - acc: 0.5706 - val_loss: 0.7350 - val_acc: 0.4906\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6639 - acc: 0.6003 - val_loss: 0.7332 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6348 - acc: 0.6505 - val_loss: 0.7540 - val_acc: 0.5406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6121 - acc: 0.6856 - val_loss: 0.7468 - val_acc: 0.5875\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5753 - acc: 0.7288 - val_loss: 0.8361 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5358 - acc: 0.7681 - val_loss: 0.8274 - val_acc: 0.5844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5064 - acc: 0.7890 - val_loss: 0.8422 - val_acc: 0.5813\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4669 - acc: 0.8279 - val_loss: 0.8626 - val_acc: 0.5750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4430 - acc: 0.8345 - val_loss: 0.8407 - val_acc: 0.5594\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4327 - acc: 0.8453 - val_loss: 0.9647 - val_acc: 0.5969\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4099 - acc: 0.8546 - val_loss: 1.0452 - val_acc: 0.5719\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3867 - acc: 0.8831 - val_loss: 0.9507 - val_acc: 0.5844\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3584 - acc: 0.8958 - val_loss: 1.1234 - val_acc: 0.5719\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3429 - acc: 0.8962 - val_loss: 1.0490 - val_acc: 0.5813\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3154 - acc: 0.9113 - val_loss: 1.1172 - val_acc: 0.5969\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3083 - acc: 0.9213 - val_loss: 1.1120 - val_acc: 0.5906\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7217 - acc: 0.4656\n",
      "Test eval is  [0.7216826677322388, 0.46562498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:53:15.749355: Finished Train Fold #12/500 - thus far subj acc is 0.4416666666666667 and regular acc is0.4736979181567828\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #13\n",
      "A1 :  2022-04-07 21:53:38.877696\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7935 - acc: 0.5486 - val_loss: 0.7701 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7413 - acc: 0.5432 - val_loss: 0.7445 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7123 - acc: 0.5428 - val_loss: 0.7294 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6964 - acc: 0.5478 - val_loss: 0.7220 - val_acc: 0.4000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6783 - acc: 0.5752 - val_loss: 0.7462 - val_acc: 0.3688\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6610 - acc: 0.5880 - val_loss: 0.7592 - val_acc: 0.3938\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6401 - acc: 0.6103 - val_loss: 0.8157 - val_acc: 0.4656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6257 - acc: 0.6389 - val_loss: 0.8280 - val_acc: 0.5469\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5975 - acc: 0.6790 - val_loss: 0.7818 - val_acc: 0.5031\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5713 - acc: 0.7184 - val_loss: 0.8274 - val_acc: 0.5250\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5596 - acc: 0.7427 - val_loss: 0.8328 - val_acc: 0.5156\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5288 - acc: 0.7577 - val_loss: 0.8954 - val_acc: 0.5375\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4989 - acc: 0.7901 - val_loss: 0.9140 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4852 - acc: 0.8098 - val_loss: 1.0535 - val_acc: 0.5219\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4676 - acc: 0.8214 - val_loss: 0.9410 - val_acc: 0.5406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4345 - acc: 0.8522 - val_loss: 1.0894 - val_acc: 0.5156\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4186 - acc: 0.8584 - val_loss: 1.1157 - val_acc: 0.5125\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4039 - acc: 0.8742 - val_loss: 1.1936 - val_acc: 0.5344\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4005 - acc: 0.8812 - val_loss: 1.2528 - val_acc: 0.5031\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.3901 - acc: 0.8796 - val_loss: 1.1816 - val_acc: 0.5125\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7092 - acc: 0.5000\n",
      "Test eval is  [0.7091705203056335, 0.5]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:53:54.227602: Finished Train Fold #13/500 - thus far subj acc is 0.4538461538461539 and regular acc is0.47307692353542036\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #14\n",
      "A1 :  2022-04-07 21:54:19.619748\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7914 - acc: 0.5424 - val_loss: 0.7645 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7374 - acc: 0.5378 - val_loss: 0.7368 - val_acc: 0.4844\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7063 - acc: 0.5718 - val_loss: 0.7309 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6808 - acc: 0.6030 - val_loss: 0.8813 - val_acc: 0.5219\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6577 - acc: 0.6377 - val_loss: 0.7722 - val_acc: 0.5219\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6188 - acc: 0.6979 - val_loss: 0.8148 - val_acc: 0.5156\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5856 - acc: 0.7334 - val_loss: 0.8638 - val_acc: 0.5469\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5457 - acc: 0.7755 - val_loss: 0.9019 - val_acc: 0.5312\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5253 - acc: 0.7990 - val_loss: 0.8475 - val_acc: 0.5125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4938 - acc: 0.8229 - val_loss: 0.9322 - val_acc: 0.5219\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4725 - acc: 0.8337 - val_loss: 0.9726 - val_acc: 0.5906\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4372 - acc: 0.8627 - val_loss: 1.0045 - val_acc: 0.5406\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4147 - acc: 0.8738 - val_loss: 1.0324 - val_acc: 0.5750\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3921 - acc: 0.8889 - val_loss: 1.0519 - val_acc: 0.5406\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3879 - acc: 0.8819 - val_loss: 0.9924 - val_acc: 0.5375\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3620 - acc: 0.9024 - val_loss: 1.1118 - val_acc: 0.5156\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3388 - acc: 0.9198 - val_loss: 1.0911 - val_acc: 0.5656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3267 - acc: 0.9213 - val_loss: 1.2227 - val_acc: 0.5406\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3176 - acc: 0.9213 - val_loss: 1.2983 - val_acc: 0.5500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7550 - acc: 0.4969\n",
      "Test eval is  [0.7549657225608826, 0.49687498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:54:32.267402: Finished Train Fold #14/500 - thus far subj acc is 0.4571428571428572 and regular acc is0.47500000042574747\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #15\n",
      "A1 :  2022-04-07 21:54:55.305126\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7949 - acc: 0.5212 - val_loss: 0.7636 - val_acc: 0.4781\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7439 - acc: 0.5359 - val_loss: 0.7266 - val_acc: 0.6531\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7147 - acc: 0.5729 - val_loss: 0.7049 - val_acc: 0.6750\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6967 - acc: 0.5683 - val_loss: 0.7124 - val_acc: 0.5031\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6783 - acc: 0.5856 - val_loss: 0.7122 - val_acc: 0.5375\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6580 - acc: 0.6188 - val_loss: 0.7650 - val_acc: 0.4781\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6447 - acc: 0.6605 - val_loss: 0.7380 - val_acc: 0.5375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6115 - acc: 0.6809 - val_loss: 0.7810 - val_acc: 0.5406\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5746 - acc: 0.7130 - val_loss: 0.7936 - val_acc: 0.5437\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5623 - acc: 0.7373 - val_loss: 0.7853 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5321 - acc: 0.7542 - val_loss: 0.8432 - val_acc: 0.5469\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4979 - acc: 0.7847 - val_loss: 0.8704 - val_acc: 0.5531\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4623 - acc: 0.8102 - val_loss: 0.9684 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4595 - acc: 0.8225 - val_loss: 0.9057 - val_acc: 0.5344\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4228 - acc: 0.8488 - val_loss: 1.1354 - val_acc: 0.4812\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3992 - acc: 0.8584 - val_loss: 1.1406 - val_acc: 0.5312\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3831 - acc: 0.8677 - val_loss: 1.0005 - val_acc: 0.5750\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3583 - acc: 0.8823 - val_loss: 1.2313 - val_acc: 0.5406\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3337 - acc: 0.8958 - val_loss: 1.4553 - val_acc: 0.4719\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7220 - acc: 0.3656\n",
      "Test eval is  [0.721966564655304, 0.3656249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:55:07.995706: Finished Train Fold #15/500 - thus far subj acc is 0.46 and regular acc is0.476458332935969\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #16\n",
      "A1 :  2022-04-07 21:55:30.811114\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7881 - acc: 0.5367 - val_loss: 0.7716 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7372 - acc: 0.5556 - val_loss: 0.7449 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7074 - acc: 0.5667 - val_loss: 0.7423 - val_acc: 0.4406\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6770 - acc: 0.6119 - val_loss: 0.7854 - val_acc: 0.4250\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6462 - acc: 0.6562 - val_loss: 0.7878 - val_acc: 0.5281\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6087 - acc: 0.7025 - val_loss: 0.8585 - val_acc: 0.4906\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5700 - acc: 0.7388 - val_loss: 0.9130 - val_acc: 0.5031\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5270 - acc: 0.7739 - val_loss: 0.9197 - val_acc: 0.5125\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4876 - acc: 0.8009 - val_loss: 0.9556 - val_acc: 0.5375\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4632 - acc: 0.8167 - val_loss: 1.0794 - val_acc: 0.5031\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4360 - acc: 0.8434 - val_loss: 1.0728 - val_acc: 0.5063\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3965 - acc: 0.8638 - val_loss: 1.1021 - val_acc: 0.5188\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3872 - acc: 0.8661 - val_loss: 1.1443 - val_acc: 0.5375\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3622 - acc: 0.8881 - val_loss: 1.2167 - val_acc: 0.5156\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3334 - acc: 0.9020 - val_loss: 1.2663 - val_acc: 0.5219\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3188 - acc: 0.9062 - val_loss: 1.2131 - val_acc: 0.5625\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.3149 - acc: 0.9090 - val_loss: 1.4897 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3094 - acc: 0.9059 - val_loss: 1.3395 - val_acc: 0.5250\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2829 - acc: 0.9282 - val_loss: 1.4290 - val_acc: 0.5344\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7372 - acc: 0.4250\n",
      "Test eval is  [0.7372366786003113, 0.42500001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:55:43.603378: Finished Train Fold #16/500 - thus far subj acc is 0.45625000000000004 and regular acc is0.46953124925494194\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #17\n",
      "A1 :  2022-04-07 21:56:06.643547\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7910 - acc: 0.5255 - val_loss: 0.7626 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7412 - acc: 0.5309 - val_loss: 0.7320 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7154 - acc: 0.5309 - val_loss: 0.7145 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6993 - acc: 0.5451 - val_loss: 0.7081 - val_acc: 0.4938\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6834 - acc: 0.5644 - val_loss: 0.7119 - val_acc: 0.4844\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6757 - acc: 0.5887 - val_loss: 0.7166 - val_acc: 0.4906\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6639 - acc: 0.6134 - val_loss: 0.7234 - val_acc: 0.5344\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6395 - acc: 0.6601 - val_loss: 0.7678 - val_acc: 0.5406\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6100 - acc: 0.6829 - val_loss: 0.8347 - val_acc: 0.5125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5900 - acc: 0.7126 - val_loss: 0.8573 - val_acc: 0.4969\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5695 - acc: 0.7284 - val_loss: 0.8992 - val_acc: 0.5469\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5314 - acc: 0.7596 - val_loss: 0.9462 - val_acc: 0.5375\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5029 - acc: 0.7959 - val_loss: 0.9597 - val_acc: 0.5219\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4894 - acc: 0.8044 - val_loss: 0.9403 - val_acc: 0.5312\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4650 - acc: 0.8264 - val_loss: 1.0222 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4498 - acc: 0.8364 - val_loss: 0.9952 - val_acc: 0.5469\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4232 - acc: 0.8661 - val_loss: 1.0204 - val_acc: 0.5344\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3985 - acc: 0.8727 - val_loss: 1.0020 - val_acc: 0.5375\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3852 - acc: 0.8897 - val_loss: 1.1171 - val_acc: 0.5375\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3772 - acc: 0.8989 - val_loss: 1.1297 - val_acc: 0.5312\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7161 - acc: 0.5125\n",
      "Test eval is  [0.7161077857017517, 0.512499988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:56:20.002736: Finished Train Fold #17/500 - thus far subj acc is 0.4529411764705883 and regular acc is0.46691176470588236\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #18\n",
      "A1 :  2022-04-07 21:56:43.051392\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7852 - acc: 0.5062 - val_loss: 0.7569 - val_acc: 0.4969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7377 - acc: 0.5490 - val_loss: 0.7260 - val_acc: 0.5437\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7080 - acc: 0.5810 - val_loss: 0.7392 - val_acc: 0.5188\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6873 - acc: 0.5992 - val_loss: 0.7873 - val_acc: 0.4875\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6710 - acc: 0.6300 - val_loss: 0.7790 - val_acc: 0.5094\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6492 - acc: 0.6508 - val_loss: 0.8049 - val_acc: 0.4406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6217 - acc: 0.6836 - val_loss: 0.8245 - val_acc: 0.4594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5894 - acc: 0.7207 - val_loss: 0.8266 - val_acc: 0.5156\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5566 - acc: 0.7508 - val_loss: 0.9842 - val_acc: 0.4531\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5254 - acc: 0.7828 - val_loss: 1.0440 - val_acc: 0.4750\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5012 - acc: 0.7975 - val_loss: 1.1304 - val_acc: 0.4437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4706 - acc: 0.8264 - val_loss: 1.0465 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4513 - acc: 0.8291 - val_loss: 1.1422 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4286 - acc: 0.8495 - val_loss: 1.1838 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4247 - acc: 0.8488 - val_loss: 1.1412 - val_acc: 0.4969\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3890 - acc: 0.8684 - val_loss: 1.2138 - val_acc: 0.4844\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3645 - acc: 0.8862 - val_loss: 1.2452 - val_acc: 0.5281\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3728 - acc: 0.8866 - val_loss: 1.2222 - val_acc: 0.5250\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7247 - acc: 0.5437\n",
      "Test eval is  [0.7247328162193298, 0.543749988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:56:55.164758: Finished Train Fold #18/500 - thus far subj acc is 0.4555555555555556 and regular acc is0.4694444437821706\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #19\n",
      "A1 :  2022-04-07 21:57:18.188718\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7885 - acc: 0.5305 - val_loss: 0.7611 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7368 - acc: 0.5521 - val_loss: 0.7379 - val_acc: 0.4875\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7055 - acc: 0.5664 - val_loss: 0.7350 - val_acc: 0.4750\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6762 - acc: 0.5845 - val_loss: 0.7544 - val_acc: 0.4313\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6617 - acc: 0.6030 - val_loss: 0.7545 - val_acc: 0.4344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6286 - acc: 0.6404 - val_loss: 0.9426 - val_acc: 0.4406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6088 - acc: 0.6655 - val_loss: 0.9644 - val_acc: 0.4031\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5747 - acc: 0.7188 - val_loss: 1.0243 - val_acc: 0.4219\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5485 - acc: 0.7419 - val_loss: 1.2023 - val_acc: 0.4500\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5196 - acc: 0.7674 - val_loss: 1.1624 - val_acc: 0.4500\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4877 - acc: 0.7948 - val_loss: 1.1458 - val_acc: 0.4437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4571 - acc: 0.8187 - val_loss: 1.3038 - val_acc: 0.4125\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4496 - acc: 0.8387 - val_loss: 1.1416 - val_acc: 0.4219\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4113 - acc: 0.8650 - val_loss: 1.2924 - val_acc: 0.4594\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4058 - acc: 0.8654 - val_loss: 1.1315 - val_acc: 0.4594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3704 - acc: 0.8773 - val_loss: 1.4624 - val_acc: 0.5031\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3351 - acc: 0.9047 - val_loss: 1.5485 - val_acc: 0.4812\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3163 - acc: 0.9136 - val_loss: 1.5421 - val_acc: 0.4437\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2958 - acc: 0.9232 - val_loss: 1.4783 - val_acc: 0.4406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7572 - acc: 0.3344\n",
      "Test eval is  [0.7571733593940735, 0.3343749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:57:30.701944: Finished Train Fold #19/500 - thus far subj acc is 0.46315789473684216 and regular acc is0.4733552619030601\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #20\n",
      "A1 :  2022-04-07 21:57:53.707462\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7949 - acc: 0.5177 - val_loss: 0.7642 - val_acc: 0.4969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7447 - acc: 0.5274 - val_loss: 0.7323 - val_acc: 0.4906\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7164 - acc: 0.5586 - val_loss: 0.7154 - val_acc: 0.5125\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6884 - acc: 0.6030 - val_loss: 0.7142 - val_acc: 0.5344\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6653 - acc: 0.6377 - val_loss: 0.7133 - val_acc: 0.5688\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6273 - acc: 0.6659 - val_loss: 0.8577 - val_acc: 0.4531\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6061 - acc: 0.6995 - val_loss: 0.7391 - val_acc: 0.5688\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5536 - acc: 0.7523 - val_loss: 0.8632 - val_acc: 0.5125\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5264 - acc: 0.7824 - val_loss: 0.8666 - val_acc: 0.4844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4919 - acc: 0.8036 - val_loss: 0.9347 - val_acc: 0.5344\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4538 - acc: 0.8295 - val_loss: 1.1175 - val_acc: 0.5125\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4269 - acc: 0.8492 - val_loss: 1.1130 - val_acc: 0.4969\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3897 - acc: 0.8765 - val_loss: 1.0969 - val_acc: 0.5156\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3669 - acc: 0.8916 - val_loss: 1.1219 - val_acc: 0.5312\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3537 - acc: 0.8974 - val_loss: 1.1917 - val_acc: 0.5125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3124 - acc: 0.9147 - val_loss: 1.2111 - val_acc: 0.5375\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3183 - acc: 0.9117 - val_loss: 1.3511 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2877 - acc: 0.9306 - val_loss: 1.3383 - val_acc: 0.5125\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2836 - acc: 0.9317 - val_loss: 1.3245 - val_acc: 0.5125\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2720 - acc: 0.9363 - val_loss: 1.3602 - val_acc: 0.5156\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5639 - acc: 0.5156\n",
      "Test eval is  [1.5639128684997559, 0.515625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:58:07.030196: Finished Train Fold #20/500 - thus far subj acc is 0.45500000000000007 and regular acc is0.4664062485098839\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #21\n",
      "A1 :  2022-04-07 21:58:30.037364\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.8015 - acc: 0.5150 - val_loss: 0.7703 - val_acc: 0.4594\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7474 - acc: 0.5579 - val_loss: 0.7343 - val_acc: 0.4656\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7164 - acc: 0.5594 - val_loss: 0.7202 - val_acc: 0.4812\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6907 - acc: 0.5876 - val_loss: 0.7649 - val_acc: 0.5063\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6761 - acc: 0.5953 - val_loss: 0.8146 - val_acc: 0.4688\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6536 - acc: 0.6173 - val_loss: 0.8208 - val_acc: 0.4812\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6228 - acc: 0.6620 - val_loss: 0.8279 - val_acc: 0.4781\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6027 - acc: 0.6944 - val_loss: 0.9028 - val_acc: 0.4625\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5818 - acc: 0.7172 - val_loss: 0.9757 - val_acc: 0.4531\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5454 - acc: 0.7361 - val_loss: 1.0430 - val_acc: 0.5094\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5128 - acc: 0.7712 - val_loss: 1.0701 - val_acc: 0.4406\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4960 - acc: 0.7828 - val_loss: 1.0741 - val_acc: 0.4969\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4755 - acc: 0.8005 - val_loss: 1.1750 - val_acc: 0.4594\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4465 - acc: 0.8245 - val_loss: 1.2595 - val_acc: 0.4688\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4278 - acc: 0.8368 - val_loss: 1.1225 - val_acc: 0.4688\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4078 - acc: 0.8607 - val_loss: 1.2896 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3869 - acc: 0.8711 - val_loss: 1.3663 - val_acc: 0.4563\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3757 - acc: 0.8765 - val_loss: 1.4794 - val_acc: 0.5281\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3611 - acc: 0.8808 - val_loss: 1.3112 - val_acc: 0.5219\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7123 - acc: 0.5406\n",
      "Test eval is  [0.7123487591743469, 0.5406249761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:58:42.645811: Finished Train Fold #21/500 - thus far subj acc is 0.4571428571428572 and regular acc is0.46874999858084176\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #22\n",
      "A1 :  2022-04-07 21:59:05.583601\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7939 - acc: 0.5336 - val_loss: 0.7660 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7431 - acc: 0.5312 - val_loss: 0.7336 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7160 - acc: 0.5305 - val_loss: 0.7160 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6953 - acc: 0.5309 - val_loss: 0.7132 - val_acc: 0.5063\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6803 - acc: 0.5509 - val_loss: 0.7169 - val_acc: 0.4844\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6564 - acc: 0.6208 - val_loss: 0.7470 - val_acc: 0.5125\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6268 - acc: 0.6674 - val_loss: 0.7889 - val_acc: 0.5063\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5898 - acc: 0.7137 - val_loss: 0.8187 - val_acc: 0.5469\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5505 - acc: 0.7558 - val_loss: 0.8684 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5203 - acc: 0.7716 - val_loss: 0.9749 - val_acc: 0.4844\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4900 - acc: 0.8056 - val_loss: 0.9373 - val_acc: 0.5063\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4712 - acc: 0.8179 - val_loss: 0.9809 - val_acc: 0.5156\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4339 - acc: 0.8360 - val_loss: 1.1748 - val_acc: 0.4906\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4117 - acc: 0.8557 - val_loss: 1.1730 - val_acc: 0.5125\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4030 - acc: 0.8650 - val_loss: 1.2605 - val_acc: 0.4656\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3757 - acc: 0.8789 - val_loss: 1.3287 - val_acc: 0.4781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3686 - acc: 0.8819 - val_loss: 1.2739 - val_acc: 0.4719\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3527 - acc: 0.8897 - val_loss: 1.1435 - val_acc: 0.4781\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3541 - acc: 0.8885 - val_loss: 1.3598 - val_acc: 0.4594\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3318 - acc: 0.8978 - val_loss: 1.5438 - val_acc: 0.4531\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7056 - acc: 0.5000\n",
      "Test eval is  [0.7056213617324829, 0.5]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:59:18.834275: Finished Train Fold #22/500 - thus far subj acc is 0.4636363636363637 and regular acc is0.47201704301617364\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #23\n",
      "A1 :  2022-04-07 21:59:41.909852\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7919 - acc: 0.5108 - val_loss: 0.7614 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7390 - acc: 0.5451 - val_loss: 0.7315 - val_acc: 0.5094\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7104 - acc: 0.5694 - val_loss: 0.7159 - val_acc: 0.5625\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6905 - acc: 0.6011 - val_loss: 0.7108 - val_acc: 0.5375\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6695 - acc: 0.6242 - val_loss: 0.7233 - val_acc: 0.4969\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6572 - acc: 0.6412 - val_loss: 0.7435 - val_acc: 0.5250\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6273 - acc: 0.6767 - val_loss: 0.7674 - val_acc: 0.5469\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6080 - acc: 0.6852 - val_loss: 0.7787 - val_acc: 0.5312\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5827 - acc: 0.7133 - val_loss: 0.8560 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5561 - acc: 0.7558 - val_loss: 0.8621 - val_acc: 0.5031\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5306 - acc: 0.7604 - val_loss: 0.8947 - val_acc: 0.5469\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5309 - acc: 0.7654 - val_loss: 0.8482 - val_acc: 0.5656\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5053 - acc: 0.7936 - val_loss: 0.9381 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4606 - acc: 0.8187 - val_loss: 1.1510 - val_acc: 0.4781\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4481 - acc: 0.8279 - val_loss: 1.1565 - val_acc: 0.4812\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4087 - acc: 0.8561 - val_loss: 1.1468 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4027 - acc: 0.8561 - val_loss: 1.1378 - val_acc: 0.4969\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4169 - acc: 0.8634 - val_loss: 1.0168 - val_acc: 0.5156\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3778 - acc: 0.8800 - val_loss: 1.2295 - val_acc: 0.4812\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3639 - acc: 0.8816 - val_loss: 1.6017 - val_acc: 0.4344\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6975 - acc: 0.4812\n",
      "Test eval is  [0.6974693536758423, 0.48124998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 21:59:55.046411: Finished Train Fold #23/500 - thus far subj acc is 0.46521739130434786 and regular acc is0.47323369331981824\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #24\n",
      "A1 :  2022-04-07 22:00:17.831117\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7755 - acc: 0.5475 - val_loss: 0.7515 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7323 - acc: 0.5440 - val_loss: 0.7253 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7014 - acc: 0.5490 - val_loss: 0.7108 - val_acc: 0.4906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6763 - acc: 0.5992 - val_loss: 0.7187 - val_acc: 0.5656\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6527 - acc: 0.6165 - val_loss: 0.7110 - val_acc: 0.5688\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6258 - acc: 0.6786 - val_loss: 0.7526 - val_acc: 0.5437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5987 - acc: 0.7056 - val_loss: 0.8247 - val_acc: 0.4906\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5688 - acc: 0.7261 - val_loss: 0.8782 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5281 - acc: 0.7650 - val_loss: 1.0074 - val_acc: 0.4625\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5019 - acc: 0.7924 - val_loss: 0.9813 - val_acc: 0.5000\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4866 - acc: 0.8121 - val_loss: 1.0708 - val_acc: 0.4688\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4548 - acc: 0.8306 - val_loss: 1.1758 - val_acc: 0.4750\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4219 - acc: 0.8588 - val_loss: 1.2497 - val_acc: 0.5094\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4042 - acc: 0.8584 - val_loss: 1.2031 - val_acc: 0.4750\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3911 - acc: 0.8750 - val_loss: 1.3392 - val_acc: 0.4969\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3526 - acc: 0.8939 - val_loss: 1.2306 - val_acc: 0.5125\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3435 - acc: 0.9012 - val_loss: 1.5381 - val_acc: 0.4688\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3621 - acc: 0.8897 - val_loss: 1.4048 - val_acc: 0.4594\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3294 - acc: 0.9090 - val_loss: 1.5094 - val_acc: 0.4406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7252 - acc: 0.4062\n",
      "Test eval is  [0.7251659631729126, 0.40625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:00:30.784616: Finished Train Fold #24/500 - thus far subj acc is 0.4666666666666666 and regular acc is0.4735677056014538\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #25\n",
      "A1 :  2022-04-07 22:00:53.756093\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 12ms/step - loss: 0.7901 - acc: 0.5309 - val_loss: 0.7606 - val_acc: 0.4781\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7399 - acc: 0.5606 - val_loss: 0.7377 - val_acc: 0.4437\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7092 - acc: 0.5621 - val_loss: 0.7357 - val_acc: 0.4938\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6874 - acc: 0.5849 - val_loss: 0.7562 - val_acc: 0.4969\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6697 - acc: 0.6119 - val_loss: 0.8899 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6475 - acc: 0.6454 - val_loss: 0.8773 - val_acc: 0.4938\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6266 - acc: 0.6775 - val_loss: 0.8463 - val_acc: 0.5188\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6040 - acc: 0.7010 - val_loss: 0.9027 - val_acc: 0.5437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5890 - acc: 0.7110 - val_loss: 0.8760 - val_acc: 0.5406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5609 - acc: 0.7461 - val_loss: 0.9602 - val_acc: 0.4875\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5385 - acc: 0.7635 - val_loss: 0.9701 - val_acc: 0.4906\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4981 - acc: 0.7940 - val_loss: 1.1004 - val_acc: 0.5281\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4850 - acc: 0.8048 - val_loss: 1.1228 - val_acc: 0.4594\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4749 - acc: 0.8079 - val_loss: 1.1974 - val_acc: 0.4750\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4445 - acc: 0.8356 - val_loss: 1.1060 - val_acc: 0.5063\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4121 - acc: 0.8453 - val_loss: 1.3222 - val_acc: 0.4563\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3946 - acc: 0.8600 - val_loss: 1.3632 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3898 - acc: 0.8630 - val_loss: 1.3028 - val_acc: 0.4969\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3801 - acc: 0.8719 - val_loss: 1.3851 - val_acc: 0.5219\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7193 - acc: 0.5406\n",
      "Test eval is  [0.7193111181259155, 0.5406249761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:01:06.194494: Finished Train Fold #25/500 - thus far subj acc is 0.46399999999999997 and regular acc is0.47087499737739563\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #26\n",
      "A1 :  2022-04-07 22:01:29.187727\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7811 - acc: 0.5316 - val_loss: 0.7661 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7335 - acc: 0.5343 - val_loss: 0.7460 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7031 - acc: 0.5509 - val_loss: 0.7306 - val_acc: 0.3656\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6795 - acc: 0.5876 - val_loss: 0.7713 - val_acc: 0.3625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6624 - acc: 0.6100 - val_loss: 0.7348 - val_acc: 0.4531\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6423 - acc: 0.6474 - val_loss: 0.7419 - val_acc: 0.4781\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6109 - acc: 0.6833 - val_loss: 0.7877 - val_acc: 0.5094\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5814 - acc: 0.7099 - val_loss: 0.8062 - val_acc: 0.5719\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5543 - acc: 0.7627 - val_loss: 0.7740 - val_acc: 0.5437\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5215 - acc: 0.7867 - val_loss: 0.8860 - val_acc: 0.5219\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4948 - acc: 0.7963 - val_loss: 0.8817 - val_acc: 0.5656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4733 - acc: 0.8260 - val_loss: 1.0840 - val_acc: 0.4719\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4330 - acc: 0.8488 - val_loss: 1.0921 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4210 - acc: 0.8522 - val_loss: 1.1123 - val_acc: 0.5156\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4018 - acc: 0.8688 - val_loss: 1.2014 - val_acc: 0.4906\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3610 - acc: 0.8954 - val_loss: 1.2311 - val_acc: 0.5094\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3464 - acc: 0.8997 - val_loss: 1.0940 - val_acc: 0.4906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3322 - acc: 0.9032 - val_loss: 1.3067 - val_acc: 0.4812\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3335 - acc: 0.9035 - val_loss: 1.3487 - val_acc: 0.4750\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7152 - acc: 0.5312\n",
      "Test eval is  [0.7152084112167358, 0.53125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:01:41.796403: Finished Train Fold #26/500 - thus far subj acc is 0.4653846153846154 and regular acc is0.4735576888689628\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #27\n",
      "A1 :  2022-04-07 22:02:05.099155\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7789 - acc: 0.5324 - val_loss: 0.7528 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7346 - acc: 0.5320 - val_loss: 0.7241 - val_acc: 0.4781\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7109 - acc: 0.5644 - val_loss: 0.7136 - val_acc: 0.4938\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6955 - acc: 0.5822 - val_loss: 0.7850 - val_acc: 0.4625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6783 - acc: 0.6030 - val_loss: 0.7937 - val_acc: 0.4781\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6603 - acc: 0.6408 - val_loss: 0.7926 - val_acc: 0.4875\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6380 - acc: 0.6655 - val_loss: 0.8140 - val_acc: 0.4844\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6057 - acc: 0.7006 - val_loss: 0.8274 - val_acc: 0.5156\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5690 - acc: 0.7446 - val_loss: 0.9192 - val_acc: 0.4781\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5259 - acc: 0.7812 - val_loss: 0.8888 - val_acc: 0.4969\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5085 - acc: 0.7894 - val_loss: 1.1141 - val_acc: 0.4594\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4584 - acc: 0.8221 - val_loss: 0.9953 - val_acc: 0.5156\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4424 - acc: 0.8360 - val_loss: 1.0717 - val_acc: 0.5344\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4017 - acc: 0.8623 - val_loss: 1.1004 - val_acc: 0.5188\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3846 - acc: 0.8688 - val_loss: 1.1724 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3614 - acc: 0.8835 - val_loss: 1.2062 - val_acc: 0.4906\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3468 - acc: 0.8912 - val_loss: 1.2920 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3199 - acc: 0.9074 - val_loss: 1.2520 - val_acc: 0.4844\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3196 - acc: 0.9147 - val_loss: 1.2723 - val_acc: 0.5188\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7061 - acc: 0.5625\n",
      "Test eval is  [0.7061084508895874, 0.5625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:02:17.622172: Finished Train Fold #27/500 - thus far subj acc is 0.4703703703703703 and regular acc is0.4756944411330753\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #28\n",
      "A1 :  2022-04-07 22:02:40.526701\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7974 - acc: 0.5370 - val_loss: 0.7690 - val_acc: 0.4812\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7443 - acc: 0.5583 - val_loss: 0.7453 - val_acc: 0.5344\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7131 - acc: 0.5814 - val_loss: 0.7633 - val_acc: 0.4594\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6868 - acc: 0.5922 - val_loss: 0.8488 - val_acc: 0.5312\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6671 - acc: 0.6289 - val_loss: 0.8041 - val_acc: 0.4969\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6456 - acc: 0.6597 - val_loss: 0.8171 - val_acc: 0.4688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6200 - acc: 0.6856 - val_loss: 0.8955 - val_acc: 0.4781\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5946 - acc: 0.7172 - val_loss: 0.9281 - val_acc: 0.5344\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5641 - acc: 0.7488 - val_loss: 1.0003 - val_acc: 0.5625\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5294 - acc: 0.7739 - val_loss: 1.1981 - val_acc: 0.5063\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5105 - acc: 0.7928 - val_loss: 1.0331 - val_acc: 0.5437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4636 - acc: 0.8279 - val_loss: 1.1057 - val_acc: 0.4781\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4532 - acc: 0.8383 - val_loss: 1.1332 - val_acc: 0.4844\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4238 - acc: 0.8557 - val_loss: 1.1247 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4133 - acc: 0.8557 - val_loss: 1.1124 - val_acc: 0.5219\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3816 - acc: 0.8773 - val_loss: 1.2904 - val_acc: 0.5250\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3728 - acc: 0.8873 - val_loss: 1.1758 - val_acc: 0.5625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3566 - acc: 0.8908 - val_loss: 1.2881 - val_acc: 0.5219\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7495 - acc: 0.4938\n",
      "Test eval is  [0.7495325803756714, 0.4937500059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:02:52.679674: Finished Train Fold #28/500 - thus far subj acc is 0.475 and regular acc is0.4787946396640369\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #29\n",
      "A1 :  2022-04-07 22:03:16.628707\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7997 - acc: 0.5374 - val_loss: 0.7896 - val_acc: 0.3000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7403 - acc: 0.5475 - val_loss: 0.7891 - val_acc: 0.3000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6986 - acc: 0.5791 - val_loss: 0.7838 - val_acc: 0.3094\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6742 - acc: 0.5895 - val_loss: 0.7614 - val_acc: 0.4406\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6409 - acc: 0.6404 - val_loss: 0.7430 - val_acc: 0.5469\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6103 - acc: 0.6960 - val_loss: 0.8769 - val_acc: 0.4781\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5881 - acc: 0.7037 - val_loss: 0.8935 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5581 - acc: 0.7384 - val_loss: 0.9438 - val_acc: 0.5281\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5209 - acc: 0.7766 - val_loss: 0.9591 - val_acc: 0.5406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4915 - acc: 0.7932 - val_loss: 1.1735 - val_acc: 0.4844\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4717 - acc: 0.8241 - val_loss: 0.9619 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4529 - acc: 0.8364 - val_loss: 1.0423 - val_acc: 0.5125\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4263 - acc: 0.8588 - val_loss: 1.1336 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3970 - acc: 0.8754 - val_loss: 1.3893 - val_acc: 0.4750\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3929 - acc: 0.8785 - val_loss: 1.2327 - val_acc: 0.5031\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3684 - acc: 0.8889 - val_loss: 1.2519 - val_acc: 0.5156\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3646 - acc: 0.8954 - val_loss: 1.3503 - val_acc: 0.5094\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3327 - acc: 0.9140 - val_loss: 1.4169 - val_acc: 0.4844\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3347 - acc: 0.9117 - val_loss: 1.3783 - val_acc: 0.4781\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3178 - acc: 0.9167 - val_loss: 1.5575 - val_acc: 0.4781\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6429 - acc: 0.4750\n",
      "Test eval is  [1.6429475545883179, 0.4749999940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:03:29.769727: Finished Train Fold #29/500 - thus far subj acc is 0.4689655172413793 and regular acc is0.4793103419501206\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #30\n",
      "A1 :  2022-04-07 22:03:52.896949\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7840 - acc: 0.5340 - val_loss: 0.7502 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7332 - acc: 0.5532 - val_loss: 0.7146 - val_acc: 0.5906\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7026 - acc: 0.5826 - val_loss: 0.7352 - val_acc: 0.4750\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6733 - acc: 0.6107 - val_loss: 0.7507 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6479 - acc: 0.6454 - val_loss: 0.8421 - val_acc: 0.4906\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6090 - acc: 0.6852 - val_loss: 0.9678 - val_acc: 0.4500\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5738 - acc: 0.7184 - val_loss: 0.8945 - val_acc: 0.4406\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5490 - acc: 0.7531 - val_loss: 1.0331 - val_acc: 0.4187\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4971 - acc: 0.8029 - val_loss: 1.1624 - val_acc: 0.4938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4715 - acc: 0.8067 - val_loss: 1.2718 - val_acc: 0.4344\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4495 - acc: 0.8275 - val_loss: 1.1817 - val_acc: 0.5031\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4229 - acc: 0.8434 - val_loss: 1.1914 - val_acc: 0.4750\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3937 - acc: 0.8769 - val_loss: 1.2994 - val_acc: 0.4656\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3755 - acc: 0.8823 - val_loss: 1.2172 - val_acc: 0.5031\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3695 - acc: 0.8823 - val_loss: 1.2613 - val_acc: 0.4781\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3467 - acc: 0.8904 - val_loss: 1.1876 - val_acc: 0.5281\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3355 - acc: 0.8978 - val_loss: 1.2746 - val_acc: 0.5219\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3058 - acc: 0.9147 - val_loss: 1.3619 - val_acc: 0.4906\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7673 - acc: 0.2969\n",
      "Test eval is  [0.76728355884552, 0.296875]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:04:05.147702: Finished Train Fold #30/500 - thus far subj acc is 0.47 and regular acc is0.4791666636864344\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #31\n",
      "A1 :  2022-04-07 22:04:28.619427\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7811 - acc: 0.5397 - val_loss: 0.7489 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7333 - acc: 0.5432 - val_loss: 0.7162 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7068 - acc: 0.5698 - val_loss: 0.7453 - val_acc: 0.5125\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6886 - acc: 0.5872 - val_loss: 0.7311 - val_acc: 0.5250\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6792 - acc: 0.5930 - val_loss: 0.7144 - val_acc: 0.5594\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6675 - acc: 0.6238 - val_loss: 0.7748 - val_acc: 0.5656\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6529 - acc: 0.6393 - val_loss: 0.7699 - val_acc: 0.5656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6312 - acc: 0.6566 - val_loss: 0.8155 - val_acc: 0.5813\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6096 - acc: 0.6883 - val_loss: 0.8271 - val_acc: 0.5531\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5845 - acc: 0.7157 - val_loss: 0.8487 - val_acc: 0.5312\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5517 - acc: 0.7338 - val_loss: 0.8798 - val_acc: 0.5625\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5187 - acc: 0.7627 - val_loss: 0.9597 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5019 - acc: 0.7701 - val_loss: 0.9023 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4719 - acc: 0.7959 - val_loss: 0.9899 - val_acc: 0.5219\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4490 - acc: 0.8102 - val_loss: 0.9512 - val_acc: 0.5562\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4383 - acc: 0.8071 - val_loss: 1.0590 - val_acc: 0.5094\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4036 - acc: 0.8326 - val_loss: 1.1913 - val_acc: 0.5531\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3829 - acc: 0.8480 - val_loss: 1.2420 - val_acc: 0.5250\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3880 - acc: 0.8515 - val_loss: 1.1089 - val_acc: 0.5156\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3547 - acc: 0.8696 - val_loss: 1.1652 - val_acc: 0.5312\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2943 - acc: 0.4719\n",
      "Test eval is  [1.2943308353424072, 0.47187501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:04:42.990952: Finished Train Fold #31/500 - thus far subj acc is 0.4645161290322581 and regular acc is0.47328628743848494\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #32\n",
      "A1 :  2022-04-07 22:05:05.939346\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7828 - acc: 0.5521 - val_loss: 0.7679 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7320 - acc: 0.5559 - val_loss: 0.7496 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7044 - acc: 0.5602 - val_loss: 0.7293 - val_acc: 0.4344\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6815 - acc: 0.5856 - val_loss: 0.7517 - val_acc: 0.4250\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6637 - acc: 0.6211 - val_loss: 0.7768 - val_acc: 0.4656\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6429 - acc: 0.6393 - val_loss: 0.7843 - val_acc: 0.4625\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6169 - acc: 0.6647 - val_loss: 0.7671 - val_acc: 0.5375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5835 - acc: 0.7033 - val_loss: 0.8173 - val_acc: 0.5437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5580 - acc: 0.7242 - val_loss: 0.8763 - val_acc: 0.5813\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5244 - acc: 0.7620 - val_loss: 0.8403 - val_acc: 0.5656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5043 - acc: 0.7785 - val_loss: 0.9088 - val_acc: 0.5188\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4568 - acc: 0.8179 - val_loss: 1.1278 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4442 - acc: 0.8245 - val_loss: 1.0524 - val_acc: 0.5219\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3976 - acc: 0.8561 - val_loss: 1.1345 - val_acc: 0.5312\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3793 - acc: 0.8650 - val_loss: 1.0866 - val_acc: 0.5406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3733 - acc: 0.8762 - val_loss: 1.0037 - val_acc: 0.5531\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.3757 - acc: 0.8700 - val_loss: 1.0311 - val_acc: 0.5594\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3367 - acc: 0.8854 - val_loss: 1.1468 - val_acc: 0.5406\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3114 - acc: 0.9062 - val_loss: 1.1475 - val_acc: 0.5594\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7924 - acc: 0.3594\n",
      "Test eval is  [0.7923722863197327, 0.359375]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:05:19.391936: Finished Train Fold #32/500 - thus far subj acc is 0.459375 and regular acc is0.4732421850785613\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #33\n",
      "A1 :  2022-04-07 22:05:43.755751\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7780 - acc: 0.5436 - val_loss: 0.7519 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7315 - acc: 0.5436 - val_loss: 0.7257 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7065 - acc: 0.5540 - val_loss: 0.7151 - val_acc: 0.4906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6906 - acc: 0.5602 - val_loss: 0.7172 - val_acc: 0.4750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6713 - acc: 0.5833 - val_loss: 0.7488 - val_acc: 0.4906\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6502 - acc: 0.6123 - val_loss: 0.8041 - val_acc: 0.5219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6320 - acc: 0.6508 - val_loss: 0.7644 - val_acc: 0.5688\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6081 - acc: 0.6998 - val_loss: 0.7734 - val_acc: 0.5281\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5781 - acc: 0.7184 - val_loss: 0.8766 - val_acc: 0.5219\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5556 - acc: 0.7365 - val_loss: 0.9212 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5209 - acc: 0.7681 - val_loss: 0.8872 - val_acc: 0.5219\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4914 - acc: 0.7878 - val_loss: 0.9521 - val_acc: 0.4875\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4699 - acc: 0.8048 - val_loss: 1.1067 - val_acc: 0.4594\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4332 - acc: 0.8318 - val_loss: 1.0484 - val_acc: 0.4812\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4188 - acc: 0.8495 - val_loss: 1.1212 - val_acc: 0.4750\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3940 - acc: 0.8557 - val_loss: 1.1641 - val_acc: 0.4812\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3923 - acc: 0.8526 - val_loss: 1.2588 - val_acc: 0.4594\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3821 - acc: 0.8615 - val_loss: 1.2720 - val_acc: 0.4437\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3603 - acc: 0.8796 - val_loss: 1.4391 - val_acc: 0.4344\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 0.4000\n",
      "Test eval is  [0.7429249882698059, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:05:56.464813: Finished Train Fold #33/500 - thus far subj acc is 0.4575757575757576 and regular acc is0.4697916643186049\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #34\n",
      "A1 :  2022-04-07 22:06:19.490319\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7867 - acc: 0.5359 - val_loss: 0.7584 - val_acc: 0.4906\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7337 - acc: 0.5401 - val_loss: 0.7236 - val_acc: 0.5188\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7037 - acc: 0.5945 - val_loss: 0.7163 - val_acc: 0.5156\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6850 - acc: 0.6169 - val_loss: 0.7228 - val_acc: 0.5562\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6607 - acc: 0.6242 - val_loss: 0.7123 - val_acc: 0.5437\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6257 - acc: 0.6794 - val_loss: 0.7739 - val_acc: 0.5688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6013 - acc: 0.7045 - val_loss: 0.8415 - val_acc: 0.5437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5635 - acc: 0.7500 - val_loss: 0.8455 - val_acc: 0.5719\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5353 - acc: 0.7674 - val_loss: 0.8779 - val_acc: 0.5719\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4941 - acc: 0.8029 - val_loss: 0.9602 - val_acc: 0.5437\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4729 - acc: 0.8206 - val_loss: 1.0256 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4506 - acc: 0.8364 - val_loss: 0.9727 - val_acc: 0.5594\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4263 - acc: 0.8499 - val_loss: 1.0807 - val_acc: 0.5375\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3986 - acc: 0.8704 - val_loss: 1.1025 - val_acc: 0.5406\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3928 - acc: 0.8746 - val_loss: 1.2307 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3859 - acc: 0.8866 - val_loss: 1.0381 - val_acc: 0.5969\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3506 - acc: 0.9001 - val_loss: 1.2203 - val_acc: 0.5500\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3392 - acc: 0.9101 - val_loss: 1.2172 - val_acc: 0.5406\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3224 - acc: 0.9201 - val_loss: 1.2403 - val_acc: 0.5719\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3065 - acc: 0.9236 - val_loss: 1.1795 - val_acc: 0.5531\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2635 - acc: 0.5281\n",
      "Test eval is  [1.2634648084640503, 0.528124988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:06:32.920992: Finished Train Fold #34/500 - thus far subj acc is 0.45588235294117646 and regular acc is0.46773896848454194\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #35\n",
      "A1 :  2022-04-07 22:06:55.839597\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 12ms/step - loss: 0.7915 - acc: 0.5247 - val_loss: 0.7595 - val_acc: 0.5875\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7399 - acc: 0.5336 - val_loss: 0.7239 - val_acc: 0.5969\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7128 - acc: 0.5517 - val_loss: 0.7121 - val_acc: 0.5906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6914 - acc: 0.5667 - val_loss: 0.7217 - val_acc: 0.5406\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6732 - acc: 0.6015 - val_loss: 0.7696 - val_acc: 0.5594\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6515 - acc: 0.6431 - val_loss: 0.8095 - val_acc: 0.5281\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6262 - acc: 0.6698 - val_loss: 0.9417 - val_acc: 0.5625\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5961 - acc: 0.7052 - val_loss: 0.8381 - val_acc: 0.5344\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5762 - acc: 0.7388 - val_loss: 0.9041 - val_acc: 0.5063\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5332 - acc: 0.7708 - val_loss: 0.9972 - val_acc: 0.4656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5125 - acc: 0.7948 - val_loss: 0.9648 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4793 - acc: 0.8110 - val_loss: 1.0580 - val_acc: 0.4563\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4559 - acc: 0.8279 - val_loss: 1.2039 - val_acc: 0.4281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4332 - acc: 0.8492 - val_loss: 1.1842 - val_acc: 0.4812\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4062 - acc: 0.8565 - val_loss: 1.2538 - val_acc: 0.4781\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3788 - acc: 0.8808 - val_loss: 1.2909 - val_acc: 0.4563\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3603 - acc: 0.8912 - val_loss: 1.3221 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3459 - acc: 0.9012 - val_loss: 1.3975 - val_acc: 0.4531\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3299 - acc: 0.9001 - val_loss: 1.1788 - val_acc: 0.5031\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.4031\n",
      "Test eval is  [0.7308400869369507, 0.40312498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:07:08.519425: Finished Train Fold #35/500 - thus far subj acc is 0.4542857142857143 and regular acc is0.46946428333009993\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #36\n",
      "A1 :  2022-04-07 22:07:31.919889\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7837 - acc: 0.5451 - val_loss: 0.7572 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7348 - acc: 0.5312 - val_loss: 0.7304 - val_acc: 0.4906\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7048 - acc: 0.5563 - val_loss: 0.7256 - val_acc: 0.4875\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6832 - acc: 0.5868 - val_loss: 0.7321 - val_acc: 0.4969\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6632 - acc: 0.6196 - val_loss: 0.7216 - val_acc: 0.5250\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6386 - acc: 0.6381 - val_loss: 0.7872 - val_acc: 0.5031\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6120 - acc: 0.6894 - val_loss: 0.7277 - val_acc: 0.5594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5797 - acc: 0.7261 - val_loss: 0.8208 - val_acc: 0.5437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.7708 - val_loss: 0.8683 - val_acc: 0.5312\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5104 - acc: 0.7901 - val_loss: 0.9066 - val_acc: 0.6000\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4878 - acc: 0.8133 - val_loss: 0.9431 - val_acc: 0.5781\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4541 - acc: 0.8399 - val_loss: 0.9624 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4359 - acc: 0.8538 - val_loss: 0.9793 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3966 - acc: 0.8723 - val_loss: 1.0440 - val_acc: 0.5500\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3809 - acc: 0.8870 - val_loss: 1.2308 - val_acc: 0.5594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3576 - acc: 0.8939 - val_loss: 1.0526 - val_acc: 0.6062\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3398 - acc: 0.9016 - val_loss: 1.1660 - val_acc: 0.5469\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3231 - acc: 0.9132 - val_loss: 1.1609 - val_acc: 0.5625\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3113 - acc: 0.9282 - val_loss: 1.1791 - val_acc: 0.5844\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2849 - acc: 0.9282 - val_loss: 1.1937 - val_acc: 0.5813\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.7093 - acc: 0.4094\n",
      "Test eval is  [1.709324836730957, 0.40937501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:07:54.035724: Finished Train Fold #36/500 - thus far subj acc is 0.4527777777777778 and regular acc is0.46762152512868244\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #37\n",
      "A1 :  2022-04-07 22:08:17.013619\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7909 - acc: 0.5154 - val_loss: 0.7635 - val_acc: 0.3906\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7415 - acc: 0.5243 - val_loss: 0.7315 - val_acc: 0.3969\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7153 - acc: 0.5424 - val_loss: 0.7405 - val_acc: 0.3906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6970 - acc: 0.5733 - val_loss: 0.7436 - val_acc: 0.3969\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6821 - acc: 0.5706 - val_loss: 0.7813 - val_acc: 0.3500\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6726 - acc: 0.5891 - val_loss: 0.8580 - val_acc: 0.3187\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6700 - acc: 0.6049 - val_loss: 0.9074 - val_acc: 0.3594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6519 - acc: 0.6281 - val_loss: 0.9311 - val_acc: 0.3375\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6404 - acc: 0.6443 - val_loss: 0.9156 - val_acc: 0.3500\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6225 - acc: 0.6701 - val_loss: 0.9473 - val_acc: 0.3719\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6112 - acc: 0.6856 - val_loss: 1.0184 - val_acc: 0.4219\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5804 - acc: 0.7211 - val_loss: 1.0314 - val_acc: 0.4719\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5644 - acc: 0.7442 - val_loss: 1.0024 - val_acc: 0.4719\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5419 - acc: 0.7631 - val_loss: 0.9681 - val_acc: 0.4688\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5081 - acc: 0.7971 - val_loss: 1.2058 - val_acc: 0.4281\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4865 - acc: 0.8121 - val_loss: 1.0938 - val_acc: 0.4656\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4850 - acc: 0.8098 - val_loss: 1.2571 - val_acc: 0.4094\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4568 - acc: 0.8345 - val_loss: 1.1930 - val_acc: 0.4344\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7196 - acc: 0.7000\n",
      "Test eval is  [0.719562828540802, 0.699999988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:08:29.071159: Finished Train Fold #37/500 - thus far subj acc is 0.44594594594594594 and regular acc is0.4660472950419864\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #38\n",
      "A1 :  2022-04-07 22:08:51.882212\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.8068 - acc: 0.5278 - val_loss: 0.7678 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7495 - acc: 0.5309 - val_loss: 0.7219 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7166 - acc: 0.5305 - val_loss: 0.7031 - val_acc: 0.6000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6898 - acc: 0.5363 - val_loss: 0.6942 - val_acc: 0.6000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6753 - acc: 0.5617 - val_loss: 0.6982 - val_acc: 0.5094\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6577 - acc: 0.6281 - val_loss: 0.7031 - val_acc: 0.4875\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6289 - acc: 0.6609 - val_loss: 0.7387 - val_acc: 0.4844\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6080 - acc: 0.6863 - val_loss: 0.7162 - val_acc: 0.4906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5811 - acc: 0.7068 - val_loss: 0.7573 - val_acc: 0.4938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5607 - acc: 0.7469 - val_loss: 0.7600 - val_acc: 0.5156\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5229 - acc: 0.7805 - val_loss: 0.9716 - val_acc: 0.4187\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5119 - acc: 0.7882 - val_loss: 0.9059 - val_acc: 0.5188\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4768 - acc: 0.8086 - val_loss: 1.0373 - val_acc: 0.4969\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4615 - acc: 0.8275 - val_loss: 0.9758 - val_acc: 0.5437\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4383 - acc: 0.8345 - val_loss: 1.0805 - val_acc: 0.5125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4128 - acc: 0.8526 - val_loss: 1.1708 - val_acc: 0.4938\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4029 - acc: 0.8642 - val_loss: 1.1312 - val_acc: 0.5188\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3939 - acc: 0.8646 - val_loss: 1.2057 - val_acc: 0.5406\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3784 - acc: 0.8765 - val_loss: 1.0880 - val_acc: 0.5250\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3653 - acc: 0.8823 - val_loss: 1.2492 - val_acc: 0.5125\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7286 - acc: 0.4000\n",
      "Test eval is  [0.7286210656166077, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:09:05.241117: Finished Train Fold #38/500 - thus far subj acc is 0.4526315789473684 and regular acc is0.4722039448587518\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #39\n",
      "A1 :  2022-04-07 22:09:28.965051\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7965 - acc: 0.5301 - val_loss: 0.7703 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7456 - acc: 0.5309 - val_loss: 0.7331 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7086 - acc: 0.5340 - val_loss: 0.7479 - val_acc: 0.4656\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6849 - acc: 0.5768 - val_loss: 0.7200 - val_acc: 0.4688\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6615 - acc: 0.6312 - val_loss: 0.7196 - val_acc: 0.5188\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6423 - acc: 0.6690 - val_loss: 0.7119 - val_acc: 0.5437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6237 - acc: 0.6867 - val_loss: 0.7462 - val_acc: 0.5156\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6044 - acc: 0.7106 - val_loss: 0.7529 - val_acc: 0.5031\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5852 - acc: 0.7276 - val_loss: 0.7604 - val_acc: 0.5063\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5591 - acc: 0.7384 - val_loss: 0.8334 - val_acc: 0.4875\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5400 - acc: 0.7604 - val_loss: 0.8218 - val_acc: 0.5375\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5162 - acc: 0.7828 - val_loss: 0.9001 - val_acc: 0.5156\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5017 - acc: 0.7913 - val_loss: 0.9683 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4818 - acc: 0.8160 - val_loss: 0.9303 - val_acc: 0.5219\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4524 - acc: 0.8318 - val_loss: 1.0312 - val_acc: 0.4969\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4374 - acc: 0.8453 - val_loss: 1.0435 - val_acc: 0.4969\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4122 - acc: 0.8561 - val_loss: 1.0964 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3909 - acc: 0.8789 - val_loss: 1.1182 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3790 - acc: 0.8843 - val_loss: 1.1249 - val_acc: 0.5125\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3720 - acc: 0.8846 - val_loss: 1.2150 - val_acc: 0.5250\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3041 - acc: 0.5156\n",
      "Test eval is  [1.304078221321106, 0.515625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:09:43.083720: Finished Train Fold #39/500 - thus far subj acc is 0.45128205128205123 and regular acc is0.4703525618100778\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #40\n",
      "A1 :  2022-04-07 22:10:06.309276\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7939 - acc: 0.5590 - val_loss: 0.7787 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7370 - acc: 0.5525 - val_loss: 0.7564 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6947 - acc: 0.5772 - val_loss: 0.7369 - val_acc: 0.5094\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6668 - acc: 0.6343 - val_loss: 0.7519 - val_acc: 0.5063\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6398 - acc: 0.6366 - val_loss: 0.7677 - val_acc: 0.4812\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6193 - acc: 0.6678 - val_loss: 0.7563 - val_acc: 0.5344\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5871 - acc: 0.7095 - val_loss: 0.7829 - val_acc: 0.5188\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5578 - acc: 0.7450 - val_loss: 0.8220 - val_acc: 0.5500\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5405 - acc: 0.7666 - val_loss: 0.7943 - val_acc: 0.5344\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5095 - acc: 0.7948 - val_loss: 0.7956 - val_acc: 0.5656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4917 - acc: 0.8110 - val_loss: 0.9457 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4744 - acc: 0.8283 - val_loss: 0.8327 - val_acc: 0.5875\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4608 - acc: 0.8364 - val_loss: 0.8549 - val_acc: 0.5562\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4282 - acc: 0.8607 - val_loss: 0.9429 - val_acc: 0.5406\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4244 - acc: 0.8634 - val_loss: 0.9296 - val_acc: 0.5813\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3948 - acc: 0.8843 - val_loss: 0.9878 - val_acc: 0.5375\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3875 - acc: 0.8885 - val_loss: 0.9572 - val_acc: 0.5625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3609 - acc: 0.8989 - val_loss: 1.0233 - val_acc: 0.5531\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3496 - acc: 0.9090 - val_loss: 1.0490 - val_acc: 0.5625\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8705 - acc: 0.2625\n",
      "Test eval is  [0.870475172996521, 0.26249998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:10:19.341131: Finished Train Fold #40/500 - thus far subj acc is 0.4525 and regular acc is0.4714843727648258\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #41\n",
      "A1 :  2022-04-07 22:10:43.303211\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7859 - acc: 0.5424 - val_loss: 0.7580 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7350 - acc: 0.5571 - val_loss: 0.7347 - val_acc: 0.4469\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7017 - acc: 0.5729 - val_loss: 0.7324 - val_acc: 0.4469\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6779 - acc: 0.5826 - val_loss: 0.7387 - val_acc: 0.4594\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6517 - acc: 0.6127 - val_loss: 0.8005 - val_acc: 0.4875\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6272 - acc: 0.6427 - val_loss: 0.8066 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5964 - acc: 0.6806 - val_loss: 0.8328 - val_acc: 0.5031\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5567 - acc: 0.7276 - val_loss: 0.9002 - val_acc: 0.5125\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5167 - acc: 0.7593 - val_loss: 1.0575 - val_acc: 0.4969\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4929 - acc: 0.7778 - val_loss: 1.0639 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4551 - acc: 0.8133 - val_loss: 1.0486 - val_acc: 0.5125\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4357 - acc: 0.8144 - val_loss: 1.1342 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4139 - acc: 0.8438 - val_loss: 1.1214 - val_acc: 0.5344\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3966 - acc: 0.8499 - val_loss: 1.1619 - val_acc: 0.5281\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3657 - acc: 0.8673 - val_loss: 1.1693 - val_acc: 0.5344\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3476 - acc: 0.8854 - val_loss: 1.1184 - val_acc: 0.5781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3470 - acc: 0.8854 - val_loss: 1.1834 - val_acc: 0.5688\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3278 - acc: 0.9078 - val_loss: 1.1715 - val_acc: 0.5594\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3207 - acc: 0.9090 - val_loss: 1.1247 - val_acc: 0.5844\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7558 - acc: 0.4250\n",
      "Test eval is  [0.7557545900344849, 0.42500001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:10:56.509797: Finished Train Fold #41/500 - thus far subj acc is 0.4439024390243903 and regular acc is0.46638719265053913\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #42\n",
      "A1 :  2022-04-07 22:11:17.695735\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7956 - acc: 0.5405 - val_loss: 0.7670 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7398 - acc: 0.5440 - val_loss: 0.7330 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7078 - acc: 0.5448 - val_loss: 0.7195 - val_acc: 0.4906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6799 - acc: 0.5702 - val_loss: 0.7261 - val_acc: 0.4688\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6630 - acc: 0.6038 - val_loss: 0.7518 - val_acc: 0.4750\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6427 - acc: 0.6435 - val_loss: 0.8458 - val_acc: 0.4938\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6131 - acc: 0.6933 - val_loss: 0.8064 - val_acc: 0.5281\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5962 - acc: 0.7056 - val_loss: 0.9898 - val_acc: 0.5156\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5612 - acc: 0.7400 - val_loss: 0.9598 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5352 - acc: 0.7577 - val_loss: 0.9942 - val_acc: 0.5063\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4998 - acc: 0.7959 - val_loss: 1.0733 - val_acc: 0.5063\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4840 - acc: 0.8056 - val_loss: 0.9890 - val_acc: 0.4969\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4563 - acc: 0.8260 - val_loss: 1.0607 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4300 - acc: 0.8441 - val_loss: 0.9911 - val_acc: 0.5562\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4209 - acc: 0.8576 - val_loss: 1.0261 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3935 - acc: 0.8576 - val_loss: 1.2667 - val_acc: 0.4969\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3825 - acc: 0.8735 - val_loss: 1.2570 - val_acc: 0.4750\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3546 - acc: 0.8924 - val_loss: 1.2179 - val_acc: 0.5094\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3437 - acc: 0.8997 - val_loss: 1.3199 - val_acc: 0.4688\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7411 - acc: 0.3938\n",
      "Test eval is  [0.7410706281661987, 0.39375001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:11:28.886145: Finished Train Fold #42/500 - thus far subj acc is 0.4428571428571429 and regular acc is0.4654017835855484\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #43\n",
      "A1 :  2022-04-07 22:11:47.978670\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7906 - acc: 0.5262 - val_loss: 0.7631 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7398 - acc: 0.5297 - val_loss: 0.7294 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7117 - acc: 0.5309 - val_loss: 0.7144 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6899 - acc: 0.5312 - val_loss: 0.7121 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6709 - acc: 0.5490 - val_loss: 0.7113 - val_acc: 0.5219\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6513 - acc: 0.6181 - val_loss: 0.7132 - val_acc: 0.5063\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6324 - acc: 0.6605 - val_loss: 0.7059 - val_acc: 0.5562\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6215 - acc: 0.6925 - val_loss: 0.7420 - val_acc: 0.4906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5973 - acc: 0.7153 - val_loss: 0.7470 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5834 - acc: 0.7288 - val_loss: 0.7080 - val_acc: 0.5437\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5675 - acc: 0.7504 - val_loss: 0.7207 - val_acc: 0.5437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5473 - acc: 0.7647 - val_loss: 0.8031 - val_acc: 0.5500\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5286 - acc: 0.7789 - val_loss: 0.8146 - val_acc: 0.5437\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5191 - acc: 0.7905 - val_loss: 0.8690 - val_acc: 0.5125\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5029 - acc: 0.7994 - val_loss: 0.8652 - val_acc: 0.5594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4866 - acc: 0.8094 - val_loss: 0.8779 - val_acc: 0.5750\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4766 - acc: 0.8183 - val_loss: 0.9346 - val_acc: 0.5219\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4663 - acc: 0.8287 - val_loss: 0.8048 - val_acc: 0.5781\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4606 - acc: 0.8279 - val_loss: 0.9814 - val_acc: 0.5312\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4674 - acc: 0.8252 - val_loss: 0.8551 - val_acc: 0.5281\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3009 - acc: 0.4812\n",
      "Test eval is  [1.3009071350097656, 0.48124998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:11:59.327236: Finished Train Fold #43/500 - thus far subj acc is 0.4418604651162791 and regular acc is0.4637354633142782\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #44\n",
      "A1 :  2022-04-07 22:12:18.402230\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7919 - acc: 0.5309 - val_loss: 0.7634 - val_acc: 0.5656\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7417 - acc: 0.5494 - val_loss: 0.7346 - val_acc: 0.5875\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7095 - acc: 0.5787 - val_loss: 0.7549 - val_acc: 0.5500\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6844 - acc: 0.6231 - val_loss: 0.8140 - val_acc: 0.5469\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6623 - acc: 0.6416 - val_loss: 0.7655 - val_acc: 0.5719\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6437 - acc: 0.6659 - val_loss: 0.7859 - val_acc: 0.5250\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6104 - acc: 0.7068 - val_loss: 0.8339 - val_acc: 0.5469\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5821 - acc: 0.7465 - val_loss: 0.8554 - val_acc: 0.5875\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5445 - acc: 0.7685 - val_loss: 1.0393 - val_acc: 0.5656\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5095 - acc: 0.7905 - val_loss: 1.0612 - val_acc: 0.5437\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4766 - acc: 0.8302 - val_loss: 0.9685 - val_acc: 0.5125\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4451 - acc: 0.8468 - val_loss: 1.0841 - val_acc: 0.5594\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4204 - acc: 0.8638 - val_loss: 1.1752 - val_acc: 0.4969\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3906 - acc: 0.8819 - val_loss: 1.0214 - val_acc: 0.5688\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3655 - acc: 0.8989 - val_loss: 1.2839 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3539 - acc: 0.8962 - val_loss: 1.1837 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3371 - acc: 0.9024 - val_loss: 1.2633 - val_acc: 0.5531\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3185 - acc: 0.9155 - val_loss: 1.1799 - val_acc: 0.5781\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7411 - acc: 0.3094\n",
      "Test eval is  [0.7410569787025452, 0.30937498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:12:28.880291: Finished Train Fold #44/500 - thus far subj acc is 0.4431818181818182 and regular acc is0.4641335206952962\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #45\n",
      "A1 :  2022-04-07 22:12:48.233908\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7909 - acc: 0.5363 - val_loss: 0.7658 - val_acc: 0.4313\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7389 - acc: 0.5494 - val_loss: 0.7328 - val_acc: 0.4156\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7070 - acc: 0.5660 - val_loss: 0.8164 - val_acc: 0.4437\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6836 - acc: 0.5976 - val_loss: 0.8753 - val_acc: 0.4313\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6616 - acc: 0.6327 - val_loss: 0.8353 - val_acc: 0.4812\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6445 - acc: 0.6393 - val_loss: 0.9283 - val_acc: 0.4688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6178 - acc: 0.6717 - val_loss: 0.9101 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5832 - acc: 0.7010 - val_loss: 1.0408 - val_acc: 0.4875\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5537 - acc: 0.7481 - val_loss: 0.9934 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5170 - acc: 0.7785 - val_loss: 1.1119 - val_acc: 0.5156\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4934 - acc: 0.7978 - val_loss: 1.0834 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4579 - acc: 0.8233 - val_loss: 1.1751 - val_acc: 0.4844\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4379 - acc: 0.8407 - val_loss: 1.1089 - val_acc: 0.5094\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4109 - acc: 0.8688 - val_loss: 1.2490 - val_acc: 0.4812\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3944 - acc: 0.8627 - val_loss: 1.2145 - val_acc: 0.4938\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3677 - acc: 0.8715 - val_loss: 1.2376 - val_acc: 0.5125\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3391 - acc: 0.8997 - val_loss: 1.3756 - val_acc: 0.5063\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3211 - acc: 0.9097 - val_loss: 1.4090 - val_acc: 0.4812\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7293 - acc: 0.5312\n",
      "Test eval is  [0.7293250560760498, 0.53125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:12:58.914093: Finished Train Fold #45/500 - thus far subj acc is 0.43777777777777777 and regular acc is0.46069444219271344\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #46\n",
      "A1 :  2022-04-07 22:13:17.977694\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8004 - acc: 0.5266 - val_loss: 0.7743 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7472 - acc: 0.5355 - val_loss: 0.7407 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7178 - acc: 0.5513 - val_loss: 0.7220 - val_acc: 0.4344\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6878 - acc: 0.5872 - val_loss: 0.7356 - val_acc: 0.4469\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6717 - acc: 0.6003 - val_loss: 0.7297 - val_acc: 0.4781\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6468 - acc: 0.6219 - val_loss: 0.7129 - val_acc: 0.5750\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6329 - acc: 0.6512 - val_loss: 0.7523 - val_acc: 0.5531\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6134 - acc: 0.6678 - val_loss: 0.7410 - val_acc: 0.5562\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5856 - acc: 0.7133 - val_loss: 0.7472 - val_acc: 0.6125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5593 - acc: 0.7292 - val_loss: 0.7631 - val_acc: 0.5750\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5410 - acc: 0.7531 - val_loss: 0.7898 - val_acc: 0.5844\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5095 - acc: 0.7820 - val_loss: 0.7764 - val_acc: 0.6125\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4756 - acc: 0.8032 - val_loss: 0.7661 - val_acc: 0.6094\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4631 - acc: 0.8268 - val_loss: 0.8361 - val_acc: 0.5969\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4246 - acc: 0.8511 - val_loss: 0.8651 - val_acc: 0.6125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3933 - acc: 0.8607 - val_loss: 1.0267 - val_acc: 0.5531\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3716 - acc: 0.8870 - val_loss: 0.8964 - val_acc: 0.6313\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3381 - acc: 0.9008 - val_loss: 0.9975 - val_acc: 0.5875\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3182 - acc: 0.9136 - val_loss: 1.0876 - val_acc: 0.5656\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3218 - acc: 0.9093 - val_loss: 1.0747 - val_acc: 0.5781\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5166 - acc: 0.4344\n",
      "Test eval is  [1.5165644884109497, 0.43437498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:13:29.343936: Finished Train Fold #46/500 - thus far subj acc is 0.43913043478260866 and regular acc is0.46222825866678485\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #47\n",
      "A1 :  2022-04-07 22:13:48.461903\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7905 - acc: 0.5324 - val_loss: 0.7656 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7384 - acc: 0.5428 - val_loss: 0.7358 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7064 - acc: 0.5478 - val_loss: 0.7452 - val_acc: 0.4469\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6786 - acc: 0.5957 - val_loss: 0.8146 - val_acc: 0.4250\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6463 - acc: 0.6366 - val_loss: 0.8503 - val_acc: 0.4594\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6178 - acc: 0.6752 - val_loss: 0.9756 - val_acc: 0.4750\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5861 - acc: 0.7002 - val_loss: 0.9761 - val_acc: 0.4344\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5668 - acc: 0.7326 - val_loss: 0.9393 - val_acc: 0.4781\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5272 - acc: 0.7774 - val_loss: 0.9394 - val_acc: 0.5063\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4974 - acc: 0.7812 - val_loss: 0.9859 - val_acc: 0.4812\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4829 - acc: 0.7909 - val_loss: 1.0055 - val_acc: 0.4688\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4474 - acc: 0.8283 - val_loss: 1.1830 - val_acc: 0.4781\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4183 - acc: 0.8488 - val_loss: 1.1861 - val_acc: 0.4938\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3990 - acc: 0.8546 - val_loss: 1.1566 - val_acc: 0.5000\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3950 - acc: 0.8669 - val_loss: 1.1775 - val_acc: 0.4781\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3516 - acc: 0.8846 - val_loss: 1.3067 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3420 - acc: 0.8900 - val_loss: 1.2686 - val_acc: 0.5656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3439 - acc: 0.8935 - val_loss: 1.2712 - val_acc: 0.5156\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7522 - acc: 0.4000\n",
      "Test eval is  [0.7521653175354004, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:13:58.971120: Finished Train Fold #47/500 - thus far subj acc is 0.4404255319148936 and regular acc is0.46163563588832285\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #48\n",
      "A1 :  2022-04-07 22:14:18.118153\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7831 - acc: 0.5266 - val_loss: 0.7551 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7350 - acc: 0.5309 - val_loss: 0.7268 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7076 - acc: 0.5309 - val_loss: 0.7064 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6922 - acc: 0.5309 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6822 - acc: 0.5309 - val_loss: 0.7021 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6689 - acc: 0.5448 - val_loss: 0.7010 - val_acc: 0.5375\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6570 - acc: 0.5860 - val_loss: 0.6973 - val_acc: 0.5625\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6518 - acc: 0.6119 - val_loss: 0.7164 - val_acc: 0.5719\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6375 - acc: 0.6346 - val_loss: 0.7088 - val_acc: 0.5781\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6218 - acc: 0.6667 - val_loss: 0.7193 - val_acc: 0.5688\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6134 - acc: 0.6709 - val_loss: 0.7190 - val_acc: 0.5406\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5969 - acc: 0.7172 - val_loss: 0.7422 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5804 - acc: 0.7396 - val_loss: 0.7753 - val_acc: 0.5594\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5640 - acc: 0.7581 - val_loss: 0.8302 - val_acc: 0.5844\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5536 - acc: 0.7566 - val_loss: 0.7414 - val_acc: 0.5594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5340 - acc: 0.7643 - val_loss: 0.8557 - val_acc: 0.6062\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5186 - acc: 0.7789 - val_loss: 0.8420 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5068 - acc: 0.7982 - val_loss: 0.7918 - val_acc: 0.5781\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5019 - acc: 0.7936 - val_loss: 0.8066 - val_acc: 0.5875\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4871 - acc: 0.8040 - val_loss: 0.7977 - val_acc: 0.5344\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7064 - acc: 0.5000\n",
      "Test eval is  [0.7064302563667297, 0.5]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:14:29.643438: Finished Train Fold #48/500 - thus far subj acc is 0.43958333333333327 and regular acc is0.4603515602648258\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #49\n",
      "A1 :  2022-04-07 22:14:48.586874\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7999 - acc: 0.5220 - val_loss: 0.7734 - val_acc: 0.3344\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7441 - acc: 0.5367 - val_loss: 0.7463 - val_acc: 0.3438\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7067 - acc: 0.5640 - val_loss: 0.7449 - val_acc: 0.4313\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6781 - acc: 0.5972 - val_loss: 0.7317 - val_acc: 0.4469\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6566 - acc: 0.6281 - val_loss: 0.7754 - val_acc: 0.4375\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6333 - acc: 0.6613 - val_loss: 0.7457 - val_acc: 0.5344\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6019 - acc: 0.7060 - val_loss: 0.8410 - val_acc: 0.5656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5551 - acc: 0.7508 - val_loss: 0.8916 - val_acc: 0.4906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5201 - acc: 0.7720 - val_loss: 0.9667 - val_acc: 0.5437\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4859 - acc: 0.7990 - val_loss: 1.1322 - val_acc: 0.5031\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4638 - acc: 0.8237 - val_loss: 1.0792 - val_acc: 0.5250\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4294 - acc: 0.8407 - val_loss: 1.0656 - val_acc: 0.5531\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3949 - acc: 0.8634 - val_loss: 1.1589 - val_acc: 0.5063\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3962 - acc: 0.8634 - val_loss: 1.0804 - val_acc: 0.5562\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3696 - acc: 0.8850 - val_loss: 1.2104 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3430 - acc: 0.8978 - val_loss: 1.1766 - val_acc: 0.5156\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3145 - acc: 0.9117 - val_loss: 1.1883 - val_acc: 0.5125\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3168 - acc: 0.9051 - val_loss: 1.2950 - val_acc: 0.5437\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2921 - acc: 0.9174 - val_loss: 1.5430 - val_acc: 0.4875\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2968 - acc: 0.9225 - val_loss: 1.4404 - val_acc: 0.5031\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8164 - acc: 0.5531\n",
      "Test eval is  [0.8163507580757141, 0.5531250238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:14:59.989542: Finished Train Fold #49/500 - thus far subj acc is 0.4408163265306122 and regular acc is0.4611607120961559\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #50\n",
      "A1 :  2022-04-07 22:15:19.236224\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7968 - acc: 0.5301 - val_loss: 0.7703 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7393 - acc: 0.5312 - val_loss: 0.7328 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7049 - acc: 0.5382 - val_loss: 0.7434 - val_acc: 0.4875\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6837 - acc: 0.5926 - val_loss: 0.7103 - val_acc: 0.4906\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6671 - acc: 0.6157 - val_loss: 0.7384 - val_acc: 0.4250\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6399 - acc: 0.6497 - val_loss: 0.7627 - val_acc: 0.5063\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6285 - acc: 0.6624 - val_loss: 0.7776 - val_acc: 0.4437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6037 - acc: 0.7052 - val_loss: 0.7377 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5792 - acc: 0.7257 - val_loss: 0.8701 - val_acc: 0.4688\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5528 - acc: 0.7535 - val_loss: 0.7847 - val_acc: 0.5281\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5477 - acc: 0.7627 - val_loss: 0.9027 - val_acc: 0.4969\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5098 - acc: 0.7859 - val_loss: 0.9549 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4926 - acc: 0.8106 - val_loss: 0.9811 - val_acc: 0.4781\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4683 - acc: 0.8245 - val_loss: 0.9600 - val_acc: 0.4938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4502 - acc: 0.8349 - val_loss: 1.0241 - val_acc: 0.4719\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4422 - acc: 0.8353 - val_loss: 1.0814 - val_acc: 0.4719\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4212 - acc: 0.8538 - val_loss: 1.1406 - val_acc: 0.4719\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4201 - acc: 0.8576 - val_loss: 0.9900 - val_acc: 0.4812\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3969 - acc: 0.8731 - val_loss: 1.0035 - val_acc: 0.5375\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3955 - acc: 0.8781 - val_loss: 1.1106 - val_acc: 0.5125\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7599 - acc: 0.4625\n",
      "Test eval is  [0.7598586678504944, 0.4625000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:15:30.792957: Finished Train Fold #50/500 - thus far subj acc is 0.44599999999999995 and regular acc is0.46299999833107\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #51\n",
      "A1 :  2022-04-07 22:15:49.931855\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7933 - acc: 0.5123 - val_loss: 0.7625 - val_acc: 0.5844\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7417 - acc: 0.5289 - val_loss: 0.7271 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7154 - acc: 0.5378 - val_loss: 0.7114 - val_acc: 0.5437\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6983 - acc: 0.5602 - val_loss: 0.7299 - val_acc: 0.5562\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6800 - acc: 0.5887 - val_loss: 0.7952 - val_acc: 0.4406\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6547 - acc: 0.6289 - val_loss: 0.9062 - val_acc: 0.4469\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6216 - acc: 0.6790 - val_loss: 0.8740 - val_acc: 0.4500\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5844 - acc: 0.7168 - val_loss: 0.9015 - val_acc: 0.4781\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5578 - acc: 0.7361 - val_loss: 0.9870 - val_acc: 0.4375\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5171 - acc: 0.7712 - val_loss: 1.1149 - val_acc: 0.4719\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4790 - acc: 0.8106 - val_loss: 1.2953 - val_acc: 0.4688\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4456 - acc: 0.8380 - val_loss: 1.1701 - val_acc: 0.4781\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4290 - acc: 0.8511 - val_loss: 1.1684 - val_acc: 0.4531\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3879 - acc: 0.8708 - val_loss: 1.2743 - val_acc: 0.4719\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3878 - acc: 0.8700 - val_loss: 1.1337 - val_acc: 0.5156\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3490 - acc: 0.8912 - val_loss: 1.2340 - val_acc: 0.4875\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3144 - acc: 0.9082 - val_loss: 1.5995 - val_acc: 0.4406\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3064 - acc: 0.9113 - val_loss: 1.5269 - val_acc: 0.4563\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3009 - acc: 0.9136 - val_loss: 1.4464 - val_acc: 0.4844\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7137 - acc: 0.4812\n",
      "Test eval is  [0.7136790752410889, 0.48124998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:16:00.748757: Finished Train Fold #51/500 - thus far subj acc is 0.44705882352941173 and regular acc is0.4629901945590973\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #52\n",
      "A1 :  2022-04-07 22:16:21.281446\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7981 - acc: 0.5444 - val_loss: 0.7675 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7433 - acc: 0.5432 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7115 - acc: 0.5455 - val_loss: 0.7161 - val_acc: 0.4906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6860 - acc: 0.5729 - val_loss: 0.7184 - val_acc: 0.4281\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6672 - acc: 0.6061 - val_loss: 0.7506 - val_acc: 0.4500\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6363 - acc: 0.6559 - val_loss: 0.7945 - val_acc: 0.4437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6113 - acc: 0.6775 - val_loss: 0.8095 - val_acc: 0.4719\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5719 - acc: 0.7157 - val_loss: 0.8515 - val_acc: 0.4781\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5404 - acc: 0.7504 - val_loss: 0.8662 - val_acc: 0.5125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5041 - acc: 0.7697 - val_loss: 0.9000 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4793 - acc: 0.7978 - val_loss: 0.9611 - val_acc: 0.4719\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4604 - acc: 0.7986 - val_loss: 0.9733 - val_acc: 0.4781\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4417 - acc: 0.8137 - val_loss: 0.9864 - val_acc: 0.5531\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4086 - acc: 0.8503 - val_loss: 0.9104 - val_acc: 0.5375\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3876 - acc: 0.8650 - val_loss: 1.0830 - val_acc: 0.4812\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3576 - acc: 0.8835 - val_loss: 1.1127 - val_acc: 0.5469\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3419 - acc: 0.8889 - val_loss: 1.0993 - val_acc: 0.5562\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3491 - acc: 0.8885 - val_loss: 1.0208 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3203 - acc: 0.9105 - val_loss: 1.1508 - val_acc: 0.5625\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7281 - acc: 0.4000\n",
      "Test eval is  [0.728094220161438, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:16:33.316358: Finished Train Fold #52/500 - thus far subj acc is 0.44807692307692304 and regular acc is0.4633413444344814\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #53\n",
      "A1 :  2022-04-07 22:16:54.448880\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7916 - acc: 0.5278 - val_loss: 0.7573 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7412 - acc: 0.5309 - val_loss: 0.7213 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7136 - acc: 0.5305 - val_loss: 0.7052 - val_acc: 0.6000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6938 - acc: 0.5309 - val_loss: 0.7068 - val_acc: 0.6000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6815 - acc: 0.5309 - val_loss: 0.7090 - val_acc: 0.6000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6748 - acc: 0.5448 - val_loss: 0.7021 - val_acc: 0.5688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6673 - acc: 0.5664 - val_loss: 0.7204 - val_acc: 0.4844\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6498 - acc: 0.6289 - val_loss: 0.7657 - val_acc: 0.4875\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6444 - acc: 0.6343 - val_loss: 0.7661 - val_acc: 0.4219\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6298 - acc: 0.6655 - val_loss: 0.7919 - val_acc: 0.4250\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6033 - acc: 0.6975 - val_loss: 0.8055 - val_acc: 0.4281\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5804 - acc: 0.7157 - val_loss: 0.8400 - val_acc: 0.4062\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5573 - acc: 0.7446 - val_loss: 0.8815 - val_acc: 0.4219\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5429 - acc: 0.7527 - val_loss: 0.9301 - val_acc: 0.4437\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5198 - acc: 0.7770 - val_loss: 0.8765 - val_acc: 0.4719\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4863 - acc: 0.8048 - val_loss: 1.0890 - val_acc: 0.4563\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4758 - acc: 0.8110 - val_loss: 0.9649 - val_acc: 0.4500\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4645 - acc: 0.8206 - val_loss: 1.0436 - val_acc: 0.4563\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4435 - acc: 0.8391 - val_loss: 1.0953 - val_acc: 0.4844\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4263 - acc: 0.8546 - val_loss: 1.1308 - val_acc: 0.4281\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2792 - acc: 0.4500\n",
      "Test eval is  [1.2792049646377563, 0.44999998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:17:05.787227: Finished Train Fold #53/500 - thus far subj acc is 0.4471698113207546 and regular acc is0.462146224840632\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #54\n",
      "A1 :  2022-04-07 22:17:24.700110\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7955 - acc: 0.5116 - val_loss: 0.7656 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7449 - acc: 0.5189 - val_loss: 0.7303 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7162 - acc: 0.5197 - val_loss: 0.7131 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7031 - acc: 0.5351 - val_loss: 0.7079 - val_acc: 0.4719\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6903 - acc: 0.5544 - val_loss: 0.7016 - val_acc: 0.5188\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6742 - acc: 0.5880 - val_loss: 0.7136 - val_acc: 0.5688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6588 - acc: 0.6350 - val_loss: 0.7391 - val_acc: 0.4875\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6298 - acc: 0.6825 - val_loss: 0.7167 - val_acc: 0.5844\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5943 - acc: 0.7056 - val_loss: 0.7434 - val_acc: 0.5156\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5699 - acc: 0.7334 - val_loss: 0.7942 - val_acc: 0.5063\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5421 - acc: 0.7658 - val_loss: 0.8285 - val_acc: 0.4906\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5243 - acc: 0.7755 - val_loss: 0.9095 - val_acc: 0.4938\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4953 - acc: 0.8044 - val_loss: 0.8521 - val_acc: 0.5625\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4744 - acc: 0.8156 - val_loss: 0.8638 - val_acc: 0.5688\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4458 - acc: 0.8322 - val_loss: 0.8766 - val_acc: 0.5906\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4234 - acc: 0.8488 - val_loss: 0.9692 - val_acc: 0.5656\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4042 - acc: 0.8603 - val_loss: 0.9941 - val_acc: 0.5906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3976 - acc: 0.8661 - val_loss: 0.9766 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3727 - acc: 0.8870 - val_loss: 1.0547 - val_acc: 0.5781\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3687 - acc: 0.8796 - val_loss: 1.1111 - val_acc: 0.5281\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1139 - acc: 0.5250\n",
      "Test eval is  [1.1139416694641113, 0.5249999761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:17:36.272056: Finished Train Fold #54/500 - thus far subj acc is 0.4462962962962962 and regular acc is0.46192129453023273\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #55\n",
      "A1 :  2022-04-07 22:17:55.339969\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7830 - acc: 0.5251 - val_loss: 0.7605 - val_acc: 0.3875\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7343 - acc: 0.5579 - val_loss: 0.7351 - val_acc: 0.4250\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7003 - acc: 0.5849 - val_loss: 0.7360 - val_acc: 0.3938\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6743 - acc: 0.6150 - val_loss: 0.7688 - val_acc: 0.4094\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6530 - acc: 0.6377 - val_loss: 0.7632 - val_acc: 0.5281\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6275 - acc: 0.6728 - val_loss: 0.8437 - val_acc: 0.5219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5912 - acc: 0.7056 - val_loss: 0.8715 - val_acc: 0.4938\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5605 - acc: 0.7350 - val_loss: 0.9340 - val_acc: 0.5219\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5271 - acc: 0.7766 - val_loss: 0.9404 - val_acc: 0.4750\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4958 - acc: 0.8067 - val_loss: 1.0420 - val_acc: 0.5094\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4748 - acc: 0.8129 - val_loss: 1.0531 - val_acc: 0.5281\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4442 - acc: 0.8291 - val_loss: 1.0585 - val_acc: 0.5312\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4175 - acc: 0.8457 - val_loss: 1.1570 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3928 - acc: 0.8654 - val_loss: 1.0933 - val_acc: 0.5531\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3785 - acc: 0.8708 - val_loss: 1.0993 - val_acc: 0.5437\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3699 - acc: 0.8796 - val_loss: 1.1045 - val_acc: 0.5625\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3419 - acc: 0.8927 - val_loss: 1.2439 - val_acc: 0.5344\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3403 - acc: 0.8897 - val_loss: 1.1562 - val_acc: 0.5562\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7306 - acc: 0.5281\n",
      "Test eval is  [0.7306241393089294, 0.528124988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:18:06.001185: Finished Train Fold #55/500 - thus far subj acc is 0.44909090909090904 and regular acc is0.4630681796507402\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #56\n",
      "A1 :  2022-04-07 22:18:25.291835\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7907 - acc: 0.5154 - val_loss: 0.7688 - val_acc: 0.4500\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7396 - acc: 0.5833 - val_loss: 0.7405 - val_acc: 0.4406\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7100 - acc: 0.6138 - val_loss: 0.7485 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6826 - acc: 0.6262 - val_loss: 0.8361 - val_acc: 0.5063\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6631 - acc: 0.6543 - val_loss: 0.9628 - val_acc: 0.4344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6427 - acc: 0.6759 - val_loss: 0.8563 - val_acc: 0.4344\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6052 - acc: 0.7103 - val_loss: 0.9128 - val_acc: 0.4313\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5802 - acc: 0.7400 - val_loss: 1.0507 - val_acc: 0.4313\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5556 - acc: 0.7589 - val_loss: 1.1010 - val_acc: 0.4812\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5246 - acc: 0.7820 - val_loss: 1.0826 - val_acc: 0.4688\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4980 - acc: 0.8086 - val_loss: 1.1077 - val_acc: 0.5031\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4598 - acc: 0.8353 - val_loss: 1.0971 - val_acc: 0.4688\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4368 - acc: 0.8507 - val_loss: 1.1356 - val_acc: 0.4969\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4157 - acc: 0.8650 - val_loss: 1.2423 - val_acc: 0.4812\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3962 - acc: 0.8765 - val_loss: 1.2095 - val_acc: 0.4688\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3628 - acc: 0.8943 - val_loss: 1.2899 - val_acc: 0.4781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3476 - acc: 0.9032 - val_loss: 1.3348 - val_acc: 0.5063\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3342 - acc: 0.9101 - val_loss: 1.3535 - val_acc: 0.4844\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7396 - acc: 0.4594\n",
      "Test eval is  [0.7395581007003784, 0.4593749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:18:35.704351: Finished Train Fold #56/500 - thus far subj acc is 0.45357142857142857 and regular acc is0.4642299083726747\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #57\n",
      "A1 :  2022-04-07 22:18:54.787758\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8014 - acc: 0.5166 - val_loss: 0.7655 - val_acc: 0.5969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7484 - acc: 0.5289 - val_loss: 0.7305 - val_acc: 0.5875\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7171 - acc: 0.5679 - val_loss: 0.7118 - val_acc: 0.5063\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6978 - acc: 0.5856 - val_loss: 0.7174 - val_acc: 0.4906\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6732 - acc: 0.6192 - val_loss: 0.7179 - val_acc: 0.5375\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6531 - acc: 0.6377 - val_loss: 0.7773 - val_acc: 0.4688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6275 - acc: 0.6802 - val_loss: 0.7567 - val_acc: 0.4812\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6032 - acc: 0.6960 - val_loss: 0.8259 - val_acc: 0.4375\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5732 - acc: 0.7326 - val_loss: 0.8917 - val_acc: 0.4500\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5501 - acc: 0.7404 - val_loss: 0.9958 - val_acc: 0.4625\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5170 - acc: 0.7847 - val_loss: 0.9589 - val_acc: 0.4969\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4957 - acc: 0.8013 - val_loss: 0.9970 - val_acc: 0.4969\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4742 - acc: 0.8110 - val_loss: 1.0536 - val_acc: 0.5250\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4382 - acc: 0.8418 - val_loss: 1.0840 - val_acc: 0.4938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4279 - acc: 0.8511 - val_loss: 1.1261 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3978 - acc: 0.8692 - val_loss: 1.1275 - val_acc: 0.5125\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3713 - acc: 0.8789 - val_loss: 1.2280 - val_acc: 0.4844\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3529 - acc: 0.8920 - val_loss: 1.1623 - val_acc: 0.4844\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3369 - acc: 0.8985 - val_loss: 1.3320 - val_acc: 0.5063\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7219 - acc: 0.5594\n",
      "Test eval is  [0.7219074964523315, 0.559374988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:19:05.630602: Finished Train Fold #57/500 - thus far subj acc is 0.4491228070175438 and regular acc is0.46414473443700555\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #58\n",
      "A1 :  2022-04-07 22:19:24.695769\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7926 - acc: 0.5374 - val_loss: 0.7700 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7376 - acc: 0.5552 - val_loss: 0.7342 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7052 - acc: 0.5571 - val_loss: 0.7219 - val_acc: 0.4938\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6809 - acc: 0.5945 - val_loss: 0.7351 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6534 - acc: 0.6192 - val_loss: 0.7514 - val_acc: 0.4531\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6191 - acc: 0.6651 - val_loss: 0.8123 - val_acc: 0.4781\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5923 - acc: 0.6975 - val_loss: 0.8494 - val_acc: 0.5063\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5670 - acc: 0.7292 - val_loss: 0.8722 - val_acc: 0.5500\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5281 - acc: 0.7546 - val_loss: 0.9994 - val_acc: 0.4844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5077 - acc: 0.7812 - val_loss: 0.8566 - val_acc: 0.5156\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4771 - acc: 0.7967 - val_loss: 1.0274 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4624 - acc: 0.8044 - val_loss: 1.0992 - val_acc: 0.4688\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4221 - acc: 0.8380 - val_loss: 1.1659 - val_acc: 0.5312\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4021 - acc: 0.8445 - val_loss: 1.1728 - val_acc: 0.4875\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3805 - acc: 0.8665 - val_loss: 1.1525 - val_acc: 0.4969\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3490 - acc: 0.8792 - val_loss: 1.2985 - val_acc: 0.5063\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3603 - acc: 0.8816 - val_loss: 1.1514 - val_acc: 0.5344\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3221 - acc: 0.9059 - val_loss: 1.2886 - val_acc: 0.5094\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3219 - acc: 0.8985 - val_loss: 1.5181 - val_acc: 0.4688\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7517 - acc: 0.3031\n",
      "Test eval is  [0.7517292499542236, 0.3031249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:19:35.864129: Finished Train Fold #58/500 - thus far subj acc is 0.45344827586206893 and regular acc is0.46578663536186876\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #59\n",
      "A1 :  2022-04-07 22:19:54.918480\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7915 - acc: 0.5262 - val_loss: 0.7646 - val_acc: 0.4875\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7380 - acc: 0.5660 - val_loss: 0.7325 - val_acc: 0.4844\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6986 - acc: 0.5903 - val_loss: 0.8100 - val_acc: 0.4812\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6680 - acc: 0.6246 - val_loss: 0.8078 - val_acc: 0.5375\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6369 - acc: 0.6717 - val_loss: 0.7997 - val_acc: 0.5250\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6062 - acc: 0.7045 - val_loss: 0.8556 - val_acc: 0.5094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5687 - acc: 0.7550 - val_loss: 0.8837 - val_acc: 0.5531\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5267 - acc: 0.7789 - val_loss: 0.9734 - val_acc: 0.5156\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4838 - acc: 0.8083 - val_loss: 1.0721 - val_acc: 0.4812\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4756 - acc: 0.8218 - val_loss: 1.0732 - val_acc: 0.5250\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4365 - acc: 0.8441 - val_loss: 0.9878 - val_acc: 0.5531\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3964 - acc: 0.8754 - val_loss: 1.1360 - val_acc: 0.5188\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3789 - acc: 0.8812 - val_loss: 1.1411 - val_acc: 0.5781\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3523 - acc: 0.8993 - val_loss: 1.1556 - val_acc: 0.5594\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3247 - acc: 0.9140 - val_loss: 1.2535 - val_acc: 0.5406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3093 - acc: 0.9248 - val_loss: 1.4341 - val_acc: 0.5312\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2957 - acc: 0.9267 - val_loss: 1.3058 - val_acc: 0.5406\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2885 - acc: 0.9282 - val_loss: 1.3657 - val_acc: 0.5375\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7312 - acc: 0.4844\n",
      "Test eval is  [0.7312208414077759, 0.484375]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:20:05.327050: Finished Train Fold #59/500 - thus far subj acc is 0.4508474576271186 and regular acc is0.4630296583903038\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #60\n",
      "A1 :  2022-04-07 22:20:24.360240\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7815 - acc: 0.5208 - val_loss: 0.7542 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7352 - acc: 0.5312 - val_loss: 0.7255 - val_acc: 0.4969\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7104 - acc: 0.5478 - val_loss: 0.7184 - val_acc: 0.4625\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6945 - acc: 0.5621 - val_loss: 0.7514 - val_acc: 0.4594\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6808 - acc: 0.5826 - val_loss: 0.7433 - val_acc: 0.4406\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6682 - acc: 0.5995 - val_loss: 0.8039 - val_acc: 0.4656\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6535 - acc: 0.6192 - val_loss: 0.8195 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6326 - acc: 0.6416 - val_loss: 0.7920 - val_acc: 0.5219\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6081 - acc: 0.6674 - val_loss: 0.8348 - val_acc: 0.5375\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5905 - acc: 0.6960 - val_loss: 0.8904 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5687 - acc: 0.7160 - val_loss: 0.9440 - val_acc: 0.5219\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5374 - acc: 0.7473 - val_loss: 0.8679 - val_acc: 0.5406\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5068 - acc: 0.7755 - val_loss: 0.9605 - val_acc: 0.5375\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4781 - acc: 0.7913 - val_loss: 0.9548 - val_acc: 0.5469\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4555 - acc: 0.8098 - val_loss: 1.0832 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4411 - acc: 0.8175 - val_loss: 1.0749 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4142 - acc: 0.8326 - val_loss: 1.1839 - val_acc: 0.5406\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3943 - acc: 0.8534 - val_loss: 1.0915 - val_acc: 0.5344\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3834 - acc: 0.8592 - val_loss: 1.2772 - val_acc: 0.5063\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7084 - acc: 0.4969\n",
      "Test eval is  [0.7083753943443298, 0.49687498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:20:35.240037: Finished Train Fold #60/500 - thus far subj acc is 0.4516666666666666 and regular acc is0.46338541408379874\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #61\n",
      "A1 :  2022-04-07 22:20:54.352277\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7903 - acc: 0.5478 - val_loss: 0.7666 - val_acc: 0.4187\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7374 - acc: 0.5667 - val_loss: 0.7400 - val_acc: 0.4719\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7005 - acc: 0.5961 - val_loss: 0.7212 - val_acc: 0.5594\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6641 - acc: 0.6404 - val_loss: 0.7303 - val_acc: 0.5375\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6263 - acc: 0.6971 - val_loss: 0.7854 - val_acc: 0.5344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5823 - acc: 0.7326 - val_loss: 0.8325 - val_acc: 0.5531\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5470 - acc: 0.7735 - val_loss: 0.8517 - val_acc: 0.5188\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5007 - acc: 0.8094 - val_loss: 0.8726 - val_acc: 0.5500\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4705 - acc: 0.8310 - val_loss: 0.9252 - val_acc: 0.5562\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4230 - acc: 0.8580 - val_loss: 1.0066 - val_acc: 0.5469\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4089 - acc: 0.8688 - val_loss: 1.0149 - val_acc: 0.5781\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3686 - acc: 0.8893 - val_loss: 1.0579 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3642 - acc: 0.8939 - val_loss: 1.0255 - val_acc: 0.5688\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3355 - acc: 0.9093 - val_loss: 1.0174 - val_acc: 0.5938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3314 - acc: 0.9132 - val_loss: 1.1059 - val_acc: 0.5875\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2952 - acc: 0.9259 - val_loss: 1.1233 - val_acc: 0.6125\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2819 - acc: 0.9333 - val_loss: 1.2365 - val_acc: 0.5813\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2764 - acc: 0.9333 - val_loss: 1.2285 - val_acc: 0.5813\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2649 - acc: 0.9402 - val_loss: 1.2614 - val_acc: 0.5844\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7754 - acc: 0.2844\n",
      "Test eval is  [0.7753744125366211, 0.28437501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:21:05.166119: Finished Train Fold #61/500 - thus far subj acc is 0.4524590163934426 and regular acc is0.4639344234935573\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #62\n",
      "A1 :  2022-04-07 22:21:24.237788\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7895 - acc: 0.5285 - val_loss: 0.7610 - val_acc: 0.4906\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7355 - acc: 0.5606 - val_loss: 0.7482 - val_acc: 0.4531\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7036 - acc: 0.5949 - val_loss: 0.7438 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6795 - acc: 0.6192 - val_loss: 0.8472 - val_acc: 0.4656\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6668 - acc: 0.6316 - val_loss: 0.7915 - val_acc: 0.4469\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6441 - acc: 0.6566 - val_loss: 0.8819 - val_acc: 0.4406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6266 - acc: 0.6767 - val_loss: 0.9722 - val_acc: 0.5312\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6032 - acc: 0.6971 - val_loss: 0.8983 - val_acc: 0.4875\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5773 - acc: 0.7361 - val_loss: 0.9861 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5499 - acc: 0.7488 - val_loss: 1.1190 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5318 - acc: 0.7724 - val_loss: 1.1347 - val_acc: 0.4875\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5009 - acc: 0.7951 - val_loss: 1.0699 - val_acc: 0.4844\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4821 - acc: 0.8059 - val_loss: 1.1599 - val_acc: 0.4750\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4479 - acc: 0.8368 - val_loss: 1.2033 - val_acc: 0.4625\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4305 - acc: 0.8492 - val_loss: 1.2776 - val_acc: 0.4500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4042 - acc: 0.8696 - val_loss: 1.1241 - val_acc: 0.5031\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3749 - acc: 0.8858 - val_loss: 1.3130 - val_acc: 0.4906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3706 - acc: 0.8924 - val_loss: 1.1640 - val_acc: 0.4969\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3435 - acc: 0.8989 - val_loss: 1.5346 - val_acc: 0.4844\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7842 - acc: 0.4406\n",
      "Test eval is  [0.7842004299163818, 0.44062501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:21:35.077723: Finished Train Fold #62/500 - thus far subj acc is 0.4483870967741935 and regular acc is0.4610383039520633\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #63\n",
      "A1 :  2022-04-07 22:21:54.136880\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7817 - acc: 0.5328 - val_loss: 0.7550 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7341 - acc: 0.5613 - val_loss: 0.7321 - val_acc: 0.4719\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7050 - acc: 0.5876 - val_loss: 0.7233 - val_acc: 0.4812\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6843 - acc: 0.6119 - val_loss: 0.7725 - val_acc: 0.4719\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6642 - acc: 0.6470 - val_loss: 0.8012 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6487 - acc: 0.6593 - val_loss: 0.8198 - val_acc: 0.4531\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6277 - acc: 0.6836 - val_loss: 0.8175 - val_acc: 0.4563\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5938 - acc: 0.7195 - val_loss: 0.8826 - val_acc: 0.4531\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5656 - acc: 0.7454 - val_loss: 0.8677 - val_acc: 0.5031\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5458 - acc: 0.7674 - val_loss: 0.9390 - val_acc: 0.4563\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5006 - acc: 0.8005 - val_loss: 1.1116 - val_acc: 0.4313\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4703 - acc: 0.8272 - val_loss: 1.1371 - val_acc: 0.4563\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4548 - acc: 0.8318 - val_loss: 1.2226 - val_acc: 0.3969\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4340 - acc: 0.8453 - val_loss: 1.2099 - val_acc: 0.4469\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3993 - acc: 0.8723 - val_loss: 1.2667 - val_acc: 0.3938\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3843 - acc: 0.8769 - val_loss: 1.2286 - val_acc: 0.5063\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3835 - acc: 0.8827 - val_loss: 1.3194 - val_acc: 0.4375\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3668 - acc: 0.8924 - val_loss: 1.5049 - val_acc: 0.4656\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3407 - acc: 0.9028 - val_loss: 1.5662 - val_acc: 0.4094\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7356 - acc: 0.3781\n",
      "Test eval is  [0.7356340289115906, 0.37812501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:22:05.233215: Finished Train Fold #63/500 - thus far subj acc is 0.44444444444444436 and regular acc is0.4607142834436326\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #64\n",
      "A1 :  2022-04-07 22:22:24.431872\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8011 - acc: 0.5204 - val_loss: 0.7687 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7468 - acc: 0.5309 - val_loss: 0.7313 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7181 - acc: 0.5309 - val_loss: 0.7127 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7020 - acc: 0.5309 - val_loss: 0.7027 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6887 - acc: 0.5309 - val_loss: 0.6990 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6804 - acc: 0.5309 - val_loss: 0.7054 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6673 - acc: 0.5309 - val_loss: 0.7029 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6596 - acc: 0.5617 - val_loss: 0.6944 - val_acc: 0.5656\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6539 - acc: 0.6331 - val_loss: 0.6986 - val_acc: 0.5437\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6378 - acc: 0.6528 - val_loss: 0.6958 - val_acc: 0.5500\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6227 - acc: 0.6829 - val_loss: 0.7192 - val_acc: 0.5219\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6244 - acc: 0.6925 - val_loss: 0.7228 - val_acc: 0.5469\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5970 - acc: 0.7037 - val_loss: 0.7472 - val_acc: 0.5250\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6035 - acc: 0.7033 - val_loss: 0.7175 - val_acc: 0.5594\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5814 - acc: 0.7234 - val_loss: 0.7689 - val_acc: 0.5531\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5624 - acc: 0.7488 - val_loss: 0.7648 - val_acc: 0.5469\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5477 - acc: 0.7654 - val_loss: 0.8899 - val_acc: 0.5219\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5388 - acc: 0.7731 - val_loss: 0.8548 - val_acc: 0.5063\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5265 - acc: 0.7820 - val_loss: 0.8806 - val_acc: 0.4969\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5146 - acc: 0.7824 - val_loss: 0.9394 - val_acc: 0.5094\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9618 - acc: 0.4906\n",
      "Test eval is  [0.961756706237793, 0.4906249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:22:35.741354: Finished Train Fold #64/500 - thus far subj acc is 0.44375 and regular acc is0.45942382607609034\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #65\n",
      "A1 :  2022-04-07 22:22:54.835155\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7889 - acc: 0.5004 - val_loss: 0.7592 - val_acc: 0.4844\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7404 - acc: 0.5532 - val_loss: 0.7266 - val_acc: 0.4938\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7151 - acc: 0.5502 - val_loss: 0.7153 - val_acc: 0.5250\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6940 - acc: 0.5860 - val_loss: 0.7525 - val_acc: 0.5344\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6766 - acc: 0.6157 - val_loss: 0.7801 - val_acc: 0.5063\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6607 - acc: 0.6339 - val_loss: 0.8471 - val_acc: 0.5094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6402 - acc: 0.6678 - val_loss: 0.9053 - val_acc: 0.5063\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6139 - acc: 0.7029 - val_loss: 0.9185 - val_acc: 0.5031\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5832 - acc: 0.7299 - val_loss: 0.9690 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5508 - acc: 0.7608 - val_loss: 0.9571 - val_acc: 0.5312\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5336 - acc: 0.7758 - val_loss: 0.9447 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5032 - acc: 0.8044 - val_loss: 0.9559 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4727 - acc: 0.8314 - val_loss: 1.0619 - val_acc: 0.5531\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4498 - acc: 0.8418 - val_loss: 1.1511 - val_acc: 0.5063\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4288 - acc: 0.8627 - val_loss: 1.0648 - val_acc: 0.5562\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4033 - acc: 0.8727 - val_loss: 1.0580 - val_acc: 0.5469\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3963 - acc: 0.8789 - val_loss: 1.2376 - val_acc: 0.5031\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3822 - acc: 0.8816 - val_loss: 1.2286 - val_acc: 0.5125\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3587 - acc: 0.8924 - val_loss: 1.3061 - val_acc: 0.4812\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7143 - acc: 0.5625\n",
      "Test eval is  [0.7143446803092957, 0.5625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:23:05.597830: Finished Train Fold #65/500 - thus far subj acc is 0.4446153846153846 and regular acc is0.4599038440447587\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #66\n",
      "A1 :  2022-04-07 22:23:24.583384\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7986 - acc: 0.5220 - val_loss: 0.7686 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7436 - acc: 0.5340 - val_loss: 0.7286 - val_acc: 0.4812\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7055 - acc: 0.5629 - val_loss: 0.7255 - val_acc: 0.4688\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6747 - acc: 0.6022 - val_loss: 0.7154 - val_acc: 0.4719\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6539 - acc: 0.6254 - val_loss: 0.7377 - val_acc: 0.5125\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6318 - acc: 0.6516 - val_loss: 0.7683 - val_acc: 0.4906\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6025 - acc: 0.6991 - val_loss: 0.8025 - val_acc: 0.4906\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5707 - acc: 0.7184 - val_loss: 0.8303 - val_acc: 0.5094\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5425 - acc: 0.7535 - val_loss: 0.9463 - val_acc: 0.4844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5021 - acc: 0.7797 - val_loss: 0.8564 - val_acc: 0.5531\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4757 - acc: 0.8167 - val_loss: 0.9645 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4504 - acc: 0.8241 - val_loss: 0.9571 - val_acc: 0.5469\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4183 - acc: 0.8573 - val_loss: 1.0278 - val_acc: 0.5531\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3905 - acc: 0.8758 - val_loss: 1.0067 - val_acc: 0.5312\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3619 - acc: 0.8920 - val_loss: 1.0906 - val_acc: 0.5156\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3646 - acc: 0.8870 - val_loss: 0.9985 - val_acc: 0.5344\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3339 - acc: 0.8974 - val_loss: 1.2495 - val_acc: 0.5625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3131 - acc: 0.9113 - val_loss: 1.2434 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3132 - acc: 0.9120 - val_loss: 1.3223 - val_acc: 0.5312\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2861 - acc: 0.9255 - val_loss: 1.4735 - val_acc: 0.5250\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7972 - acc: 0.3938\n",
      "Test eval is  [0.7971571087837219, 0.39375001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:23:36.077058: Finished Train Fold #66/500 - thus far subj acc is 0.44696969696969696 and regular acc is0.4614583312562018\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #67\n",
      "A1 :  2022-04-07 22:23:55.209063\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7927 - acc: 0.5131 - val_loss: 0.7648 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7417 - acc: 0.5386 - val_loss: 0.7378 - val_acc: 0.4750\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7181 - acc: 0.5559 - val_loss: 0.7168 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6941 - acc: 0.5787 - val_loss: 0.7134 - val_acc: 0.4906\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6739 - acc: 0.6084 - val_loss: 0.7525 - val_acc: 0.4563\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6565 - acc: 0.6339 - val_loss: 0.7357 - val_acc: 0.5094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6264 - acc: 0.6833 - val_loss: 0.8410 - val_acc: 0.5250\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5930 - acc: 0.7126 - val_loss: 0.7755 - val_acc: 0.5500\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5668 - acc: 0.7415 - val_loss: 0.8298 - val_acc: 0.5594\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5327 - acc: 0.7724 - val_loss: 0.8856 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5147 - acc: 0.7894 - val_loss: 0.9739 - val_acc: 0.5156\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4849 - acc: 0.8144 - val_loss: 0.9029 - val_acc: 0.5594\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4682 - acc: 0.8237 - val_loss: 0.9666 - val_acc: 0.5375\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4347 - acc: 0.8391 - val_loss: 1.0023 - val_acc: 0.5719\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4224 - acc: 0.8627 - val_loss: 1.0409 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3855 - acc: 0.8723 - val_loss: 1.2269 - val_acc: 0.4469\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3879 - acc: 0.8677 - val_loss: 1.2263 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3642 - acc: 0.8885 - val_loss: 1.3671 - val_acc: 0.4469\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3725 - acc: 0.8789 - val_loss: 1.4680 - val_acc: 0.4281\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3498 - acc: 0.8958 - val_loss: 1.4154 - val_acc: 0.4500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7240 - acc: 0.4594\n",
      "Test eval is  [0.7239776253700256, 0.4593749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:24:06.760562: Finished Train Fold #67/500 - thus far subj acc is 0.4462686567164179 and regular acc is0.46044775932582455\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #68\n",
      "A1 :  2022-04-07 22:24:25.837149\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7913 - acc: 0.5355 - val_loss: 0.7659 - val_acc: 0.4844\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7358 - acc: 0.5312 - val_loss: 0.7446 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7086 - acc: 0.5613 - val_loss: 0.7222 - val_acc: 0.4563\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6788 - acc: 0.6157 - val_loss: 0.7431 - val_acc: 0.5219\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6589 - acc: 0.6508 - val_loss: 0.7407 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6280 - acc: 0.6794 - val_loss: 0.7469 - val_acc: 0.5406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5964 - acc: 0.7126 - val_loss: 0.8275 - val_acc: 0.4781\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5656 - acc: 0.7423 - val_loss: 0.8344 - val_acc: 0.5219\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5359 - acc: 0.7728 - val_loss: 0.8732 - val_acc: 0.4938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5051 - acc: 0.7894 - val_loss: 0.9392 - val_acc: 0.5312\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4854 - acc: 0.8044 - val_loss: 1.0800 - val_acc: 0.5250\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4595 - acc: 0.8275 - val_loss: 1.1486 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4376 - acc: 0.8472 - val_loss: 1.0201 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4198 - acc: 0.8546 - val_loss: 1.2196 - val_acc: 0.4563\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3781 - acc: 0.8804 - val_loss: 1.2177 - val_acc: 0.4969\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3778 - acc: 0.8816 - val_loss: 1.1627 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3566 - acc: 0.8970 - val_loss: 1.3512 - val_acc: 0.4812\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3337 - acc: 0.9082 - val_loss: 1.2575 - val_acc: 0.4688\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3218 - acc: 0.9159 - val_loss: 1.4838 - val_acc: 0.4531\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7402 - acc: 0.5437\n",
      "Test eval is  [0.7402218580245972, 0.543749988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:24:36.986102: Finished Train Fold #68/500 - thus far subj acc is 0.44705882352941173 and regular acc is0.4604319833657321\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #69\n",
      "A1 :  2022-04-07 22:24:56.201077\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7823 - acc: 0.5305 - val_loss: 0.7646 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7305 - acc: 0.5309 - val_loss: 0.7565 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7021 - acc: 0.5309 - val_loss: 0.7316 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6810 - acc: 0.5610 - val_loss: 0.7279 - val_acc: 0.4812\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6605 - acc: 0.6304 - val_loss: 0.7243 - val_acc: 0.5312\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6447 - acc: 0.6605 - val_loss: 0.7690 - val_acc: 0.5437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6225 - acc: 0.6941 - val_loss: 0.7839 - val_acc: 0.5594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6066 - acc: 0.7079 - val_loss: 0.8066 - val_acc: 0.5719\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5837 - acc: 0.7434 - val_loss: 0.8488 - val_acc: 0.5437\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5700 - acc: 0.7512 - val_loss: 0.8682 - val_acc: 0.5625\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5441 - acc: 0.7774 - val_loss: 0.8792 - val_acc: 0.5625\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5303 - acc: 0.7890 - val_loss: 0.9556 - val_acc: 0.5625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5193 - acc: 0.7971 - val_loss: 1.0535 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4982 - acc: 0.8052 - val_loss: 1.0866 - val_acc: 0.5344\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4947 - acc: 0.8106 - val_loss: 0.9682 - val_acc: 0.5531\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4732 - acc: 0.8241 - val_loss: 1.2199 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4525 - acc: 0.8422 - val_loss: 1.1820 - val_acc: 0.5156\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4528 - acc: 0.8356 - val_loss: 1.2171 - val_acc: 0.5656\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4439 - acc: 0.8364 - val_loss: 1.1886 - val_acc: 0.5562\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4219 - acc: 0.8569 - val_loss: 1.3147 - val_acc: 0.5281\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1993 - acc: 0.4187\n",
      "Test eval is  [1.199347734451294, 0.41874998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:25:07.561178: Finished Train Fold #69/500 - thus far subj acc is 0.4492753623188406 and regular acc is0.46163949068041815\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #70\n",
      "A1 :  2022-04-07 22:25:26.540687\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8060 - acc: 0.5316 - val_loss: 0.7771 - val_acc: 0.4187\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7491 - acc: 0.5675 - val_loss: 0.7495 - val_acc: 0.4281\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7133 - acc: 0.5791 - val_loss: 0.7387 - val_acc: 0.4219\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6863 - acc: 0.5891 - val_loss: 0.7640 - val_acc: 0.3625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6709 - acc: 0.6084 - val_loss: 0.7747 - val_acc: 0.3625\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6490 - acc: 0.6385 - val_loss: 0.7473 - val_acc: 0.4250\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6421 - acc: 0.6481 - val_loss: 0.7807 - val_acc: 0.4594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6121 - acc: 0.6821 - val_loss: 0.8014 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5946 - acc: 0.7110 - val_loss: 0.8816 - val_acc: 0.4469\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5566 - acc: 0.7411 - val_loss: 0.8529 - val_acc: 0.4531\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5279 - acc: 0.7654 - val_loss: 0.9187 - val_acc: 0.4469\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5012 - acc: 0.7886 - val_loss: 0.9710 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4727 - acc: 0.8167 - val_loss: 1.0460 - val_acc: 0.4906\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4373 - acc: 0.8333 - val_loss: 1.0601 - val_acc: 0.5375\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4104 - acc: 0.8615 - val_loss: 1.1412 - val_acc: 0.5312\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4046 - acc: 0.8661 - val_loss: 1.0662 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3933 - acc: 0.8646 - val_loss: 1.1874 - val_acc: 0.5437\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3706 - acc: 0.8843 - val_loss: 1.1154 - val_acc: 0.5437\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3402 - acc: 0.9066 - val_loss: 1.1233 - val_acc: 0.5562\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7310 - acc: 0.5531\n",
      "Test eval is  [0.7309756278991699, 0.5531250238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:25:37.472227: Finished Train Fold #70/500 - thus far subj acc is 0.45 and regular acc is0.4610267835003989\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #71\n",
      "A1 :  2022-04-07 22:25:56.418031\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7865 - acc: 0.5486 - val_loss: 0.7726 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7349 - acc: 0.5556 - val_loss: 0.7560 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7013 - acc: 0.5687 - val_loss: 0.7387 - val_acc: 0.4250\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6744 - acc: 0.5992 - val_loss: 0.7544 - val_acc: 0.4125\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6481 - acc: 0.6181 - val_loss: 0.7771 - val_acc: 0.4156\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6321 - acc: 0.6412 - val_loss: 0.8308 - val_acc: 0.4187\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6033 - acc: 0.6740 - val_loss: 0.8282 - val_acc: 0.5250\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5707 - acc: 0.7056 - val_loss: 0.8574 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5422 - acc: 0.7454 - val_loss: 0.9191 - val_acc: 0.4875\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5050 - acc: 0.7762 - val_loss: 1.0240 - val_acc: 0.4750\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4886 - acc: 0.7994 - val_loss: 0.9918 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4489 - acc: 0.8295 - val_loss: 1.2224 - val_acc: 0.4625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4302 - acc: 0.8353 - val_loss: 1.1454 - val_acc: 0.4938\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3973 - acc: 0.8526 - val_loss: 1.2107 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3778 - acc: 0.8758 - val_loss: 1.1894 - val_acc: 0.4938\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3695 - acc: 0.8839 - val_loss: 1.1627 - val_acc: 0.5281\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3326 - acc: 0.8993 - val_loss: 1.2962 - val_acc: 0.5156\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3496 - acc: 0.8935 - val_loss: 1.4068 - val_acc: 0.4781\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3220 - acc: 0.9020 - val_loss: 1.3472 - val_acc: 0.4875\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7809 - acc: 0.3406\n",
      "Test eval is  [0.78094881772995, 0.34062498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:26:07.456434: Finished Train Fold #71/500 - thus far subj acc is 0.4507042253521127 and regular acc is0.46232394181506736\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #72\n",
      "A1 :  2022-04-07 22:26:26.636832\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7865 - acc: 0.5409 - val_loss: 0.7598 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7379 - acc: 0.5432 - val_loss: 0.7297 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7102 - acc: 0.5432 - val_loss: 0.7290 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6939 - acc: 0.5517 - val_loss: 0.7140 - val_acc: 0.4531\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6798 - acc: 0.5687 - val_loss: 0.7169 - val_acc: 0.4875\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6607 - acc: 0.5988 - val_loss: 0.7394 - val_acc: 0.4156\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6405 - acc: 0.6188 - val_loss: 0.7939 - val_acc: 0.4437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6214 - acc: 0.6350 - val_loss: 0.8375 - val_acc: 0.4500\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5913 - acc: 0.6809 - val_loss: 0.8420 - val_acc: 0.4094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5701 - acc: 0.7180 - val_loss: 0.9379 - val_acc: 0.4500\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5354 - acc: 0.7720 - val_loss: 0.9305 - val_acc: 0.4812\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5055 - acc: 0.7921 - val_loss: 0.9750 - val_acc: 0.4531\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4702 - acc: 0.8291 - val_loss: 1.0053 - val_acc: 0.4812\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4622 - acc: 0.8314 - val_loss: 1.1433 - val_acc: 0.4563\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4365 - acc: 0.8492 - val_loss: 1.0439 - val_acc: 0.4688\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4133 - acc: 0.8634 - val_loss: 1.0694 - val_acc: 0.4938\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4039 - acc: 0.8576 - val_loss: 1.2309 - val_acc: 0.4656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3723 - acc: 0.8816 - val_loss: 1.3492 - val_acc: 0.4688\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3676 - acc: 0.8785 - val_loss: 1.3641 - val_acc: 0.4875\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3511 - acc: 0.8997 - val_loss: 1.2062 - val_acc: 0.4906\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7181 - acc: 0.3969\n",
      "Test eval is  [0.7180742025375366, 0.3968749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:26:38.205154: Finished Train Fold #72/500 - thus far subj acc is 0.44861111111111107 and regular acc is0.46063367856873405\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #73\n",
      "A1 :  2022-04-07 22:26:57.265978\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7903 - acc: 0.5359 - val_loss: 0.7624 - val_acc: 0.4906\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7397 - acc: 0.5567 - val_loss: 0.7354 - val_acc: 0.4594\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7040 - acc: 0.5810 - val_loss: 0.7171 - val_acc: 0.4750\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6836 - acc: 0.5999 - val_loss: 0.7288 - val_acc: 0.4594\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6680 - acc: 0.6200 - val_loss: 0.7221 - val_acc: 0.4219\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6485 - acc: 0.6458 - val_loss: 0.7783 - val_acc: 0.4406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6239 - acc: 0.6759 - val_loss: 0.7907 - val_acc: 0.4375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5928 - acc: 0.7022 - val_loss: 0.8668 - val_acc: 0.4563\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5720 - acc: 0.7292 - val_loss: 0.9162 - val_acc: 0.4625\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5349 - acc: 0.7751 - val_loss: 0.9464 - val_acc: 0.4844\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4969 - acc: 0.8029 - val_loss: 0.9836 - val_acc: 0.4469\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4519 - acc: 0.8387 - val_loss: 1.0124 - val_acc: 0.4313\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4446 - acc: 0.8380 - val_loss: 1.1306 - val_acc: 0.4750\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4272 - acc: 0.8511 - val_loss: 1.1237 - val_acc: 0.4625\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4076 - acc: 0.8708 - val_loss: 1.1317 - val_acc: 0.4938\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3895 - acc: 0.8727 - val_loss: 1.1595 - val_acc: 0.4875\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3643 - acc: 0.8939 - val_loss: 1.3627 - val_acc: 0.4812\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3345 - acc: 0.9059 - val_loss: 1.3415 - val_acc: 0.4938\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3474 - acc: 0.8974 - val_loss: 1.3328 - val_acc: 0.4906\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7214 - acc: 0.4625\n",
      "Test eval is  [0.7213846445083618, 0.4625000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:27:08.332885: Finished Train Fold #73/500 - thus far subj acc is 0.447945205479452 and regular acc is0.4597602719313478\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #74\n",
      "A1 :  2022-04-07 22:27:27.391022\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7928 - acc: 0.5216 - val_loss: 0.7719 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7405 - acc: 0.5374 - val_loss: 0.7393 - val_acc: 0.3969\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7109 - acc: 0.5552 - val_loss: 0.7209 - val_acc: 0.4062\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6804 - acc: 0.5938 - val_loss: 0.7326 - val_acc: 0.5562\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6561 - acc: 0.6281 - val_loss: 0.7517 - val_acc: 0.5844\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6308 - acc: 0.6721 - val_loss: 0.7441 - val_acc: 0.5312\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6022 - acc: 0.7068 - val_loss: 0.7950 - val_acc: 0.5437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5758 - acc: 0.7311 - val_loss: 0.8946 - val_acc: 0.5406\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5394 - acc: 0.7643 - val_loss: 0.8743 - val_acc: 0.5844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5144 - acc: 0.7936 - val_loss: 0.9645 - val_acc: 0.5719\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4866 - acc: 0.8079 - val_loss: 0.9351 - val_acc: 0.5500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4642 - acc: 0.8268 - val_loss: 1.0141 - val_acc: 0.5406\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4254 - acc: 0.8503 - val_loss: 1.0788 - val_acc: 0.5437\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4165 - acc: 0.8565 - val_loss: 1.0627 - val_acc: 0.4969\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4003 - acc: 0.8762 - val_loss: 1.1961 - val_acc: 0.5125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3751 - acc: 0.8846 - val_loss: 1.1889 - val_acc: 0.5031\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3630 - acc: 0.8873 - val_loss: 1.2204 - val_acc: 0.5469\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3503 - acc: 0.8970 - val_loss: 1.2423 - val_acc: 0.5406\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3445 - acc: 0.8989 - val_loss: 1.3212 - val_acc: 0.5437\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7235 - acc: 0.5375\n",
      "Test eval is  [0.7235301733016968, 0.5375000238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:27:38.449255: Finished Train Fold #74/500 - thus far subj acc is 0.4472972972972972 and regular acc is0.4597972953641737\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #75\n",
      "A1 :  2022-04-07 22:27:57.621885\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7910 - acc: 0.5255 - val_loss: 0.7627 - val_acc: 0.5281\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7426 - acc: 0.5525 - val_loss: 0.7316 - val_acc: 0.4594\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7104 - acc: 0.5745 - val_loss: 0.7602 - val_acc: 0.5312\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6865 - acc: 0.5965 - val_loss: 0.7462 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6584 - acc: 0.6431 - val_loss: 0.7650 - val_acc: 0.5031\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6436 - acc: 0.6682 - val_loss: 0.8272 - val_acc: 0.4781\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6059 - acc: 0.7191 - val_loss: 0.8430 - val_acc: 0.4906\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5684 - acc: 0.7512 - val_loss: 0.8626 - val_acc: 0.5312\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5440 - acc: 0.7801 - val_loss: 0.8742 - val_acc: 0.5344\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5061 - acc: 0.8005 - val_loss: 1.0546 - val_acc: 0.5031\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4632 - acc: 0.8403 - val_loss: 1.1766 - val_acc: 0.5031\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4406 - acc: 0.8573 - val_loss: 1.0775 - val_acc: 0.5094\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4168 - acc: 0.8696 - val_loss: 1.1371 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3905 - acc: 0.8831 - val_loss: 1.1722 - val_acc: 0.5156\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3829 - acc: 0.8981 - val_loss: 1.2423 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3576 - acc: 0.9062 - val_loss: 1.1579 - val_acc: 0.5063\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3486 - acc: 0.9105 - val_loss: 1.3057 - val_acc: 0.5031\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3210 - acc: 0.9286 - val_loss: 1.3028 - val_acc: 0.5125\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7280 - acc: 0.5625\n",
      "Test eval is  [0.728024423122406, 0.5625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:28:07.967004: Finished Train Fold #75/500 - thus far subj acc is 0.44933333333333325 and regular acc is0.46083333174387614\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #76\n",
      "A1 :  2022-04-07 22:28:27.141837\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7886 - acc: 0.5174 - val_loss: 0.7656 - val_acc: 0.3938\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7408 - acc: 0.5208 - val_loss: 0.7400 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7091 - acc: 0.5401 - val_loss: 0.7289 - val_acc: 0.4094\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6926 - acc: 0.5818 - val_loss: 0.7254 - val_acc: 0.4531\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6776 - acc: 0.5814 - val_loss: 0.7443 - val_acc: 0.4187\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6586 - acc: 0.6200 - val_loss: 0.8301 - val_acc: 0.4281\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6428 - acc: 0.6393 - val_loss: 0.7963 - val_acc: 0.4812\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6135 - acc: 0.6667 - val_loss: 0.9065 - val_acc: 0.4469\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5861 - acc: 0.7095 - val_loss: 0.8588 - val_acc: 0.4406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5553 - acc: 0.7450 - val_loss: 1.0097 - val_acc: 0.4656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5218 - acc: 0.7677 - val_loss: 0.9405 - val_acc: 0.4844\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4804 - acc: 0.8063 - val_loss: 0.9795 - val_acc: 0.5125\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4486 - acc: 0.8241 - val_loss: 1.1036 - val_acc: 0.5094\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4244 - acc: 0.8407 - val_loss: 0.9640 - val_acc: 0.5469\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4039 - acc: 0.8592 - val_loss: 1.2433 - val_acc: 0.4844\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3840 - acc: 0.8673 - val_loss: 1.1147 - val_acc: 0.5375\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3349 - acc: 0.9032 - val_loss: 1.2737 - val_acc: 0.5188\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3244 - acc: 0.9016 - val_loss: 1.2871 - val_acc: 0.5156\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3207 - acc: 0.9113 - val_loss: 1.2433 - val_acc: 0.5531\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2927 - acc: 0.9225 - val_loss: 1.3054 - val_acc: 0.5375\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6942 - acc: 0.6000\n",
      "Test eval is  [0.694244384765625, 0.6000000238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:28:38.575515: Finished Train Fold #76/500 - thus far subj acc is 0.45131578947368417 and regular acc is0.4621710510630357\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #77\n",
      "A1 :  2022-04-07 22:28:57.561229\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7767 - acc: 0.5274 - val_loss: 0.7512 - val_acc: 0.4875\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7300 - acc: 0.5340 - val_loss: 0.7237 - val_acc: 0.4844\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7069 - acc: 0.5648 - val_loss: 0.7152 - val_acc: 0.4969\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6838 - acc: 0.5907 - val_loss: 0.7389 - val_acc: 0.5031\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6650 - acc: 0.6269 - val_loss: 0.8536 - val_acc: 0.5312\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6384 - acc: 0.6439 - val_loss: 0.7816 - val_acc: 0.5469\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6114 - acc: 0.6883 - val_loss: 0.8049 - val_acc: 0.5781\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5699 - acc: 0.7380 - val_loss: 0.8760 - val_acc: 0.5281\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5325 - acc: 0.7658 - val_loss: 0.8983 - val_acc: 0.5188\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5076 - acc: 0.7905 - val_loss: 0.9408 - val_acc: 0.5594\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4628 - acc: 0.8260 - val_loss: 1.0982 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4450 - acc: 0.8410 - val_loss: 0.9826 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4110 - acc: 0.8642 - val_loss: 1.0796 - val_acc: 0.5219\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3779 - acc: 0.8816 - val_loss: 1.1804 - val_acc: 0.5156\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3677 - acc: 0.8839 - val_loss: 1.2020 - val_acc: 0.5125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3543 - acc: 0.8935 - val_loss: 1.3006 - val_acc: 0.5125\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3355 - acc: 0.9039 - val_loss: 1.2837 - val_acc: 0.5188\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3089 - acc: 0.9209 - val_loss: 1.3407 - val_acc: 0.5094\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3106 - acc: 0.9140 - val_loss: 1.3127 - val_acc: 0.5125\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7249 - acc: 0.4531\n",
      "Test eval is  [0.724895179271698, 0.453125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:29:08.405147: Finished Train Fold #77/500 - thus far subj acc is 0.4558441558441558 and regular acc is0.4639610377225009\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #78\n",
      "A1 :  2022-04-07 22:29:27.696677\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7791 - acc: 0.5509 - val_loss: 0.7575 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7308 - acc: 0.5563 - val_loss: 0.7271 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7034 - acc: 0.5579 - val_loss: 0.7108 - val_acc: 0.5031\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6869 - acc: 0.5702 - val_loss: 0.7088 - val_acc: 0.4719\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6689 - acc: 0.5918 - val_loss: 0.7163 - val_acc: 0.4563\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6514 - acc: 0.6111 - val_loss: 0.7468 - val_acc: 0.4500\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6306 - acc: 0.6528 - val_loss: 0.8105 - val_acc: 0.4437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6014 - acc: 0.6767 - val_loss: 0.9573 - val_acc: 0.4812\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5659 - acc: 0.7203 - val_loss: 0.9159 - val_acc: 0.5344\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5358 - acc: 0.7542 - val_loss: 1.0039 - val_acc: 0.4625\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5082 - acc: 0.7793 - val_loss: 1.0212 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4842 - acc: 0.7978 - val_loss: 1.0512 - val_acc: 0.4781\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4494 - acc: 0.8225 - val_loss: 1.1971 - val_acc: 0.4781\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4279 - acc: 0.8337 - val_loss: 1.1744 - val_acc: 0.4656\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4002 - acc: 0.8576 - val_loss: 1.2710 - val_acc: 0.4812\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3723 - acc: 0.8646 - val_loss: 1.3262 - val_acc: 0.5281\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3621 - acc: 0.8758 - val_loss: 1.2188 - val_acc: 0.4906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3430 - acc: 0.8939 - val_loss: 1.3283 - val_acc: 0.4594\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3275 - acc: 0.8985 - val_loss: 1.5236 - val_acc: 0.4719\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2998 - acc: 0.9074 - val_loss: 1.4208 - val_acc: 0.4875\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7698 - acc: 0.3156\n",
      "Test eval is  [0.7698444128036499, 0.31562501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:29:39.448716: Finished Train Fold #78/500 - thus far subj acc is 0.45641025641025634 and regular acc is0.463822114161956\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #79\n",
      "A1 :  2022-04-07 22:29:58.609426\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7942 - acc: 0.5112 - val_loss: 0.7653 - val_acc: 0.4781\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7416 - acc: 0.5363 - val_loss: 0.7348 - val_acc: 0.4844\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7073 - acc: 0.5529 - val_loss: 0.7312 - val_acc: 0.4625\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6812 - acc: 0.6011 - val_loss: 0.7897 - val_acc: 0.4219\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6608 - acc: 0.6192 - val_loss: 0.8601 - val_acc: 0.4125\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6390 - acc: 0.6265 - val_loss: 0.8815 - val_acc: 0.3969\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6277 - acc: 0.6647 - val_loss: 0.8506 - val_acc: 0.4500\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5996 - acc: 0.6875 - val_loss: 0.9172 - val_acc: 0.4250\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5690 - acc: 0.7234 - val_loss: 0.9717 - val_acc: 0.4000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5407 - acc: 0.7577 - val_loss: 1.0230 - val_acc: 0.4281\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5130 - acc: 0.7812 - val_loss: 0.9532 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4870 - acc: 0.8029 - val_loss: 1.0901 - val_acc: 0.4750\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4633 - acc: 0.8241 - val_loss: 1.0516 - val_acc: 0.4875\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4358 - acc: 0.8387 - val_loss: 1.0737 - val_acc: 0.4938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4133 - acc: 0.8546 - val_loss: 1.2297 - val_acc: 0.4875\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3870 - acc: 0.8623 - val_loss: 1.1690 - val_acc: 0.5250\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3712 - acc: 0.8777 - val_loss: 1.2288 - val_acc: 0.4969\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3444 - acc: 0.8900 - val_loss: 1.3240 - val_acc: 0.5063\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3571 - acc: 0.8916 - val_loss: 1.2173 - val_acc: 0.4938\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7047 - acc: 0.5125\n",
      "Test eval is  [0.7047131061553955, 0.512499988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:30:09.611817: Finished Train Fold #79/500 - thus far subj acc is 0.4544303797468353 and regular acc is0.46194620147536075\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #80\n",
      "A1 :  2022-04-07 22:30:28.737785\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8025 - acc: 0.5397 - val_loss: 0.7705 - val_acc: 0.5094\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7460 - acc: 0.5502 - val_loss: 0.7330 - val_acc: 0.5531\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7032 - acc: 0.6096 - val_loss: 0.7412 - val_acc: 0.5219\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6537 - acc: 0.6466 - val_loss: 0.8204 - val_acc: 0.5281\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6374 - acc: 0.6701 - val_loss: 0.7787 - val_acc: 0.4969\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5936 - acc: 0.7103 - val_loss: 0.8416 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5639 - acc: 0.7330 - val_loss: 0.8600 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5221 - acc: 0.7820 - val_loss: 0.8673 - val_acc: 0.5437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4908 - acc: 0.8048 - val_loss: 1.0099 - val_acc: 0.4875\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4509 - acc: 0.8295 - val_loss: 1.1064 - val_acc: 0.5469\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4291 - acc: 0.8395 - val_loss: 1.0760 - val_acc: 0.5625\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3962 - acc: 0.8650 - val_loss: 1.2136 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3731 - acc: 0.8781 - val_loss: 1.1364 - val_acc: 0.5219\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3796 - acc: 0.8800 - val_loss: 1.2267 - val_acc: 0.4688\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3277 - acc: 0.9055 - val_loss: 1.2491 - val_acc: 0.5531\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3204 - acc: 0.9097 - val_loss: 1.2021 - val_acc: 0.5562\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3058 - acc: 0.9144 - val_loss: 1.4564 - val_acc: 0.5031\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3101 - acc: 0.9140 - val_loss: 1.3593 - val_acc: 0.5312\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7528 - acc: 0.4031\n",
      "Test eval is  [0.7527727484703064, 0.40312498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:30:39.250060: Finished Train Fold #80/500 - thus far subj acc is 0.4549999999999999 and regular acc is0.4625781238079071\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #81\n",
      "A1 :  2022-04-07 22:30:58.177781\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7882 - acc: 0.5363 - val_loss: 0.7614 - val_acc: 0.4875\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7387 - acc: 0.5401 - val_loss: 0.7319 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7094 - acc: 0.5633 - val_loss: 0.7298 - val_acc: 0.4531\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6841 - acc: 0.6042 - val_loss: 0.7379 - val_acc: 0.4688\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6561 - acc: 0.6308 - val_loss: 0.7884 - val_acc: 0.4844\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6249 - acc: 0.6817 - val_loss: 0.8052 - val_acc: 0.5031\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6052 - acc: 0.6833 - val_loss: 0.8277 - val_acc: 0.5500\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5696 - acc: 0.7361 - val_loss: 0.9178 - val_acc: 0.4750\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5361 - acc: 0.7608 - val_loss: 0.8650 - val_acc: 0.5469\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4970 - acc: 0.7951 - val_loss: 1.0132 - val_acc: 0.5063\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4622 - acc: 0.8233 - val_loss: 0.9643 - val_acc: 0.4875\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4275 - acc: 0.8441 - val_loss: 1.2215 - val_acc: 0.4500\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4210 - acc: 0.8503 - val_loss: 1.0763 - val_acc: 0.4469\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3976 - acc: 0.8600 - val_loss: 1.2174 - val_acc: 0.4563\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3775 - acc: 0.8735 - val_loss: 1.3675 - val_acc: 0.4125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3538 - acc: 0.8812 - val_loss: 1.4926 - val_acc: 0.4469\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3413 - acc: 0.8951 - val_loss: 1.4804 - val_acc: 0.4219\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3278 - acc: 0.8985 - val_loss: 1.4064 - val_acc: 0.5063\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3073 - acc: 0.9128 - val_loss: 1.4007 - val_acc: 0.4469\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7332 - acc: 0.4938\n",
      "Test eval is  [0.7331516146659851, 0.4937500059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:31:09.299327: Finished Train Fold #81/500 - thus far subj acc is 0.4543209876543209 and regular acc is0.4618441344779215\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #82\n",
      "A1 :  2022-04-07 22:31:28.398111\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8011 - acc: 0.5340 - val_loss: 0.7726 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7455 - acc: 0.5451 - val_loss: 0.7391 - val_acc: 0.4969\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7056 - acc: 0.5880 - val_loss: 0.7395 - val_acc: 0.4500\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.6119 - val_loss: 0.7188 - val_acc: 0.4688\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6434 - acc: 0.6439 - val_loss: 0.7748 - val_acc: 0.5156\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6124 - acc: 0.6755 - val_loss: 0.7881 - val_acc: 0.5344\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5796 - acc: 0.7157 - val_loss: 0.8333 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5425 - acc: 0.7438 - val_loss: 0.9149 - val_acc: 0.4500\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5190 - acc: 0.7585 - val_loss: 0.8941 - val_acc: 0.4938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4771 - acc: 0.7990 - val_loss: 0.9591 - val_acc: 0.4938\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4536 - acc: 0.8175 - val_loss: 0.9684 - val_acc: 0.5188\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4290 - acc: 0.8441 - val_loss: 0.9778 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4078 - acc: 0.8580 - val_loss: 1.0448 - val_acc: 0.5344\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3863 - acc: 0.8723 - val_loss: 1.0551 - val_acc: 0.5031\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3574 - acc: 0.8854 - val_loss: 1.3213 - val_acc: 0.4750\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3385 - acc: 0.9005 - val_loss: 1.1548 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3195 - acc: 0.9070 - val_loss: 1.1909 - val_acc: 0.5562\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3108 - acc: 0.9128 - val_loss: 1.2638 - val_acc: 0.5219\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3152 - acc: 0.9062 - val_loss: 1.4012 - val_acc: 0.5063\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2905 - acc: 0.9240 - val_loss: 1.4282 - val_acc: 0.5156\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8146 - acc: 0.3688\n",
      "Test eval is  [0.8145801424980164, 0.3687500059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:31:39.999842: Finished Train Fold #82/500 - thus far subj acc is 0.4548780487804877 and regular acc is0.462233230471611\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #83\n",
      "A1 :  2022-04-07 22:31:58.883067\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7784 - acc: 0.5336 - val_loss: 0.7528 - val_acc: 0.5094\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7275 - acc: 0.5702 - val_loss: 0.7382 - val_acc: 0.5063\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6891 - acc: 0.6161 - val_loss: 0.8256 - val_acc: 0.5094\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6595 - acc: 0.6489 - val_loss: 0.7849 - val_acc: 0.5188\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6369 - acc: 0.6582 - val_loss: 0.9361 - val_acc: 0.5281\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6048 - acc: 0.6952 - val_loss: 0.8495 - val_acc: 0.4812\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5757 - acc: 0.7218 - val_loss: 0.9306 - val_acc: 0.5031\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5472 - acc: 0.7496 - val_loss: 1.0007 - val_acc: 0.5031\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5062 - acc: 0.7886 - val_loss: 1.0574 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4712 - acc: 0.8079 - val_loss: 0.9995 - val_acc: 0.5656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4393 - acc: 0.8341 - val_loss: 1.0490 - val_acc: 0.5219\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4079 - acc: 0.8588 - val_loss: 1.1296 - val_acc: 0.5500\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3814 - acc: 0.8711 - val_loss: 1.4258 - val_acc: 0.5031\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3684 - acc: 0.8889 - val_loss: 1.2829 - val_acc: 0.5344\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3609 - acc: 0.8881 - val_loss: 1.2645 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3294 - acc: 0.9032 - val_loss: 1.3291 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3012 - acc: 0.9178 - val_loss: 1.3747 - val_acc: 0.5156\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2993 - acc: 0.9178 - val_loss: 1.4526 - val_acc: 0.5219\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7330 - acc: 0.4938\n",
      "Test eval is  [0.7329990267753601, 0.4937500059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:32:09.603601: Finished Train Fold #83/500 - thus far subj acc is 0.4530120481927709 and regular acc is0.46110692656183816\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #84\n",
      "A1 :  2022-04-07 22:32:28.696755\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7891 - acc: 0.5274 - val_loss: 0.7590 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7381 - acc: 0.5409 - val_loss: 0.7229 - val_acc: 0.5719\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7068 - acc: 0.5679 - val_loss: 0.7153 - val_acc: 0.5031\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6780 - acc: 0.5837 - val_loss: 0.7257 - val_acc: 0.4969\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6546 - acc: 0.6173 - val_loss: 0.7598 - val_acc: 0.4563\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6264 - acc: 0.6435 - val_loss: 0.8007 - val_acc: 0.4719\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6037 - acc: 0.6914 - val_loss: 0.8583 - val_acc: 0.4313\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5725 - acc: 0.7234 - val_loss: 0.9454 - val_acc: 0.4375\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5445 - acc: 0.7581 - val_loss: 0.9072 - val_acc: 0.4344\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5161 - acc: 0.7762 - val_loss: 0.9488 - val_acc: 0.4500\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4872 - acc: 0.7948 - val_loss: 1.1224 - val_acc: 0.4500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4639 - acc: 0.8198 - val_loss: 1.0060 - val_acc: 0.4812\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4354 - acc: 0.8395 - val_loss: 1.2260 - val_acc: 0.4281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4219 - acc: 0.8526 - val_loss: 1.0846 - val_acc: 0.4844\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4301 - acc: 0.8434 - val_loss: 1.0254 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3952 - acc: 0.8600 - val_loss: 1.0982 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3754 - acc: 0.8800 - val_loss: 1.1113 - val_acc: 0.5094\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3603 - acc: 0.8870 - val_loss: 1.1721 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3319 - acc: 0.8947 - val_loss: 1.2480 - val_acc: 0.4938\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7373 - acc: 0.4156\n",
      "Test eval is  [0.73728346824646, 0.4156250059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:32:39.986213: Finished Train Fold #84/500 - thus far subj acc is 0.45476190476190465 and regular acc is0.46149553464991705\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #85\n",
      "A1 :  2022-04-07 22:32:59.076605\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7827 - acc: 0.5332 - val_loss: 0.7548 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7313 - acc: 0.5305 - val_loss: 0.7269 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7046 - acc: 0.5309 - val_loss: 0.7147 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6794 - acc: 0.5436 - val_loss: 0.7079 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6659 - acc: 0.6250 - val_loss: 0.7140 - val_acc: 0.4437\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6444 - acc: 0.6582 - val_loss: 0.6983 - val_acc: 0.5531\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6297 - acc: 0.6848 - val_loss: 0.7487 - val_acc: 0.5156\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6131 - acc: 0.6998 - val_loss: 0.7278 - val_acc: 0.5562\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5929 - acc: 0.7226 - val_loss: 0.7092 - val_acc: 0.5250\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5809 - acc: 0.7450 - val_loss: 0.7317 - val_acc: 0.5125\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5530 - acc: 0.7735 - val_loss: 0.7911 - val_acc: 0.5531\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5462 - acc: 0.7774 - val_loss: 0.8241 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5189 - acc: 0.8013 - val_loss: 0.8181 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5010 - acc: 0.8144 - val_loss: 0.7886 - val_acc: 0.5281\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4968 - acc: 0.8140 - val_loss: 0.8155 - val_acc: 0.5281\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4801 - acc: 0.8287 - val_loss: 0.8697 - val_acc: 0.5312\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4657 - acc: 0.8322 - val_loss: 0.7905 - val_acc: 0.5625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4534 - acc: 0.8430 - val_loss: 0.9526 - val_acc: 0.5312\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4594 - acc: 0.8368 - val_loss: 0.8596 - val_acc: 0.5312\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4460 - acc: 0.8457 - val_loss: 0.8890 - val_acc: 0.5594\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1922 - acc: 0.4656\n",
      "Test eval is  [1.1921718120574951, 0.46562498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:33:10.456986: Finished Train Fold #85/500 - thus far subj acc is 0.4541176470588234 and regular acc is0.4609558813712176\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #86\n",
      "A1 :  2022-04-07 22:33:29.395666\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7995 - acc: 0.5316 - val_loss: 0.7687 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7451 - acc: 0.5525 - val_loss: 0.7368 - val_acc: 0.4688\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7139 - acc: 0.5625 - val_loss: 0.7190 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6917 - acc: 0.5814 - val_loss: 0.7909 - val_acc: 0.4313\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6795 - acc: 0.5999 - val_loss: 0.7818 - val_acc: 0.4219\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6709 - acc: 0.6073 - val_loss: 0.7845 - val_acc: 0.4219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6572 - acc: 0.6235 - val_loss: 0.8348 - val_acc: 0.4062\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6478 - acc: 0.6381 - val_loss: 0.9031 - val_acc: 0.4062\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6266 - acc: 0.6659 - val_loss: 0.9144 - val_acc: 0.4000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6075 - acc: 0.6821 - val_loss: 1.0581 - val_acc: 0.4344\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5817 - acc: 0.7238 - val_loss: 1.0146 - val_acc: 0.4500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5484 - acc: 0.7473 - val_loss: 1.1557 - val_acc: 0.4688\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5307 - acc: 0.7693 - val_loss: 1.1131 - val_acc: 0.4719\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5064 - acc: 0.7812 - val_loss: 1.0651 - val_acc: 0.4750\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4736 - acc: 0.8156 - val_loss: 1.1420 - val_acc: 0.4719\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4466 - acc: 0.8202 - val_loss: 1.2373 - val_acc: 0.4563\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4272 - acc: 0.8364 - val_loss: 1.2827 - val_acc: 0.4812\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4046 - acc: 0.8611 - val_loss: 1.1255 - val_acc: 0.4531\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3949 - acc: 0.8607 - val_loss: 1.2593 - val_acc: 0.4938\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7276 - acc: 0.4000\n",
      "Test eval is  [0.7275630831718445, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:33:40.439831: Finished Train Fold #86/500 - thus far subj acc is 0.4534883720930231 and regular acc is0.461010173309681\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #87\n",
      "A1 :  2022-04-07 22:33:59.501502\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7731 - acc: 0.5247 - val_loss: 0.7481 - val_acc: 0.5406\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7299 - acc: 0.5343 - val_loss: 0.7217 - val_acc: 0.4875\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6996 - acc: 0.5795 - val_loss: 0.7166 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6730 - acc: 0.6161 - val_loss: 0.7447 - val_acc: 0.5188\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6546 - acc: 0.6308 - val_loss: 0.7608 - val_acc: 0.5063\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6231 - acc: 0.6929 - val_loss: 0.7493 - val_acc: 0.5156\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5871 - acc: 0.7215 - val_loss: 0.7398 - val_acc: 0.5469\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5547 - acc: 0.7620 - val_loss: 0.8288 - val_acc: 0.5625\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5178 - acc: 0.7940 - val_loss: 0.8525 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4919 - acc: 0.8144 - val_loss: 0.8572 - val_acc: 0.5156\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4571 - acc: 0.8387 - val_loss: 0.9253 - val_acc: 0.5219\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4561 - acc: 0.8368 - val_loss: 0.9964 - val_acc: 0.5156\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4228 - acc: 0.8646 - val_loss: 1.0467 - val_acc: 0.5406\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3788 - acc: 0.8893 - val_loss: 1.0817 - val_acc: 0.5531\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3542 - acc: 0.8947 - val_loss: 1.1204 - val_acc: 0.5188\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3484 - acc: 0.8958 - val_loss: 1.1426 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3203 - acc: 0.9159 - val_loss: 1.0861 - val_acc: 0.5437\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3081 - acc: 0.9244 - val_loss: 1.3051 - val_acc: 0.5375\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2944 - acc: 0.9309 - val_loss: 1.4503 - val_acc: 0.5000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7175 - acc: 0.4906\n",
      "Test eval is  [0.7175456881523132, 0.4906249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:34:10.616369: Finished Train Fold #87/500 - thus far subj acc is 0.4528735632183906 and regular acc is0.46030890701831073\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #88\n",
      "A1 :  2022-04-07 22:34:29.733665\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7833 - acc: 0.5116 - val_loss: 0.7547 - val_acc: 0.5063\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7373 - acc: 0.5270 - val_loss: 0.7247 - val_acc: 0.4750\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7126 - acc: 0.5525 - val_loss: 0.7168 - val_acc: 0.5406\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6930 - acc: 0.5903 - val_loss: 0.7614 - val_acc: 0.5031\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6593 - acc: 0.6177 - val_loss: 0.8541 - val_acc: 0.5094\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6263 - acc: 0.6802 - val_loss: 0.8517 - val_acc: 0.5594\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5976 - acc: 0.7060 - val_loss: 0.8953 - val_acc: 0.5250\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5580 - acc: 0.7411 - val_loss: 0.9721 - val_acc: 0.5063\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5116 - acc: 0.7851 - val_loss: 1.0087 - val_acc: 0.5219\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4880 - acc: 0.8133 - val_loss: 0.9634 - val_acc: 0.5094\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4429 - acc: 0.8468 - val_loss: 1.0856 - val_acc: 0.5156\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4220 - acc: 0.8499 - val_loss: 1.0541 - val_acc: 0.5469\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3878 - acc: 0.8727 - val_loss: 1.2137 - val_acc: 0.5406\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3812 - acc: 0.8823 - val_loss: 1.1360 - val_acc: 0.5156\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3409 - acc: 0.9082 - val_loss: 1.2821 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3341 - acc: 0.9093 - val_loss: 1.1954 - val_acc: 0.5094\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3192 - acc: 0.9124 - val_loss: 1.3285 - val_acc: 0.5125\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3039 - acc: 0.9120 - val_loss: 1.2589 - val_acc: 0.5562\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3061 - acc: 0.9213 - val_loss: 1.3322 - val_acc: 0.5250\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7142 - acc: 0.4719\n",
      "Test eval is  [0.7141901254653931, 0.47187501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:34:40.963179: Finished Train Fold #88/500 - thus far subj acc is 0.4534090909090909 and regular acc is0.4606534080071883\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #89\n",
      "A1 :  2022-04-07 22:35:00.184083\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7894 - acc: 0.5401 - val_loss: 0.7607 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7390 - acc: 0.5459 - val_loss: 0.7280 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7085 - acc: 0.5799 - val_loss: 0.7226 - val_acc: 0.5094\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6810 - acc: 0.6111 - val_loss: 0.7379 - val_acc: 0.5063\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6619 - acc: 0.6362 - val_loss: 0.7590 - val_acc: 0.4969\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6552 - acc: 0.6400 - val_loss: 0.7736 - val_acc: 0.4625\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6443 - acc: 0.6535 - val_loss: 0.7544 - val_acc: 0.5250\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6227 - acc: 0.6809 - val_loss: 0.8283 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5969 - acc: 0.7022 - val_loss: 0.8231 - val_acc: 0.5406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5819 - acc: 0.7149 - val_loss: 0.9114 - val_acc: 0.4875\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5660 - acc: 0.7350 - val_loss: 0.8635 - val_acc: 0.4656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5557 - acc: 0.7469 - val_loss: 0.9204 - val_acc: 0.5094\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5275 - acc: 0.7658 - val_loss: 0.9222 - val_acc: 0.5063\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5049 - acc: 0.7886 - val_loss: 0.9350 - val_acc: 0.5094\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4851 - acc: 0.7986 - val_loss: 0.9893 - val_acc: 0.4656\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4770 - acc: 0.8067 - val_loss: 1.0667 - val_acc: 0.4844\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4577 - acc: 0.8241 - val_loss: 1.1653 - val_acc: 0.4688\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4667 - acc: 0.8125 - val_loss: 1.0338 - val_acc: 0.4750\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4499 - acc: 0.8218 - val_loss: 1.1183 - val_acc: 0.4656\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7886 - acc: 0.3313\n",
      "Test eval is  [0.7885853052139282, 0.33125001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:35:11.347403: Finished Train Fold #89/500 - thus far subj acc is 0.4550561797752809 and regular acc is0.4607794934444213\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #90\n",
      "A1 :  2022-04-07 22:35:30.493259\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7781 - acc: 0.5185 - val_loss: 0.7519 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7333 - acc: 0.5355 - val_loss: 0.7220 - val_acc: 0.5344\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7129 - acc: 0.5367 - val_loss: 0.7100 - val_acc: 0.4938\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6997 - acc: 0.5525 - val_loss: 0.7142 - val_acc: 0.4656\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6909 - acc: 0.5814 - val_loss: 0.7106 - val_acc: 0.4906\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6797 - acc: 0.6022 - val_loss: 0.7704 - val_acc: 0.4688\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6689 - acc: 0.6169 - val_loss: 0.8203 - val_acc: 0.4250\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6436 - acc: 0.6590 - val_loss: 0.8178 - val_acc: 0.4563\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6307 - acc: 0.6717 - val_loss: 0.8905 - val_acc: 0.4812\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6058 - acc: 0.6995 - val_loss: 0.8261 - val_acc: 0.5094\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5723 - acc: 0.7454 - val_loss: 0.9635 - val_acc: 0.4594\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5365 - acc: 0.7639 - val_loss: 0.9030 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4998 - acc: 0.7994 - val_loss: 0.9117 - val_acc: 0.5125\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4794 - acc: 0.8117 - val_loss: 0.9215 - val_acc: 0.5094\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4604 - acc: 0.8214 - val_loss: 1.1110 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4415 - acc: 0.8295 - val_loss: 1.0653 - val_acc: 0.5281\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4008 - acc: 0.8642 - val_loss: 1.1892 - val_acc: 0.5188\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3923 - acc: 0.8619 - val_loss: 1.3148 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3837 - acc: 0.8735 - val_loss: 1.1139 - val_acc: 0.5375\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7076 - acc: 0.5031\n",
      "Test eval is  [0.7075561285018921, 0.503125011920929]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:35:41.557019: Finished Train Fold #90/500 - thus far subj acc is 0.4533333333333333 and regular acc is0.4593402769830492\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #91\n",
      "A1 :  2022-04-07 22:36:00.691182\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8031 - acc: 0.5451 - val_loss: 0.7740 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7448 - acc: 0.5544 - val_loss: 0.7390 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7097 - acc: 0.5556 - val_loss: 0.7344 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6809 - acc: 0.5741 - val_loss: 0.7265 - val_acc: 0.4563\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6561 - acc: 0.6038 - val_loss: 0.7543 - val_acc: 0.4313\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6366 - acc: 0.6339 - val_loss: 0.7313 - val_acc: 0.5125\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6121 - acc: 0.6551 - val_loss: 0.8017 - val_acc: 0.4688\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5738 - acc: 0.7110 - val_loss: 0.8051 - val_acc: 0.5250\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5472 - acc: 0.7392 - val_loss: 0.8755 - val_acc: 0.5406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5322 - acc: 0.7731 - val_loss: 0.9049 - val_acc: 0.4875\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4793 - acc: 0.8090 - val_loss: 1.1854 - val_acc: 0.4594\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4506 - acc: 0.8302 - val_loss: 1.0757 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4073 - acc: 0.8596 - val_loss: 1.0797 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4046 - acc: 0.8515 - val_loss: 1.1430 - val_acc: 0.5594\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3879 - acc: 0.8708 - val_loss: 1.2149 - val_acc: 0.5375\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3463 - acc: 0.8978 - val_loss: 1.4069 - val_acc: 0.5031\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3409 - acc: 0.8981 - val_loss: 1.3580 - val_acc: 0.5156\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3255 - acc: 0.9001 - val_loss: 1.4787 - val_acc: 0.4750\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3313 - acc: 0.9039 - val_loss: 1.1912 - val_acc: 0.5375\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3091 - acc: 0.9105 - val_loss: 1.5223 - val_acc: 0.4875\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8234 - acc: 0.4000\n",
      "Test eval is  [0.8234447240829468, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:36:12.283129: Finished Train Fold #91/500 - thus far subj acc is 0.4538461538461538 and regular acc is0.4598214279164325\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #92\n",
      "A1 :  2022-04-07 22:36:31.578400\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7880 - acc: 0.5274 - val_loss: 0.7653 - val_acc: 0.3969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7391 - acc: 0.5451 - val_loss: 0.7334 - val_acc: 0.4500\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7091 - acc: 0.5710 - val_loss: 0.7160 - val_acc: 0.4812\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6905 - acc: 0.5899 - val_loss: 0.7096 - val_acc: 0.4812\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6694 - acc: 0.6173 - val_loss: 0.7272 - val_acc: 0.4344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6548 - acc: 0.6265 - val_loss: 0.7535 - val_acc: 0.4187\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6398 - acc: 0.6485 - val_loss: 0.7601 - val_acc: 0.4656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6168 - acc: 0.6647 - val_loss: 0.7975 - val_acc: 0.4281\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5912 - acc: 0.6995 - val_loss: 0.8881 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5676 - acc: 0.7257 - val_loss: 0.9374 - val_acc: 0.4250\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5402 - acc: 0.7589 - val_loss: 0.9757 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5035 - acc: 0.7990 - val_loss: 0.9990 - val_acc: 0.4031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4857 - acc: 0.7944 - val_loss: 0.9897 - val_acc: 0.5031\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4643 - acc: 0.8241 - val_loss: 0.9700 - val_acc: 0.4969\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4258 - acc: 0.8526 - val_loss: 1.2583 - val_acc: 0.4344\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3848 - acc: 0.8669 - val_loss: 1.2738 - val_acc: 0.4531\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3834 - acc: 0.8808 - val_loss: 1.4078 - val_acc: 0.4812\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3678 - acc: 0.8881 - val_loss: 1.2367 - val_acc: 0.4781\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3617 - acc: 0.8812 - val_loss: 1.2811 - val_acc: 0.4594\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3348 - acc: 0.9047 - val_loss: 1.3568 - val_acc: 0.4437\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7248 - acc: 0.5781\n",
      "Test eval is  [0.7248193621635437, 0.578125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:36:43.238046: Finished Train Fold #92/500 - thus far subj acc is 0.4521739130434782 and regular acc is0.459171195069085\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #93\n",
      "A1 :  2022-04-07 22:37:02.217860\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7846 - acc: 0.5181 - val_loss: 0.7591 - val_acc: 0.5063\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7334 - acc: 0.5698 - val_loss: 0.7299 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6927 - acc: 0.6007 - val_loss: 0.7492 - val_acc: 0.4969\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6595 - acc: 0.6397 - val_loss: 0.8077 - val_acc: 0.4625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6231 - acc: 0.6790 - val_loss: 0.8967 - val_acc: 0.4594\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5994 - acc: 0.6948 - val_loss: 0.8667 - val_acc: 0.4469\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5610 - acc: 0.7361 - val_loss: 0.9518 - val_acc: 0.4375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5083 - acc: 0.7851 - val_loss: 0.9836 - val_acc: 0.4812\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4851 - acc: 0.8040 - val_loss: 1.1265 - val_acc: 0.4500\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4394 - acc: 0.8341 - val_loss: 1.1812 - val_acc: 0.4656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4253 - acc: 0.8488 - val_loss: 1.1013 - val_acc: 0.4844\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3958 - acc: 0.8654 - val_loss: 1.1963 - val_acc: 0.4906\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3566 - acc: 0.8916 - val_loss: 1.3536 - val_acc: 0.4781\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3360 - acc: 0.9039 - val_loss: 1.3473 - val_acc: 0.4844\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2932 - acc: 0.9240 - val_loss: 1.4321 - val_acc: 0.5125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3074 - acc: 0.9140 - val_loss: 1.4593 - val_acc: 0.4594\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2948 - acc: 0.9244 - val_loss: 1.4502 - val_acc: 0.4844\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2723 - acc: 0.9321 - val_loss: 1.3867 - val_acc: 0.5063\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.4594\n",
      "Test eval is  [0.7389499545097351, 0.4593749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:37:12.826214: Finished Train Fold #93/500 - thus far subj acc is 0.4516129032258064 and regular acc is0.46045026824038515\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #94\n",
      "A1 :  2022-04-07 22:37:31.905558\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7955 - acc: 0.5440 - val_loss: 0.7660 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7412 - acc: 0.5556 - val_loss: 0.7314 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7122 - acc: 0.5640 - val_loss: 0.7159 - val_acc: 0.4969\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6908 - acc: 0.5860 - val_loss: 0.7172 - val_acc: 0.5031\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6730 - acc: 0.6007 - val_loss: 0.7596 - val_acc: 0.4875\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6615 - acc: 0.6231 - val_loss: 0.7217 - val_acc: 0.4750\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6380 - acc: 0.6566 - val_loss: 0.7518 - val_acc: 0.5063\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6136 - acc: 0.6937 - val_loss: 0.7649 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5917 - acc: 0.7176 - val_loss: 0.8129 - val_acc: 0.4500\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5662 - acc: 0.7461 - val_loss: 0.8327 - val_acc: 0.4875\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5287 - acc: 0.7724 - val_loss: 0.8864 - val_acc: 0.4812\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4963 - acc: 0.7948 - val_loss: 0.8900 - val_acc: 0.5188\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4591 - acc: 0.8233 - val_loss: 0.9602 - val_acc: 0.5125\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4396 - acc: 0.8492 - val_loss: 0.9597 - val_acc: 0.4906\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4257 - acc: 0.8414 - val_loss: 1.0833 - val_acc: 0.4844\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3927 - acc: 0.8700 - val_loss: 1.1657 - val_acc: 0.4906\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3796 - acc: 0.8731 - val_loss: 1.2607 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3567 - acc: 0.8920 - val_loss: 1.2562 - val_acc: 0.4781\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3481 - acc: 0.8947 - val_loss: 1.2911 - val_acc: 0.4750\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7553 - acc: 0.2812\n",
      "Test eval is  [0.7553342580795288, 0.28125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:37:43.066188: Finished Train Fold #94/500 - thus far subj acc is 0.45106382978723397 and regular acc is0.4604388291531421\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #95\n",
      "A1 :  2022-04-07 22:38:02.382436\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7855 - acc: 0.5096 - val_loss: 0.7578 - val_acc: 0.4563\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7394 - acc: 0.5266 - val_loss: 0.7266 - val_acc: 0.4750\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7144 - acc: 0.5721 - val_loss: 0.7161 - val_acc: 0.4844\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6943 - acc: 0.5930 - val_loss: 0.7241 - val_acc: 0.3750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6770 - acc: 0.6165 - val_loss: 0.7494 - val_acc: 0.4656\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6579 - acc: 0.6319 - val_loss: 0.7944 - val_acc: 0.4812\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6301 - acc: 0.6539 - val_loss: 0.8041 - val_acc: 0.5344\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6053 - acc: 0.6917 - val_loss: 0.8117 - val_acc: 0.5375\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5713 - acc: 0.7176 - val_loss: 0.9434 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5284 - acc: 0.7581 - val_loss: 0.9136 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5064 - acc: 0.7886 - val_loss: 0.8756 - val_acc: 0.5906\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4799 - acc: 0.7967 - val_loss: 0.9326 - val_acc: 0.5281\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4527 - acc: 0.8318 - val_loss: 0.9299 - val_acc: 0.5656\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4317 - acc: 0.8410 - val_loss: 0.9103 - val_acc: 0.5625\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4084 - acc: 0.8584 - val_loss: 1.0931 - val_acc: 0.5469\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3850 - acc: 0.8681 - val_loss: 1.1096 - val_acc: 0.5437\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3664 - acc: 0.8827 - val_loss: 1.0123 - val_acc: 0.5781\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3371 - acc: 0.9012 - val_loss: 1.0931 - val_acc: 0.5969\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3192 - acc: 0.9059 - val_loss: 1.2285 - val_acc: 0.5500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7252 - acc: 0.5594\n",
      "Test eval is  [0.7251583337783813, 0.559374988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:38:13.480511: Finished Train Fold #95/500 - thus far subj acc is 0.4494736842105262 and regular acc is0.45855263095153004\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #96\n",
      "A1 :  2022-04-07 22:38:32.654402\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7847 - acc: 0.5463 - val_loss: 0.7673 - val_acc: 0.3938\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7346 - acc: 0.5598 - val_loss: 0.7413 - val_acc: 0.4094\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7034 - acc: 0.5961 - val_loss: 0.7402 - val_acc: 0.4062\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6794 - acc: 0.6258 - val_loss: 0.7384 - val_acc: 0.4750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6553 - acc: 0.6551 - val_loss: 0.7366 - val_acc: 0.5344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6233 - acc: 0.6829 - val_loss: 0.7290 - val_acc: 0.5719\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5972 - acc: 0.7203 - val_loss: 0.8292 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5547 - acc: 0.7604 - val_loss: 0.7973 - val_acc: 0.5594\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5086 - acc: 0.8021 - val_loss: 0.8335 - val_acc: 0.5938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4804 - acc: 0.8175 - val_loss: 0.8887 - val_acc: 0.4969\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4355 - acc: 0.8526 - val_loss: 0.9595 - val_acc: 0.5375\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3919 - acc: 0.8769 - val_loss: 1.0269 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3781 - acc: 0.8835 - val_loss: 1.1176 - val_acc: 0.5375\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3432 - acc: 0.9043 - val_loss: 1.0898 - val_acc: 0.5344\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3400 - acc: 0.9082 - val_loss: 1.1737 - val_acc: 0.5156\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2921 - acc: 0.9309 - val_loss: 1.2886 - val_acc: 0.4844\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3059 - acc: 0.9221 - val_loss: 1.4948 - val_acc: 0.4625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3051 - acc: 0.9217 - val_loss: 1.3280 - val_acc: 0.4656\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2800 - acc: 0.9402 - val_loss: 1.4466 - val_acc: 0.4781\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2656 - acc: 0.9406 - val_loss: 1.3851 - val_acc: 0.5156\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6286 - acc: 0.4594\n",
      "Test eval is  [1.6286169290542603, 0.4593749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:38:44.211025: Finished Train Fold #96/500 - thus far subj acc is 0.4489583333333333 and regular acc is0.45960286383827526\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #97\n",
      "A1 :  2022-04-07 22:39:03.375256\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8016 - acc: 0.5386 - val_loss: 0.7726 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7449 - acc: 0.5220 - val_loss: 0.7373 - val_acc: 0.5063\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7079 - acc: 0.5961 - val_loss: 0.7198 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6833 - acc: 0.6076 - val_loss: 0.7153 - val_acc: 0.4906\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6654 - acc: 0.6420 - val_loss: 0.7339 - val_acc: 0.4719\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6403 - acc: 0.6593 - val_loss: 0.7746 - val_acc: 0.4812\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6206 - acc: 0.6836 - val_loss: 0.7506 - val_acc: 0.5344\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5908 - acc: 0.7269 - val_loss: 0.8410 - val_acc: 0.4906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5556 - acc: 0.7643 - val_loss: 0.9344 - val_acc: 0.5375\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5248 - acc: 0.7843 - val_loss: 0.9280 - val_acc: 0.4781\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4870 - acc: 0.8140 - val_loss: 1.0154 - val_acc: 0.4969\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4787 - acc: 0.8171 - val_loss: 0.9755 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4592 - acc: 0.8275 - val_loss: 1.0752 - val_acc: 0.4625\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4379 - acc: 0.8484 - val_loss: 0.9649 - val_acc: 0.5344\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4445 - acc: 0.8449 - val_loss: 1.0533 - val_acc: 0.5188\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4002 - acc: 0.8731 - val_loss: 1.1373 - val_acc: 0.4844\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3894 - acc: 0.8808 - val_loss: 1.1757 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3696 - acc: 0.8873 - val_loss: 1.2446 - val_acc: 0.4625\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3766 - acc: 0.8873 - val_loss: 1.0843 - val_acc: 0.5063\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3359 - acc: 0.9082 - val_loss: 1.2749 - val_acc: 0.5156\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7367 - acc: 0.4375\n",
      "Test eval is  [0.7367088198661804, 0.4375]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:39:14.873723: Finished Train Fold #97/500 - thus far subj acc is 0.44639175257731956 and regular acc is0.4596005146650924\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #98\n",
      "A1 :  2022-04-07 22:39:34.011577\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7791 - acc: 0.5613 - val_loss: 0.7672 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7311 - acc: 0.5675 - val_loss: 0.7456 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7035 - acc: 0.5694 - val_loss: 0.7400 - val_acc: 0.3906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6824 - acc: 0.6011 - val_loss: 0.7898 - val_acc: 0.4344\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6576 - acc: 0.6319 - val_loss: 0.7761 - val_acc: 0.4406\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6270 - acc: 0.6667 - val_loss: 0.8292 - val_acc: 0.5094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6058 - acc: 0.6825 - val_loss: 0.8785 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5660 - acc: 0.7338 - val_loss: 0.9367 - val_acc: 0.5063\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5379 - acc: 0.7658 - val_loss: 0.9936 - val_acc: 0.5219\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4900 - acc: 0.8005 - val_loss: 1.0969 - val_acc: 0.4750\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4717 - acc: 0.8160 - val_loss: 1.0499 - val_acc: 0.4656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4275 - acc: 0.8414 - val_loss: 1.2524 - val_acc: 0.4625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4103 - acc: 0.8522 - val_loss: 1.2154 - val_acc: 0.5063\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3720 - acc: 0.8762 - val_loss: 1.2719 - val_acc: 0.4781\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3453 - acc: 0.8943 - val_loss: 1.5431 - val_acc: 0.4531\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3387 - acc: 0.8978 - val_loss: 1.5127 - val_acc: 0.4906\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3211 - acc: 0.9062 - val_loss: 1.2917 - val_acc: 0.5125\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2976 - acc: 0.9221 - val_loss: 1.5517 - val_acc: 0.4281\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2842 - acc: 0.9255 - val_loss: 1.6003 - val_acc: 0.4938\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7696 - acc: 0.2937\n",
      "Test eval is  [0.7696078419685364, 0.29374998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:39:44.917094: Finished Train Fold #98/500 - thus far subj acc is 0.44693877551020406 and regular acc is0.4593749992093261\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #99\n",
      "A1 :  2022-04-07 22:40:04.028991\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7983 - acc: 0.5421 - val_loss: 0.7715 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7397 - acc: 0.5436 - val_loss: 0.7326 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7091 - acc: 0.5424 - val_loss: 0.7235 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6874 - acc: 0.5428 - val_loss: 0.7212 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6692 - acc: 0.5428 - val_loss: 0.7442 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6575 - acc: 0.6034 - val_loss: 0.7438 - val_acc: 0.4844\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6396 - acc: 0.6393 - val_loss: 0.7472 - val_acc: 0.4906\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6346 - acc: 0.6717 - val_loss: 0.7277 - val_acc: 0.5156\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6198 - acc: 0.6890 - val_loss: 0.7422 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5953 - acc: 0.7211 - val_loss: 0.7396 - val_acc: 0.5312\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5736 - acc: 0.7531 - val_loss: 0.8103 - val_acc: 0.5031\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5561 - acc: 0.7589 - val_loss: 0.8278 - val_acc: 0.4969\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5437 - acc: 0.7832 - val_loss: 0.8281 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5354 - acc: 0.7828 - val_loss: 0.7954 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5170 - acc: 0.7971 - val_loss: 0.8819 - val_acc: 0.4875\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5091 - acc: 0.8048 - val_loss: 0.9179 - val_acc: 0.5031\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4992 - acc: 0.8152 - val_loss: 0.8771 - val_acc: 0.5094\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4777 - acc: 0.8260 - val_loss: 0.9268 - val_acc: 0.4875\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4702 - acc: 0.8264 - val_loss: 1.0847 - val_acc: 0.4750\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4563 - acc: 0.8480 - val_loss: 0.9700 - val_acc: 0.5281\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7654 - acc: 0.4000\n",
      "Test eval is  [0.7653731107711792, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:40:15.515615: Finished Train Fold #99/500 - thus far subj acc is 0.4454545454545454 and regular acc is0.4577020192989195\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #100\n",
      "A1 :  2022-04-07 22:40:34.813162\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7952 - acc: 0.5440 - val_loss: 0.7672 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7417 - acc: 0.5432 - val_loss: 0.7402 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7061 - acc: 0.5432 - val_loss: 0.7234 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6789 - acc: 0.5718 - val_loss: 0.7112 - val_acc: 0.4750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6602 - acc: 0.6385 - val_loss: 0.7054 - val_acc: 0.5281\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6275 - acc: 0.6809 - val_loss: 0.7012 - val_acc: 0.5469\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6114 - acc: 0.7037 - val_loss: 0.7143 - val_acc: 0.5656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5785 - acc: 0.7407 - val_loss: 0.7605 - val_acc: 0.5875\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5514 - acc: 0.7639 - val_loss: 0.7510 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5286 - acc: 0.7917 - val_loss: 0.8387 - val_acc: 0.5406\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5126 - acc: 0.7978 - val_loss: 0.8473 - val_acc: 0.5281\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4817 - acc: 0.8256 - val_loss: 0.8445 - val_acc: 0.5437\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4615 - acc: 0.8333 - val_loss: 0.8725 - val_acc: 0.5312\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4442 - acc: 0.8426 - val_loss: 0.9582 - val_acc: 0.5281\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4279 - acc: 0.8538 - val_loss: 0.9169 - val_acc: 0.5406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4028 - acc: 0.8765 - val_loss: 1.0361 - val_acc: 0.5562\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3921 - acc: 0.8839 - val_loss: 0.9550 - val_acc: 0.5656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3697 - acc: 0.8951 - val_loss: 0.9254 - val_acc: 0.5719\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3681 - acc: 0.9047 - val_loss: 1.0026 - val_acc: 0.5594\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3520 - acc: 0.9086 - val_loss: 1.0721 - val_acc: 0.5250\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6173 - acc: 0.4500\n",
      "Test eval is  [1.617300271987915, 0.44999998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:40:46.315264: Finished Train Fold #100/500 - thus far subj acc is 0.44499999999999995 and regular acc is0.45712499916553495\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #101\n",
      "A1 :  2022-04-07 22:41:05.479872\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7841 - acc: 0.5394 - val_loss: 0.7622 - val_acc: 0.5031\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7332 - acc: 0.5544 - val_loss: 0.7539 - val_acc: 0.4938\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6994 - acc: 0.5856 - val_loss: 0.7432 - val_acc: 0.4656\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6779 - acc: 0.5957 - val_loss: 0.7363 - val_acc: 0.4938\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6571 - acc: 0.6505 - val_loss: 0.7661 - val_acc: 0.4500\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6165 - acc: 0.6794 - val_loss: 0.8067 - val_acc: 0.5031\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5897 - acc: 0.7118 - val_loss: 0.8737 - val_acc: 0.5625\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5573 - acc: 0.7407 - val_loss: 0.8672 - val_acc: 0.5250\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5176 - acc: 0.7789 - val_loss: 0.8663 - val_acc: 0.5625\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4846 - acc: 0.8063 - val_loss: 1.0085 - val_acc: 0.5312\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4586 - acc: 0.8279 - val_loss: 0.9031 - val_acc: 0.5437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4338 - acc: 0.8418 - val_loss: 0.9932 - val_acc: 0.5562\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4198 - acc: 0.8584 - val_loss: 1.1561 - val_acc: 0.5406\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4064 - acc: 0.8546 - val_loss: 1.0358 - val_acc: 0.5562\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3721 - acc: 0.8877 - val_loss: 1.3583 - val_acc: 0.5344\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3449 - acc: 0.9016 - val_loss: 1.2397 - val_acc: 0.4906\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3489 - acc: 0.8974 - val_loss: 1.2958 - val_acc: 0.4969\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3301 - acc: 0.9078 - val_loss: 1.3098 - val_acc: 0.5344\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3039 - acc: 0.9221 - val_loss: 1.4128 - val_acc: 0.5063\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2992 - acc: 0.9240 - val_loss: 1.3383 - val_acc: 0.5156\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7423 - acc: 0.4906\n",
      "Test eval is  [0.742310643196106, 0.4906249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:41:17.002265: Finished Train Fold #101/500 - thus far subj acc is 0.44455445544554445 and regular acc is0.45705445450131255\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #102\n",
      "A1 :  2022-04-07 22:41:36.256974\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7891 - acc: 0.5220 - val_loss: 0.7606 - val_acc: 0.4969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7401 - acc: 0.5397 - val_loss: 0.7276 - val_acc: 0.5125\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7138 - acc: 0.5656 - val_loss: 0.7183 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6926 - acc: 0.5694 - val_loss: 0.7297 - val_acc: 0.4219\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6736 - acc: 0.6026 - val_loss: 0.7703 - val_acc: 0.4688\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6537 - acc: 0.6366 - val_loss: 0.7830 - val_acc: 0.4656\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6324 - acc: 0.6694 - val_loss: 0.8239 - val_acc: 0.4750\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6066 - acc: 0.6925 - val_loss: 0.7991 - val_acc: 0.5500\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5801 - acc: 0.7191 - val_loss: 0.8674 - val_acc: 0.4875\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5494 - acc: 0.7554 - val_loss: 1.0126 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5345 - acc: 0.7600 - val_loss: 1.0298 - val_acc: 0.5281\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5028 - acc: 0.7967 - val_loss: 0.9462 - val_acc: 0.4344\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4677 - acc: 0.8333 - val_loss: 0.9595 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4389 - acc: 0.8488 - val_loss: 1.1202 - val_acc: 0.4906\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4303 - acc: 0.8519 - val_loss: 1.1037 - val_acc: 0.5281\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4013 - acc: 0.8630 - val_loss: 1.1354 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3833 - acc: 0.8804 - val_loss: 1.2808 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3815 - acc: 0.8773 - val_loss: 1.2585 - val_acc: 0.5031\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3538 - acc: 0.8970 - val_loss: 1.5317 - val_acc: 0.4594\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7168 - acc: 0.4906\n",
      "Test eval is  [0.7167699933052063, 0.4906249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:41:47.275301: Finished Train Fold #102/500 - thus far subj acc is 0.44411764705882345 and regular acc is0.4573835774379618\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #103\n",
      "A1 :  2022-04-07 22:42:06.254120\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7769 - acc: 0.5455 - val_loss: 0.7633 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7283 - acc: 0.5540 - val_loss: 0.7451 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7055 - acc: 0.5556 - val_loss: 0.7440 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5552 - val_loss: 0.7330 - val_acc: 0.4000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6693 - acc: 0.5556 - val_loss: 0.7583 - val_acc: 0.4000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6523 - acc: 0.5910 - val_loss: 0.8127 - val_acc: 0.4437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6347 - acc: 0.6404 - val_loss: 0.8478 - val_acc: 0.4563\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6146 - acc: 0.6566 - val_loss: 0.8350 - val_acc: 0.4531\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5813 - acc: 0.6995 - val_loss: 0.8756 - val_acc: 0.4844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5531 - acc: 0.7473 - val_loss: 1.1071 - val_acc: 0.4656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5341 - acc: 0.7593 - val_loss: 1.1108 - val_acc: 0.4656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5074 - acc: 0.7882 - val_loss: 1.1498 - val_acc: 0.4563\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4946 - acc: 0.7944 - val_loss: 1.2228 - val_acc: 0.4781\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4631 - acc: 0.8202 - val_loss: 1.0695 - val_acc: 0.4844\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4434 - acc: 0.8318 - val_loss: 1.1635 - val_acc: 0.5031\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4264 - acc: 0.8511 - val_loss: 1.3119 - val_acc: 0.4375\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4096 - acc: 0.8557 - val_loss: 1.2174 - val_acc: 0.4969\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4108 - acc: 0.8569 - val_loss: 1.3992 - val_acc: 0.4875\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4006 - acc: 0.8704 - val_loss: 1.4830 - val_acc: 0.4719\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3831 - acc: 0.8765 - val_loss: 1.3572 - val_acc: 0.5000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8089 - acc: 0.4000\n",
      "Test eval is  [0.8088857531547546, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:42:17.842938: Finished Train Fold #103/500 - thus far subj acc is 0.44466019417475716 and regular acc is0.4577063096379771\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #104\n",
      "A1 :  2022-04-07 22:42:37.093692\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7867 - acc: 0.5212 - val_loss: 0.7656 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7354 - acc: 0.5312 - val_loss: 0.7380 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7086 - acc: 0.5536 - val_loss: 0.7159 - val_acc: 0.5219\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6827 - acc: 0.5826 - val_loss: 0.7159 - val_acc: 0.5125\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6601 - acc: 0.6026 - val_loss: 0.7422 - val_acc: 0.4500\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6357 - acc: 0.6296 - val_loss: 0.7971 - val_acc: 0.4875\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6269 - acc: 0.6663 - val_loss: 0.7599 - val_acc: 0.5375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5939 - acc: 0.7002 - val_loss: 0.8224 - val_acc: 0.5156\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5623 - acc: 0.7346 - val_loss: 0.8534 - val_acc: 0.5375\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5489 - acc: 0.7485 - val_loss: 0.8131 - val_acc: 0.5281\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5232 - acc: 0.7755 - val_loss: 0.8470 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5056 - acc: 0.7797 - val_loss: 0.9186 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4645 - acc: 0.8252 - val_loss: 0.9722 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4463 - acc: 0.8434 - val_loss: 1.0104 - val_acc: 0.5375\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4384 - acc: 0.8472 - val_loss: 1.0316 - val_acc: 0.5156\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4018 - acc: 0.8665 - val_loss: 1.0110 - val_acc: 0.5500\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3909 - acc: 0.8742 - val_loss: 1.0112 - val_acc: 0.5625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3852 - acc: 0.8900 - val_loss: 1.1214 - val_acc: 0.5312\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3589 - acc: 0.9024 - val_loss: 1.0649 - val_acc: 0.5406\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7356 - acc: 0.4750\n",
      "Test eval is  [0.7356383204460144, 0.4749999940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:42:48.058100: Finished Train Fold #104/500 - thus far subj acc is 0.44423076923076926 and regular acc is0.4571514413333856\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #105\n",
      "A1 :  2022-04-07 22:43:07.205119\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7817 - acc: 0.5590 - val_loss: 0.7797 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7281 - acc: 0.5679 - val_loss: 0.7509 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6997 - acc: 0.5718 - val_loss: 0.7352 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6766 - acc: 0.6007 - val_loss: 0.7561 - val_acc: 0.3844\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6569 - acc: 0.6188 - val_loss: 0.7763 - val_acc: 0.4531\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6403 - acc: 0.6424 - val_loss: 0.7401 - val_acc: 0.4625\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6291 - acc: 0.6501 - val_loss: 0.7696 - val_acc: 0.4625\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6042 - acc: 0.6779 - val_loss: 0.7882 - val_acc: 0.5844\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5770 - acc: 0.7103 - val_loss: 0.8484 - val_acc: 0.5188\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5558 - acc: 0.7323 - val_loss: 0.8630 - val_acc: 0.5094\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5272 - acc: 0.7542 - val_loss: 0.8131 - val_acc: 0.5844\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5059 - acc: 0.7677 - val_loss: 0.8686 - val_acc: 0.5188\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4816 - acc: 0.7971 - val_loss: 0.9171 - val_acc: 0.5312\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4585 - acc: 0.8164 - val_loss: 0.9624 - val_acc: 0.4875\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4427 - acc: 0.8287 - val_loss: 0.9687 - val_acc: 0.5656\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4085 - acc: 0.8507 - val_loss: 1.1135 - val_acc: 0.5562\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3949 - acc: 0.8615 - val_loss: 0.9860 - val_acc: 0.5656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3710 - acc: 0.8742 - val_loss: 0.9986 - val_acc: 0.5656\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3669 - acc: 0.8800 - val_loss: 1.0419 - val_acc: 0.5656\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7897 - acc: 0.3000\n",
      "Test eval is  [0.7897141575813293, 0.30000001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:43:18.176377: Finished Train Fold #105/500 - thus far subj acc is 0.4447619047619048 and regular acc is0.4573214275496347\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #106\n",
      "A1 :  2022-04-07 22:43:37.511413\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7867 - acc: 0.5204 - val_loss: 0.7552 - val_acc: 0.6062\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7420 - acc: 0.5644 - val_loss: 0.7300 - val_acc: 0.5562\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7127 - acc: 0.5710 - val_loss: 0.7106 - val_acc: 0.6375\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6829 - acc: 0.6169 - val_loss: 0.7354 - val_acc: 0.5688\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6607 - acc: 0.6397 - val_loss: 0.7688 - val_acc: 0.4500\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6373 - acc: 0.6736 - val_loss: 0.7608 - val_acc: 0.5125\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6179 - acc: 0.6759 - val_loss: 0.8110 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5749 - acc: 0.7323 - val_loss: 0.8725 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5432 - acc: 0.7558 - val_loss: 0.9451 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5131 - acc: 0.7843 - val_loss: 1.0210 - val_acc: 0.5156\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4699 - acc: 0.8268 - val_loss: 1.0208 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4507 - acc: 0.8326 - val_loss: 1.0688 - val_acc: 0.4906\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4263 - acc: 0.8538 - val_loss: 1.1092 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4058 - acc: 0.8696 - val_loss: 1.2216 - val_acc: 0.4500\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3804 - acc: 0.8746 - val_loss: 1.3918 - val_acc: 0.4406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3410 - acc: 0.9039 - val_loss: 1.3892 - val_acc: 0.4812\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3435 - acc: 0.9032 - val_loss: 1.3928 - val_acc: 0.4906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3075 - acc: 0.9236 - val_loss: 1.6632 - val_acc: 0.4344\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3371 - acc: 0.9047 - val_loss: 1.4676 - val_acc: 0.4500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7234 - acc: 0.4062\n",
      "Test eval is  [0.7234027981758118, 0.40625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:43:48.422614: Finished Train Fold #106/500 - thus far subj acc is 0.44339622641509435 and regular acc is0.4558372632512506\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #107\n",
      "A1 :  2022-04-07 22:44:07.384105\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8042 - acc: 0.5100 - val_loss: 0.7713 - val_acc: 0.5375\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7503 - acc: 0.5448 - val_loss: 0.7342 - val_acc: 0.4906\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7192 - acc: 0.5598 - val_loss: 0.7151 - val_acc: 0.4469\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6995 - acc: 0.5683 - val_loss: 0.7046 - val_acc: 0.4938\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6874 - acc: 0.5841 - val_loss: 0.6991 - val_acc: 0.4656\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6738 - acc: 0.6030 - val_loss: 0.7074 - val_acc: 0.5094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6569 - acc: 0.6300 - val_loss: 0.6912 - val_acc: 0.5938\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6403 - acc: 0.6709 - val_loss: 0.7002 - val_acc: 0.5156\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6270 - acc: 0.6844 - val_loss: 0.7469 - val_acc: 0.5406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6042 - acc: 0.7130 - val_loss: 0.7910 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5861 - acc: 0.7284 - val_loss: 0.7953 - val_acc: 0.5406\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5580 - acc: 0.7581 - val_loss: 0.8577 - val_acc: 0.4906\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5410 - acc: 0.7751 - val_loss: 0.8501 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5106 - acc: 0.8002 - val_loss: 0.8553 - val_acc: 0.5156\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5077 - acc: 0.8002 - val_loss: 0.9546 - val_acc: 0.5938\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4753 - acc: 0.8218 - val_loss: 0.9671 - val_acc: 0.5531\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4666 - acc: 0.8241 - val_loss: 0.9933 - val_acc: 0.5344\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4430 - acc: 0.8418 - val_loss: 1.0727 - val_acc: 0.5031\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4446 - acc: 0.8492 - val_loss: 1.0519 - val_acc: 0.5125\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4203 - acc: 0.8549 - val_loss: 1.1579 - val_acc: 0.5188\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5317 - acc: 0.5281\n",
      "Test eval is  [1.5317230224609375, 0.528124988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:44:18.962021: Finished Train Fold #107/500 - thus far subj acc is 0.4439252336448598 and regular acc is0.4553738308844165\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #108\n",
      "A1 :  2022-04-07 22:44:38.100455\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7897 - acc: 0.5405 - val_loss: 0.7618 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7388 - acc: 0.5471 - val_loss: 0.7316 - val_acc: 0.4844\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7073 - acc: 0.5775 - val_loss: 0.7380 - val_acc: 0.4125\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6779 - acc: 0.6181 - val_loss: 0.7428 - val_acc: 0.4156\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6553 - acc: 0.6304 - val_loss: 0.8181 - val_acc: 0.4094\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6339 - acc: 0.6640 - val_loss: 0.8163 - val_acc: 0.4750\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5981 - acc: 0.7045 - val_loss: 0.8423 - val_acc: 0.4437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5732 - acc: 0.7249 - val_loss: 0.8697 - val_acc: 0.4969\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5369 - acc: 0.7677 - val_loss: 0.9932 - val_acc: 0.4906\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5162 - acc: 0.7720 - val_loss: 1.0366 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4752 - acc: 0.8094 - val_loss: 1.1333 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4405 - acc: 0.8383 - val_loss: 1.0499 - val_acc: 0.4938\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4231 - acc: 0.8410 - val_loss: 1.1830 - val_acc: 0.4969\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4110 - acc: 0.8511 - val_loss: 1.0674 - val_acc: 0.5344\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3788 - acc: 0.8661 - val_loss: 1.2028 - val_acc: 0.5281\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3624 - acc: 0.8754 - val_loss: 1.2699 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3343 - acc: 0.8943 - val_loss: 1.3240 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3225 - acc: 0.9028 - val_loss: 1.3307 - val_acc: 0.5312\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7331 - acc: 0.4906\n",
      "Test eval is  [0.7330548763275146, 0.4906249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:44:48.538851: Finished Train Fold #108/500 - thus far subj acc is 0.4444444444444444 and regular acc is0.45604745271029296\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #109\n",
      "A1 :  2022-04-07 22:45:07.895348\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8021 - acc: 0.5185 - val_loss: 0.7706 - val_acc: 0.4719\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7489 - acc: 0.5297 - val_loss: 0.7341 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7201 - acc: 0.5498 - val_loss: 0.7162 - val_acc: 0.4656\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7004 - acc: 0.5606 - val_loss: 0.7218 - val_acc: 0.5063\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6844 - acc: 0.5845 - val_loss: 0.7249 - val_acc: 0.4344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6713 - acc: 0.6061 - val_loss: 0.7242 - val_acc: 0.4250\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6509 - acc: 0.6362 - val_loss: 0.7710 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6304 - acc: 0.6644 - val_loss: 0.7497 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6138 - acc: 0.6775 - val_loss: 0.8095 - val_acc: 0.4906\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5818 - acc: 0.7191 - val_loss: 0.8046 - val_acc: 0.4625\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5575 - acc: 0.7342 - val_loss: 0.8066 - val_acc: 0.4938\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5449 - acc: 0.7477 - val_loss: 0.8893 - val_acc: 0.4875\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5033 - acc: 0.7812 - val_loss: 0.9029 - val_acc: 0.4844\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4773 - acc: 0.8160 - val_loss: 0.9568 - val_acc: 0.4406\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4611 - acc: 0.8252 - val_loss: 0.8975 - val_acc: 0.5188\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4404 - acc: 0.8507 - val_loss: 1.0030 - val_acc: 0.4500\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4163 - acc: 0.8596 - val_loss: 1.1159 - val_acc: 0.4719\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3988 - acc: 0.8677 - val_loss: 1.0160 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3894 - acc: 0.8785 - val_loss: 1.2284 - val_acc: 0.4781\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7163 - acc: 0.6812\n",
      "Test eval is  [0.716335654258728, 0.6812499761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:45:18.987558: Finished Train Fold #109/500 - thus far subj acc is 0.44495412844036697 and regular acc is0.45636467786010254\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #110\n",
      "A1 :  2022-04-07 22:45:38.210777\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7914 - acc: 0.5394 - val_loss: 0.7628 - val_acc: 0.4969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7402 - acc: 0.5467 - val_loss: 0.7302 - val_acc: 0.4969\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7113 - acc: 0.5687 - val_loss: 0.7227 - val_acc: 0.4594\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6884 - acc: 0.5968 - val_loss: 0.8252 - val_acc: 0.4781\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6641 - acc: 0.6343 - val_loss: 0.7819 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6436 - acc: 0.6644 - val_loss: 0.8336 - val_acc: 0.4938\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6173 - acc: 0.6998 - val_loss: 0.8978 - val_acc: 0.5156\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5798 - acc: 0.7311 - val_loss: 0.8164 - val_acc: 0.6031\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5504 - acc: 0.7631 - val_loss: 0.8065 - val_acc: 0.5688\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5080 - acc: 0.7975 - val_loss: 0.9163 - val_acc: 0.5500\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4700 - acc: 0.8279 - val_loss: 0.9791 - val_acc: 0.5781\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4495 - acc: 0.8349 - val_loss: 1.0064 - val_acc: 0.5562\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4228 - acc: 0.8522 - val_loss: 1.0680 - val_acc: 0.5562\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3886 - acc: 0.8789 - val_loss: 1.0207 - val_acc: 0.5688\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3722 - acc: 0.8904 - val_loss: 1.0829 - val_acc: 0.5625\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3521 - acc: 0.8962 - val_loss: 1.2435 - val_acc: 0.5406\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3403 - acc: 0.8985 - val_loss: 1.2392 - val_acc: 0.5312\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3193 - acc: 0.9105 - val_loss: 1.3922 - val_acc: 0.5219\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2917 - acc: 0.9228 - val_loss: 1.3287 - val_acc: 0.5469\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7329 - acc: 0.3969\n",
      "Test eval is  [0.73285311460495, 0.3968749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:45:49.349595: Finished Train Fold #110/500 - thus far subj acc is 0.44545454545454544 and regular acc is0.45840908966281196\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #111\n",
      "A1 :  2022-04-07 22:46:08.413031\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7988 - acc: 0.5347 - val_loss: 0.7706 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7433 - acc: 0.5548 - val_loss: 0.7364 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7133 - acc: 0.5552 - val_loss: 0.7177 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6945 - acc: 0.5552 - val_loss: 0.7068 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6808 - acc: 0.5556 - val_loss: 0.7083 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6624 - acc: 0.5559 - val_loss: 0.7128 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6566 - acc: 0.5556 - val_loss: 0.7384 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6378 - acc: 0.5556 - val_loss: 0.7085 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6209 - acc: 0.6157 - val_loss: 0.7261 - val_acc: 0.5344\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6074 - acc: 0.6771 - val_loss: 0.7352 - val_acc: 0.5094\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5856 - acc: 0.7199 - val_loss: 0.7474 - val_acc: 0.5781\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5786 - acc: 0.7191 - val_loss: 0.7612 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5726 - acc: 0.7234 - val_loss: 0.8113 - val_acc: 0.5594\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5540 - acc: 0.7508 - val_loss: 0.8568 - val_acc: 0.4938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5544 - acc: 0.7446 - val_loss: 0.8119 - val_acc: 0.5562\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5302 - acc: 0.7689 - val_loss: 0.7814 - val_acc: 0.5938\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5347 - acc: 0.7581 - val_loss: 0.8454 - val_acc: 0.5437\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5246 - acc: 0.7739 - val_loss: 0.8005 - val_acc: 0.5312\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5120 - acc: 0.7847 - val_loss: 1.0016 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5085 - acc: 0.7874 - val_loss: 0.8525 - val_acc: 0.5656\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7431 - acc: 0.3000\n",
      "Test eval is  [0.7431443929672241, 0.30000001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:46:19.824864: Finished Train Fold #111/500 - thus far subj acc is 0.44504504504504505 and regular acc is0.45785472844098063\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #112\n",
      "A1 :  2022-04-07 22:46:38.915346\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8001 - acc: 0.5374 - val_loss: 0.7709 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7428 - acc: 0.5324 - val_loss: 0.7363 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7114 - acc: 0.5451 - val_loss: 0.7133 - val_acc: 0.4625\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6893 - acc: 0.5644 - val_loss: 0.7007 - val_acc: 0.5188\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6703 - acc: 0.5999 - val_loss: 0.7015 - val_acc: 0.5312\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6512 - acc: 0.6466 - val_loss: 0.7226 - val_acc: 0.5562\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6260 - acc: 0.6833 - val_loss: 0.8550 - val_acc: 0.5344\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6048 - acc: 0.7049 - val_loss: 0.9328 - val_acc: 0.5094\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5776 - acc: 0.7357 - val_loss: 0.8822 - val_acc: 0.4781\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5550 - acc: 0.7604 - val_loss: 0.8856 - val_acc: 0.5281\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5157 - acc: 0.7940 - val_loss: 1.0921 - val_acc: 0.5000\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4898 - acc: 0.8102 - val_loss: 1.0274 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4507 - acc: 0.8484 - val_loss: 1.2022 - val_acc: 0.4969\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4377 - acc: 0.8565 - val_loss: 1.1657 - val_acc: 0.5063\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4214 - acc: 0.8696 - val_loss: 1.2369 - val_acc: 0.4688\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4027 - acc: 0.8792 - val_loss: 1.1278 - val_acc: 0.4969\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3800 - acc: 0.8900 - val_loss: 1.3992 - val_acc: 0.4906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3678 - acc: 0.9035 - val_loss: 1.3062 - val_acc: 0.4688\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3577 - acc: 0.9086 - val_loss: 1.3414 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3541 - acc: 0.9043 - val_loss: 1.2111 - val_acc: 0.4406\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7155 - acc: 0.5437\n",
      "Test eval is  [0.7154843807220459, 0.543749988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:46:50.348574: Finished Train Fold #112/500 - thus far subj acc is 0.44375 and regular acc is0.45644531132919447\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #113\n",
      "A1 :  2022-04-07 22:47:09.424586\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7945 - acc: 0.5405 - val_loss: 0.7705 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7413 - acc: 0.5436 - val_loss: 0.7409 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7081 - acc: 0.5432 - val_loss: 0.7268 - val_acc: 0.4906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6857 - acc: 0.5660 - val_loss: 0.7367 - val_acc: 0.4594\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.6073 - val_loss: 0.7451 - val_acc: 0.4187\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6357 - acc: 0.6431 - val_loss: 0.7423 - val_acc: 0.4563\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6116 - acc: 0.7002 - val_loss: 0.7737 - val_acc: 0.5437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5719 - acc: 0.7539 - val_loss: 0.9178 - val_acc: 0.4969\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5376 - acc: 0.7731 - val_loss: 0.9052 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5070 - acc: 0.7982 - val_loss: 0.9512 - val_acc: 0.5125\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4725 - acc: 0.8268 - val_loss: 1.0459 - val_acc: 0.5312\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4372 - acc: 0.8380 - val_loss: 1.0210 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4157 - acc: 0.8553 - val_loss: 1.1481 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3767 - acc: 0.8773 - val_loss: 1.1716 - val_acc: 0.4875\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3856 - acc: 0.8711 - val_loss: 1.0340 - val_acc: 0.5094\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3514 - acc: 0.8900 - val_loss: 1.1249 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3288 - acc: 0.9070 - val_loss: 1.1795 - val_acc: 0.5344\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3316 - acc: 0.8978 - val_loss: 1.1917 - val_acc: 0.5031\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3140 - acc: 0.9120 - val_loss: 1.3177 - val_acc: 0.4938\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7518 - acc: 0.4000\n",
      "Test eval is  [0.7517770528793335, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:47:20.536193: Finished Train Fold #113/500 - thus far subj acc is 0.4451327433628318 and regular acc is0.45721791908804293\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #114\n",
      "A1 :  2022-04-07 22:47:39.717719\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7879 - acc: 0.5324 - val_loss: 0.7598 - val_acc: 0.4719\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7395 - acc: 0.5409 - val_loss: 0.7314 - val_acc: 0.4469\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7098 - acc: 0.5544 - val_loss: 0.7432 - val_acc: 0.4531\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6901 - acc: 0.5768 - val_loss: 0.8040 - val_acc: 0.4406\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6704 - acc: 0.5934 - val_loss: 0.8107 - val_acc: 0.4094\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6595 - acc: 0.6292 - val_loss: 0.8032 - val_acc: 0.4406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6274 - acc: 0.6748 - val_loss: 0.8515 - val_acc: 0.5312\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6136 - acc: 0.6914 - val_loss: 0.8425 - val_acc: 0.5312\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5849 - acc: 0.7145 - val_loss: 0.8692 - val_acc: 0.4812\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5601 - acc: 0.7411 - val_loss: 0.9179 - val_acc: 0.5031\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5262 - acc: 0.7728 - val_loss: 1.0038 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5015 - acc: 0.7959 - val_loss: 1.1170 - val_acc: 0.4625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4670 - acc: 0.8198 - val_loss: 0.9772 - val_acc: 0.5125\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4549 - acc: 0.8256 - val_loss: 0.9898 - val_acc: 0.5531\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4174 - acc: 0.8519 - val_loss: 1.0262 - val_acc: 0.5344\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3975 - acc: 0.8677 - val_loss: 1.0885 - val_acc: 0.5125\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3777 - acc: 0.8727 - val_loss: 1.1152 - val_acc: 0.5063\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3580 - acc: 0.8924 - val_loss: 1.1626 - val_acc: 0.5312\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7313 - acc: 0.4781\n",
      "Test eval is  [0.7313381433486938, 0.4781250059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:47:50.317987: Finished Train Fold #114/500 - thus far subj acc is 0.4447368421052631 and regular acc is0.45671600756937997\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #115\n",
      "A1 :  2022-04-07 22:48:09.396288\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7994 - acc: 0.5204 - val_loss: 0.7697 - val_acc: 0.3969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7462 - acc: 0.5517 - val_loss: 0.7362 - val_acc: 0.4500\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7109 - acc: 0.5783 - val_loss: 0.7404 - val_acc: 0.5094\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6785 - acc: 0.5910 - val_loss: 0.7650 - val_acc: 0.4844\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6504 - acc: 0.6346 - val_loss: 0.7341 - val_acc: 0.5250\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6165 - acc: 0.6956 - val_loss: 0.8585 - val_acc: 0.5063\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5879 - acc: 0.7184 - val_loss: 0.8829 - val_acc: 0.5219\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5482 - acc: 0.7504 - val_loss: 0.8918 - val_acc: 0.5281\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5154 - acc: 0.7840 - val_loss: 0.9278 - val_acc: 0.5312\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4864 - acc: 0.7998 - val_loss: 0.8606 - val_acc: 0.5781\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4588 - acc: 0.8287 - val_loss: 0.9349 - val_acc: 0.5656\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4340 - acc: 0.8453 - val_loss: 1.0755 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4219 - acc: 0.8499 - val_loss: 1.0493 - val_acc: 0.5406\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3942 - acc: 0.8704 - val_loss: 1.1073 - val_acc: 0.5375\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3578 - acc: 0.8904 - val_loss: 1.2562 - val_acc: 0.5406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3433 - acc: 0.8924 - val_loss: 1.3832 - val_acc: 0.5125\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3375 - acc: 0.8966 - val_loss: 1.2505 - val_acc: 0.5219\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3295 - acc: 0.9016 - val_loss: 1.1596 - val_acc: 0.5688\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3262 - acc: 0.9016 - val_loss: 1.2116 - val_acc: 0.5594\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2891 - acc: 0.9275 - val_loss: 1.1855 - val_acc: 0.5906\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4416 - acc: 0.4437\n",
      "Test eval is  [1.4416415691375732, 0.4437499940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:48:20.928867: Finished Train Fold #115/500 - thus far subj acc is 0.4452173913043478 and regular acc is0.4569021727727807\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #116\n",
      "A1 :  2022-04-07 22:48:39.962586\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7973 - acc: 0.5062 - val_loss: 0.7673 - val_acc: 0.4938\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7453 - acc: 0.5367 - val_loss: 0.7326 - val_acc: 0.4906\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7118 - acc: 0.5864 - val_loss: 0.7563 - val_acc: 0.5344\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6831 - acc: 0.6100 - val_loss: 0.8196 - val_acc: 0.5344\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6556 - acc: 0.6346 - val_loss: 0.9618 - val_acc: 0.5281\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6236 - acc: 0.6890 - val_loss: 0.9811 - val_acc: 0.5219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5920 - acc: 0.7114 - val_loss: 0.9571 - val_acc: 0.5219\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5634 - acc: 0.7384 - val_loss: 1.0382 - val_acc: 0.5063\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5194 - acc: 0.7662 - val_loss: 0.9549 - val_acc: 0.5219\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4924 - acc: 0.8063 - val_loss: 1.1691 - val_acc: 0.4688\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4641 - acc: 0.8214 - val_loss: 1.1987 - val_acc: 0.4844\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4443 - acc: 0.8380 - val_loss: 1.3343 - val_acc: 0.4187\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4228 - acc: 0.8472 - val_loss: 1.2429 - val_acc: 0.4375\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3977 - acc: 0.8607 - val_loss: 1.3301 - val_acc: 0.4563\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3876 - acc: 0.8727 - val_loss: 1.4077 - val_acc: 0.4531\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3753 - acc: 0.8731 - val_loss: 1.2640 - val_acc: 0.4688\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3370 - acc: 0.8962 - val_loss: 1.4963 - val_acc: 0.4625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3324 - acc: 0.8993 - val_loss: 1.5299 - val_acc: 0.4375\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7424 - acc: 0.3156\n",
      "Test eval is  [0.7424336671829224, 0.31562501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:48:50.509331: Finished Train Fold #116/500 - thus far subj acc is 0.4439655172413792 and regular acc is0.456788791921632\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #117\n",
      "A1 :  2022-04-07 22:49:09.564324\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7862 - acc: 0.5529 - val_loss: 0.7651 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7301 - acc: 0.5556 - val_loss: 0.7393 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6938 - acc: 0.5556 - val_loss: 0.7285 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6702 - acc: 0.5556 - val_loss: 0.7251 - val_acc: 0.5219\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6477 - acc: 0.6285 - val_loss: 0.7655 - val_acc: 0.4781\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6270 - acc: 0.6651 - val_loss: 0.7223 - val_acc: 0.5594\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5970 - acc: 0.6921 - val_loss: 0.7135 - val_acc: 0.5750\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5839 - acc: 0.7226 - val_loss: 0.7674 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5596 - acc: 0.7485 - val_loss: 0.8072 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5421 - acc: 0.7620 - val_loss: 0.7791 - val_acc: 0.5031\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5309 - acc: 0.7758 - val_loss: 0.8843 - val_acc: 0.4969\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5192 - acc: 0.7928 - val_loss: 0.9835 - val_acc: 0.5125\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4964 - acc: 0.8086 - val_loss: 1.1131 - val_acc: 0.4875\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4795 - acc: 0.8179 - val_loss: 0.8919 - val_acc: 0.5156\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4591 - acc: 0.8287 - val_loss: 0.9245 - val_acc: 0.4812\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4723 - acc: 0.8160 - val_loss: 1.0409 - val_acc: 0.4500\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4475 - acc: 0.8356 - val_loss: 1.0397 - val_acc: 0.5031\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4379 - acc: 0.8438 - val_loss: 1.1351 - val_acc: 0.4781\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4113 - acc: 0.8708 - val_loss: 1.2468 - val_acc: 0.4719\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4117 - acc: 0.8642 - val_loss: 1.1727 - val_acc: 0.4688\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9119 - acc: 0.4125\n",
      "Test eval is  [1.9119045734405518, 0.4124999940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:49:21.200767: Finished Train Fold #117/500 - thus far subj acc is 0.4435897435897435 and regular acc is0.455582263887438\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #118\n",
      "A1 :  2022-04-07 22:49:40.283068\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7953 - acc: 0.5077 - val_loss: 0.7645 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7448 - acc: 0.5170 - val_loss: 0.7293 - val_acc: 0.5531\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7172 - acc: 0.5328 - val_loss: 0.7094 - val_acc: 0.5500\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6998 - acc: 0.5625 - val_loss: 0.7095 - val_acc: 0.5562\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6891 - acc: 0.5733 - val_loss: 0.7007 - val_acc: 0.5844\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6811 - acc: 0.5910 - val_loss: 0.6893 - val_acc: 0.5531\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6700 - acc: 0.5968 - val_loss: 0.7178 - val_acc: 0.5406\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6592 - acc: 0.6150 - val_loss: 0.7699 - val_acc: 0.5906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6396 - acc: 0.6470 - val_loss: 0.8993 - val_acc: 0.5375\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6313 - acc: 0.6524 - val_loss: 0.7833 - val_acc: 0.5656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6120 - acc: 0.6767 - val_loss: 0.7872 - val_acc: 0.5750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5904 - acc: 0.7018 - val_loss: 0.8593 - val_acc: 0.5469\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5823 - acc: 0.7079 - val_loss: 0.9484 - val_acc: 0.5406\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5719 - acc: 0.7141 - val_loss: 0.8945 - val_acc: 0.5406\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5593 - acc: 0.7334 - val_loss: 0.9900 - val_acc: 0.5406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5361 - acc: 0.7492 - val_loss: 1.0598 - val_acc: 0.5156\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5326 - acc: 0.7554 - val_loss: 1.0877 - val_acc: 0.5219\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5295 - acc: 0.7554 - val_loss: 0.9602 - val_acc: 0.5344\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5019 - acc: 0.7886 - val_loss: 1.0393 - val_acc: 0.5406\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4926 - acc: 0.7874 - val_loss: 1.0276 - val_acc: 0.5188\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1149 - acc: 0.5594\n",
      "Test eval is  [1.1149200201034546, 0.559374988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:49:51.878913: Finished Train Fold #118/500 - thus far subj acc is 0.44152542372881354 and regular acc is0.4552171599056761\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #119\n",
      "A1 :  2022-04-07 22:50:10.906338\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7837 - acc: 0.5285 - val_loss: 0.7588 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7373 - acc: 0.5324 - val_loss: 0.7278 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7101 - acc: 0.5324 - val_loss: 0.7147 - val_acc: 0.5063\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6895 - acc: 0.5694 - val_loss: 0.7044 - val_acc: 0.4594\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6746 - acc: 0.5725 - val_loss: 0.6951 - val_acc: 0.5219\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6504 - acc: 0.6412 - val_loss: 0.6871 - val_acc: 0.5969\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6403 - acc: 0.6478 - val_loss: 0.7394 - val_acc: 0.5531\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6085 - acc: 0.6983 - val_loss: 0.7212 - val_acc: 0.5625\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5878 - acc: 0.7149 - val_loss: 0.7221 - val_acc: 0.5844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5604 - acc: 0.7369 - val_loss: 0.7627 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5408 - acc: 0.7542 - val_loss: 0.8129 - val_acc: 0.5500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5259 - acc: 0.7758 - val_loss: 0.7793 - val_acc: 0.5500\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4874 - acc: 0.8005 - val_loss: 0.8687 - val_acc: 0.5813\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4653 - acc: 0.8179 - val_loss: 0.8989 - val_acc: 0.5531\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4583 - acc: 0.8179 - val_loss: 1.0300 - val_acc: 0.5469\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4311 - acc: 0.8407 - val_loss: 0.8801 - val_acc: 0.5406\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3994 - acc: 0.8634 - val_loss: 1.0191 - val_acc: 0.5531\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3912 - acc: 0.8708 - val_loss: 1.0678 - val_acc: 0.5469\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3628 - acc: 0.8873 - val_loss: 1.1483 - val_acc: 0.5500\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3582 - acc: 0.8947 - val_loss: 1.0834 - val_acc: 0.5344\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1234 - acc: 0.5344\n",
      "Test eval is  [1.1233612298965454, 0.534375011920929]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:50:22.444767: Finished Train Fold #119/500 - thus far subj acc is 0.44285714285714284 and regular acc is0.45609243577267944\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #120\n",
      "A1 :  2022-04-07 22:50:41.474492\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7843 - acc: 0.5336 - val_loss: 0.7628 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7363 - acc: 0.5432 - val_loss: 0.7390 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7106 - acc: 0.5432 - val_loss: 0.7247 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6912 - acc: 0.5494 - val_loss: 0.7257 - val_acc: 0.3969\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6780 - acc: 0.5610 - val_loss: 0.7274 - val_acc: 0.4313\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6562 - acc: 0.5965 - val_loss: 0.7481 - val_acc: 0.4656\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6491 - acc: 0.6242 - val_loss: 0.7508 - val_acc: 0.4938\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6215 - acc: 0.6312 - val_loss: 0.7725 - val_acc: 0.4688\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6030 - acc: 0.6597 - val_loss: 0.7701 - val_acc: 0.5125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5873 - acc: 0.6686 - val_loss: 0.7825 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5616 - acc: 0.7284 - val_loss: 0.8061 - val_acc: 0.5437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5375 - acc: 0.7774 - val_loss: 0.8791 - val_acc: 0.4938\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5174 - acc: 0.7797 - val_loss: 0.8213 - val_acc: 0.5875\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4751 - acc: 0.8133 - val_loss: 1.0833 - val_acc: 0.4781\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4698 - acc: 0.8329 - val_loss: 0.9324 - val_acc: 0.5063\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4296 - acc: 0.8534 - val_loss: 1.0292 - val_acc: 0.5344\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4146 - acc: 0.8681 - val_loss: 1.0847 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3901 - acc: 0.8843 - val_loss: 1.1624 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3883 - acc: 0.8835 - val_loss: 1.1542 - val_acc: 0.4875\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7134 - acc: 0.5000\n",
      "Test eval is  [0.7133713960647583, 0.5]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:50:52.488233: Finished Train Fold #120/500 - thus far subj acc is 0.44416666666666665 and regular acc is0.45674479057391487\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #121\n",
      "A1 :  2022-04-07 22:51:11.529238\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7912 - acc: 0.5532 - val_loss: 0.7674 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7380 - acc: 0.5552 - val_loss: 0.7322 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7060 - acc: 0.5552 - val_loss: 0.7086 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6788 - acc: 0.5552 - val_loss: 0.7013 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6637 - acc: 0.5556 - val_loss: 0.7141 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6479 - acc: 0.5556 - val_loss: 0.6824 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6277 - acc: 0.6092 - val_loss: 0.7183 - val_acc: 0.5250\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6103 - acc: 0.7087 - val_loss: 0.7193 - val_acc: 0.5719\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5938 - acc: 0.7249 - val_loss: 0.7124 - val_acc: 0.5562\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5706 - acc: 0.7377 - val_loss: 0.7210 - val_acc: 0.5562\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5567 - acc: 0.7662 - val_loss: 0.7925 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5326 - acc: 0.7882 - val_loss: 0.8030 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5126 - acc: 0.8029 - val_loss: 0.7815 - val_acc: 0.5469\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5011 - acc: 0.8175 - val_loss: 0.8039 - val_acc: 0.4969\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4827 - acc: 0.8299 - val_loss: 0.8853 - val_acc: 0.5063\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4616 - acc: 0.8418 - val_loss: 0.8156 - val_acc: 0.5281\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4669 - acc: 0.8341 - val_loss: 0.9710 - val_acc: 0.5344\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4535 - acc: 0.8445 - val_loss: 0.9331 - val_acc: 0.5063\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4259 - acc: 0.8634 - val_loss: 0.9477 - val_acc: 0.5125\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4059 - acc: 0.8762 - val_loss: 0.9478 - val_acc: 0.5094\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5231 - acc: 0.4719\n",
      "Test eval is  [1.5230984687805176, 0.47187501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:51:23.424806: Finished Train Fold #121/500 - thus far subj acc is 0.44462809917355367 and regular acc is0.45710227164355194\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #122\n",
      "A1 :  2022-04-07 22:51:42.434713\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7849 - acc: 0.5397 - val_loss: 0.7535 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7336 - acc: 0.5424 - val_loss: 0.7304 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7046 - acc: 0.5428 - val_loss: 0.7210 - val_acc: 0.6000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6846 - acc: 0.5432 - val_loss: 0.7165 - val_acc: 0.6000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6627 - acc: 0.5432 - val_loss: 0.7028 - val_acc: 0.6000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6461 - acc: 0.6119 - val_loss: 0.7144 - val_acc: 0.4531\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6261 - acc: 0.6605 - val_loss: 0.7570 - val_acc: 0.4469\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6011 - acc: 0.7041 - val_loss: 0.7531 - val_acc: 0.4656\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5876 - acc: 0.7207 - val_loss: 0.7928 - val_acc: 0.4125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5658 - acc: 0.7519 - val_loss: 0.8212 - val_acc: 0.4344\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5436 - acc: 0.7739 - val_loss: 0.8322 - val_acc: 0.3906\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5304 - acc: 0.7832 - val_loss: 0.9137 - val_acc: 0.3812\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5149 - acc: 0.7955 - val_loss: 0.8892 - val_acc: 0.3875\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4939 - acc: 0.8106 - val_loss: 0.9451 - val_acc: 0.4000\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4850 - acc: 0.8113 - val_loss: 0.9415 - val_acc: 0.4000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4791 - acc: 0.8191 - val_loss: 0.9943 - val_acc: 0.3906\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4634 - acc: 0.8302 - val_loss: 1.0924 - val_acc: 0.3844\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4656 - acc: 0.8218 - val_loss: 1.0523 - val_acc: 0.3938\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4645 - acc: 0.8241 - val_loss: 1.1937 - val_acc: 0.3469\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4460 - acc: 0.8322 - val_loss: 1.0610 - val_acc: 0.4094\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1115 - acc: 0.5531\n",
      "Test eval is  [1.1114692687988281, 0.5531250238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:51:53.974351: Finished Train Fold #122/500 - thus far subj acc is 0.4442622950819672 and regular acc is0.4572233596786124\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #123\n",
      "A1 :  2022-04-07 22:52:12.992398\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7774 - acc: 0.5174 - val_loss: 0.7522 - val_acc: 0.4906\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7324 - acc: 0.5212 - val_loss: 0.7240 - val_acc: 0.4938\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7099 - acc: 0.5610 - val_loss: 0.7130 - val_acc: 0.5312\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6911 - acc: 0.5752 - val_loss: 0.7209 - val_acc: 0.4688\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6746 - acc: 0.5980 - val_loss: 0.7040 - val_acc: 0.5844\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6489 - acc: 0.6269 - val_loss: 0.7497 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6262 - acc: 0.6609 - val_loss: 0.7520 - val_acc: 0.5094\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5990 - acc: 0.6890 - val_loss: 0.7800 - val_acc: 0.5469\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5931 - acc: 0.7137 - val_loss: 0.8215 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5572 - acc: 0.7334 - val_loss: 0.8929 - val_acc: 0.5344\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5207 - acc: 0.7689 - val_loss: 0.8275 - val_acc: 0.5625\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4968 - acc: 0.7909 - val_loss: 0.8927 - val_acc: 0.5375\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4684 - acc: 0.8237 - val_loss: 0.9000 - val_acc: 0.5625\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4483 - acc: 0.8360 - val_loss: 0.8394 - val_acc: 0.5625\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4295 - acc: 0.8465 - val_loss: 1.0299 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4092 - acc: 0.8646 - val_loss: 1.0246 - val_acc: 0.5156\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3914 - acc: 0.8738 - val_loss: 1.0439 - val_acc: 0.5281\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3908 - acc: 0.8731 - val_loss: 0.9741 - val_acc: 0.5625\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3696 - acc: 0.8850 - val_loss: 1.0512 - val_acc: 0.5531\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3643 - acc: 0.8850 - val_loss: 1.1188 - val_acc: 0.5437\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0589 - acc: 0.5156\n",
      "Test eval is  [1.058931827545166, 0.515625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:52:34.772650: Finished Train Fold #123/500 - thus far subj acc is 0.4455284552845528 and regular acc is0.45800304800514285\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #124\n",
      "A1 :  2022-04-07 22:52:54.416134\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7902 - acc: 0.5197 - val_loss: 0.7616 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7406 - acc: 0.5305 - val_loss: 0.7299 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7109 - acc: 0.5417 - val_loss: 0.7118 - val_acc: 0.4938\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6929 - acc: 0.5575 - val_loss: 0.7098 - val_acc: 0.4969\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6709 - acc: 0.6142 - val_loss: 0.7061 - val_acc: 0.5344\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6424 - acc: 0.6566 - val_loss: 0.7342 - val_acc: 0.5469\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6180 - acc: 0.6991 - val_loss: 0.7922 - val_acc: 0.5375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5791 - acc: 0.7392 - val_loss: 0.8114 - val_acc: 0.5531\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5533 - acc: 0.7608 - val_loss: 0.8875 - val_acc: 0.5125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5202 - acc: 0.7824 - val_loss: 0.9014 - val_acc: 0.5312\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4749 - acc: 0.8117 - val_loss: 1.0102 - val_acc: 0.5688\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4561 - acc: 0.8260 - val_loss: 1.0995 - val_acc: 0.5625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4376 - acc: 0.8399 - val_loss: 1.0221 - val_acc: 0.5562\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4128 - acc: 0.8657 - val_loss: 1.1529 - val_acc: 0.5312\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3859 - acc: 0.8723 - val_loss: 1.2011 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3648 - acc: 0.8843 - val_loss: 1.1265 - val_acc: 0.5562\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3490 - acc: 0.8981 - val_loss: 1.2690 - val_acc: 0.5500\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3358 - acc: 0.9035 - val_loss: 1.2118 - val_acc: 0.5125\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3343 - acc: 0.9074 - val_loss: 1.3084 - val_acc: 0.5312\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3054 - acc: 0.9198 - val_loss: 1.2885 - val_acc: 0.5344\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3345 - acc: 0.4906\n",
      "Test eval is  [1.3344624042510986, 0.4906249940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:53:06.005909: Finished Train Fold #124/500 - thus far subj acc is 0.44596774193548383 and regular acc is0.45846774116639166\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #125\n",
      "A1 :  2022-04-07 22:53:25.295893\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.8028 - acc: 0.5278 - val_loss: 0.7813 - val_acc: 0.3938\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7475 - acc: 0.5536 - val_loss: 0.7532 - val_acc: 0.3750\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7075 - acc: 0.5806 - val_loss: 0.7793 - val_acc: 0.3750\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6763 - acc: 0.6231 - val_loss: 0.8237 - val_acc: 0.4125\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6543 - acc: 0.6404 - val_loss: 0.8460 - val_acc: 0.4031\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6207 - acc: 0.6694 - val_loss: 0.8560 - val_acc: 0.3812\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5874 - acc: 0.7056 - val_loss: 0.9317 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5512 - acc: 0.7504 - val_loss: 0.9297 - val_acc: 0.5344\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5199 - acc: 0.7770 - val_loss: 0.9945 - val_acc: 0.4781\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4827 - acc: 0.8148 - val_loss: 1.0179 - val_acc: 0.5156\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4501 - acc: 0.8206 - val_loss: 0.9774 - val_acc: 0.5406\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4136 - acc: 0.8418 - val_loss: 1.0926 - val_acc: 0.5938\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3854 - acc: 0.8623 - val_loss: 1.2820 - val_acc: 0.5312\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3500 - acc: 0.8897 - val_loss: 1.3024 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3453 - acc: 0.8904 - val_loss: 1.2687 - val_acc: 0.5844\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3192 - acc: 0.9082 - val_loss: 1.2854 - val_acc: 0.5625\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3172 - acc: 0.9147 - val_loss: 1.3027 - val_acc: 0.5750\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3191 - acc: 0.9097 - val_loss: 1.0946 - val_acc: 0.6281\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7308 - acc: 0.5688\n",
      "Test eval is  [0.7308193445205688, 0.5687500238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:53:35.646536: Finished Train Fold #125/500 - thus far subj acc is 0.44639999999999996 and regular acc is0.4587249991893768\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #126\n",
      "A1 :  2022-04-07 22:53:54.698660\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7863 - acc: 0.5482 - val_loss: 0.7642 - val_acc: 0.4313\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7374 - acc: 0.5637 - val_loss: 0.7424 - val_acc: 0.4563\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7074 - acc: 0.5895 - val_loss: 0.7273 - val_acc: 0.5375\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6790 - acc: 0.6219 - val_loss: 0.7152 - val_acc: 0.5625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6507 - acc: 0.6655 - val_loss: 0.7612 - val_acc: 0.5594\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6134 - acc: 0.7018 - val_loss: 0.7889 - val_acc: 0.5594\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5860 - acc: 0.7292 - val_loss: 0.8340 - val_acc: 0.5406\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5654 - acc: 0.7423 - val_loss: 0.8274 - val_acc: 0.5594\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5211 - acc: 0.7847 - val_loss: 0.8674 - val_acc: 0.5531\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4951 - acc: 0.8059 - val_loss: 0.8860 - val_acc: 0.5625\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4642 - acc: 0.8329 - val_loss: 1.0781 - val_acc: 0.5375\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4391 - acc: 0.8449 - val_loss: 1.0374 - val_acc: 0.5531\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4290 - acc: 0.8526 - val_loss: 0.9730 - val_acc: 0.5594\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4118 - acc: 0.8557 - val_loss: 1.0048 - val_acc: 0.5375\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3800 - acc: 0.8827 - val_loss: 1.1391 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3600 - acc: 0.8920 - val_loss: 1.0973 - val_acc: 0.5594\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3423 - acc: 0.8958 - val_loss: 1.1894 - val_acc: 0.5562\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3173 - acc: 0.9144 - val_loss: 1.1476 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3056 - acc: 0.9225 - val_loss: 1.2177 - val_acc: 0.5625\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3028 - acc: 0.9190 - val_loss: 1.3866 - val_acc: 0.5281\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7398 - acc: 0.3313\n",
      "Test eval is  [0.7397528886795044, 0.33125001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:54:06.069951: Finished Train Fold #126/500 - thus far subj acc is 0.4476190476190476 and regular acc is0.4595982136707457\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #127\n",
      "A1 :  2022-04-07 22:54:25.102601\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7847 - acc: 0.5702 - val_loss: 0.7636 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7293 - acc: 0.5802 - val_loss: 0.7405 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6965 - acc: 0.5802 - val_loss: 0.7350 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6757 - acc: 0.5802 - val_loss: 0.7272 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6573 - acc: 0.5802 - val_loss: 0.7597 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6328 - acc: 0.5802 - val_loss: 0.7365 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6132 - acc: 0.6165 - val_loss: 0.8463 - val_acc: 0.4969\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5934 - acc: 0.7087 - val_loss: 0.7917 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5724 - acc: 0.7446 - val_loss: 0.8603 - val_acc: 0.4469\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5567 - acc: 0.7762 - val_loss: 0.9961 - val_acc: 0.4437\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5303 - acc: 0.7924 - val_loss: 0.9832 - val_acc: 0.4156\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5085 - acc: 0.8048 - val_loss: 1.1900 - val_acc: 0.4125\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4965 - acc: 0.8214 - val_loss: 0.9970 - val_acc: 0.4563\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4845 - acc: 0.8364 - val_loss: 1.0474 - val_acc: 0.4563\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4675 - acc: 0.8488 - val_loss: 1.1375 - val_acc: 0.4594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4562 - acc: 0.8492 - val_loss: 1.2002 - val_acc: 0.4656\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4356 - acc: 0.8573 - val_loss: 1.1419 - val_acc: 0.4469\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4340 - acc: 0.8634 - val_loss: 1.0230 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4382 - acc: 0.8573 - val_loss: 1.1902 - val_acc: 0.4406\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4100 - acc: 0.8715 - val_loss: 1.1663 - val_acc: 0.4781\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8912 - acc: 0.1000\n",
      "Test eval is  [0.8912097811698914, 0.10000000149011612]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:54:36.569085: Finished Train Fold #127/500 - thus far subj acc is 0.4464566929133858 and regular acc is0.45858759790893616\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #128\n",
      "A1 :  2022-04-07 22:54:55.586609\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7913 - acc: 0.5270 - val_loss: 0.7630 - val_acc: 0.5031\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7416 - acc: 0.5505 - val_loss: 0.7283 - val_acc: 0.5125\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7151 - acc: 0.5671 - val_loss: 0.7078 - val_acc: 0.5906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6959 - acc: 0.5822 - val_loss: 0.7048 - val_acc: 0.5750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6847 - acc: 0.6142 - val_loss: 0.7199 - val_acc: 0.5688\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6683 - acc: 0.6420 - val_loss: 0.6997 - val_acc: 0.5500\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6479 - acc: 0.6555 - val_loss: 0.7240 - val_acc: 0.5281\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6043 - acc: 0.7141 - val_loss: 0.7744 - val_acc: 0.5344\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5871 - acc: 0.7431 - val_loss: 0.8542 - val_acc: 0.5406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5533 - acc: 0.7689 - val_loss: 0.8740 - val_acc: 0.5281\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5074 - acc: 0.8048 - val_loss: 1.0593 - val_acc: 0.5500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4717 - acc: 0.8310 - val_loss: 1.0006 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4530 - acc: 0.8407 - val_loss: 1.1504 - val_acc: 0.5562\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4278 - acc: 0.8619 - val_loss: 1.0844 - val_acc: 0.5281\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4082 - acc: 0.8738 - val_loss: 1.2406 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3772 - acc: 0.8862 - val_loss: 1.2069 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3589 - acc: 0.9024 - val_loss: 1.4241 - val_acc: 0.5594\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3466 - acc: 0.9051 - val_loss: 1.3215 - val_acc: 0.5406\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3177 - acc: 0.9182 - val_loss: 1.3690 - val_acc: 0.5562\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2960 - acc: 0.9309 - val_loss: 1.3415 - val_acc: 0.5250\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2899 - acc: 0.4781\n",
      "Test eval is  [1.2898728847503662, 0.4781250059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:55:17.360454: Finished Train Fold #128/500 - thus far subj acc is 0.44375000000000003 and regular acc is0.4557861323119141\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #129\n",
      "A1 :  2022-04-07 22:55:36.463453\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7869 - acc: 0.5347 - val_loss: 0.7597 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7367 - acc: 0.5436 - val_loss: 0.7281 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7072 - acc: 0.5548 - val_loss: 0.7137 - val_acc: 0.5125\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6920 - acc: 0.5675 - val_loss: 0.7052 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6734 - acc: 0.5795 - val_loss: 0.7074 - val_acc: 0.5094\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6612 - acc: 0.6061 - val_loss: 0.7258 - val_acc: 0.4750\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6492 - acc: 0.6242 - val_loss: 0.7293 - val_acc: 0.4781\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6191 - acc: 0.6632 - val_loss: 0.7942 - val_acc: 0.4875\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5953 - acc: 0.6717 - val_loss: 0.7846 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5661 - acc: 0.7242 - val_loss: 0.8711 - val_acc: 0.5094\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5472 - acc: 0.7307 - val_loss: 0.9573 - val_acc: 0.4812\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5207 - acc: 0.7604 - val_loss: 1.0371 - val_acc: 0.4281\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4724 - acc: 0.8117 - val_loss: 1.0730 - val_acc: 0.4500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4642 - acc: 0.8148 - val_loss: 1.0049 - val_acc: 0.4969\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4320 - acc: 0.8283 - val_loss: 1.1104 - val_acc: 0.4594\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4079 - acc: 0.8465 - val_loss: 1.2410 - val_acc: 0.4781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3741 - acc: 0.8723 - val_loss: 1.2444 - val_acc: 0.5250\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3711 - acc: 0.8816 - val_loss: 1.2575 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3438 - acc: 0.8920 - val_loss: 1.2872 - val_acc: 0.5250\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3251 - acc: 0.9035 - val_loss: 1.4053 - val_acc: 0.4625\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7493 - acc: 0.4000\n",
      "Test eval is  [0.749300479888916, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:55:48.273740: Finished Train Fold #129/500 - thus far subj acc is 0.4441860465116279 and regular acc is0.45595930187508116\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #130\n",
      "A1 :  2022-04-07 22:56:07.292713\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7962 - acc: 0.5046 - val_loss: 0.7656 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7440 - acc: 0.5374 - val_loss: 0.7304 - val_acc: 0.4875\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7173 - acc: 0.5556 - val_loss: 0.7108 - val_acc: 0.5188\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7015 - acc: 0.5679 - val_loss: 0.7002 - val_acc: 0.5625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6930 - acc: 0.5679 - val_loss: 0.7005 - val_acc: 0.5375\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6812 - acc: 0.5876 - val_loss: 0.7031 - val_acc: 0.5281\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6634 - acc: 0.6146 - val_loss: 0.7324 - val_acc: 0.5094\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6517 - acc: 0.6304 - val_loss: 0.7515 - val_acc: 0.4906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6373 - acc: 0.6439 - val_loss: 0.7914 - val_acc: 0.5250\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6130 - acc: 0.6728 - val_loss: 0.8595 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5861 - acc: 0.7091 - val_loss: 0.8714 - val_acc: 0.5281\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5628 - acc: 0.7377 - val_loss: 0.9102 - val_acc: 0.4719\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5352 - acc: 0.7662 - val_loss: 1.0131 - val_acc: 0.4688\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4970 - acc: 0.7878 - val_loss: 0.9678 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4765 - acc: 0.8075 - val_loss: 1.0223 - val_acc: 0.4563\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4442 - acc: 0.8349 - val_loss: 1.2511 - val_acc: 0.4375\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4289 - acc: 0.8441 - val_loss: 1.2582 - val_acc: 0.4563\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4000 - acc: 0.8673 - val_loss: 1.3890 - val_acc: 0.4281\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3797 - acc: 0.8777 - val_loss: 1.3755 - val_acc: 0.4781\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3427 - acc: 0.8958 - val_loss: 1.5770 - val_acc: 0.4656\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7165 - acc: 0.4625\n",
      "Test eval is  [0.716513454914093, 0.4625000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:56:18.846375: Finished Train Fold #130/500 - thus far subj acc is 0.44384615384615383 and regular acc is0.45552884575266106\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #131\n",
      "A1 :  2022-04-07 22:56:37.931519\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7892 - acc: 0.5289 - val_loss: 0.7618 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7392 - acc: 0.5309 - val_loss: 0.7286 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7108 - acc: 0.5301 - val_loss: 0.7126 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6930 - acc: 0.5332 - val_loss: 0.7150 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6796 - acc: 0.5698 - val_loss: 0.7355 - val_acc: 0.4437\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6680 - acc: 0.6138 - val_loss: 0.7257 - val_acc: 0.4406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6451 - acc: 0.6520 - val_loss: 0.7750 - val_acc: 0.4187\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6160 - acc: 0.6813 - val_loss: 0.8333 - val_acc: 0.4688\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5906 - acc: 0.7172 - val_loss: 0.8358 - val_acc: 0.4625\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5558 - acc: 0.7473 - val_loss: 0.9060 - val_acc: 0.4594\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5366 - acc: 0.7623 - val_loss: 0.9271 - val_acc: 0.4875\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5134 - acc: 0.7940 - val_loss: 0.9005 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4911 - acc: 0.8137 - val_loss: 0.9490 - val_acc: 0.5312\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4639 - acc: 0.8387 - val_loss: 1.0649 - val_acc: 0.4531\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4428 - acc: 0.8410 - val_loss: 1.0524 - val_acc: 0.4781\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4119 - acc: 0.8627 - val_loss: 1.0548 - val_acc: 0.4750\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4165 - acc: 0.8569 - val_loss: 1.0812 - val_acc: 0.4812\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3746 - acc: 0.8846 - val_loss: 1.1797 - val_acc: 0.4969\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3691 - acc: 0.8889 - val_loss: 1.0592 - val_acc: 0.5063\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7235 - acc: 0.5000\n",
      "Test eval is  [0.7234607338905334, 0.5]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:56:49.318036: Finished Train Fold #131/500 - thus far subj acc is 0.4442748091603053 and regular acc is0.4555820607160794\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #132\n",
      "A1 :  2022-04-07 22:57:08.302799\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7909 - acc: 0.5544 - val_loss: 0.7656 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7347 - acc: 0.5795 - val_loss: 0.7334 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7029 - acc: 0.5883 - val_loss: 0.7255 - val_acc: 0.4906\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6750 - acc: 0.6142 - val_loss: 0.7510 - val_acc: 0.4500\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6479 - acc: 0.6393 - val_loss: 0.7742 - val_acc: 0.5063\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6230 - acc: 0.6736 - val_loss: 0.7700 - val_acc: 0.5719\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5833 - acc: 0.7157 - val_loss: 0.8161 - val_acc: 0.5500\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5472 - acc: 0.7485 - val_loss: 0.8204 - val_acc: 0.6250\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5025 - acc: 0.7755 - val_loss: 0.9360 - val_acc: 0.6000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4691 - acc: 0.8152 - val_loss: 0.9731 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4339 - acc: 0.8445 - val_loss: 0.9064 - val_acc: 0.5437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4050 - acc: 0.8546 - val_loss: 1.0699 - val_acc: 0.5375\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3804 - acc: 0.8777 - val_loss: 1.1488 - val_acc: 0.5063\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3543 - acc: 0.8904 - val_loss: 1.1690 - val_acc: 0.5344\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3455 - acc: 0.8935 - val_loss: 1.1958 - val_acc: 0.5219\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3179 - acc: 0.9132 - val_loss: 1.3021 - val_acc: 0.5250\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3045 - acc: 0.9163 - val_loss: 1.2387 - val_acc: 0.5281\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2781 - acc: 0.9271 - val_loss: 1.3664 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2790 - acc: 0.9344 - val_loss: 1.2599 - val_acc: 0.5594\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8691 - acc: 0.1031\n",
      "Test eval is  [0.8691387176513672, 0.10312499850988388]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:57:19.444517: Finished Train Fold #132/500 - thus far subj acc is 0.44469696969696965 and regular acc is0.4559185602561091\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #133\n",
      "A1 :  2022-04-07 22:57:38.496696\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7820 - acc: 0.5185 - val_loss: 0.7556 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7352 - acc: 0.5328 - val_loss: 0.7265 - val_acc: 0.4750\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7019 - acc: 0.5768 - val_loss: 0.7391 - val_acc: 0.5437\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6735 - acc: 0.6138 - val_loss: 0.7661 - val_acc: 0.5125\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6531 - acc: 0.6254 - val_loss: 0.8040 - val_acc: 0.5063\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6280 - acc: 0.6605 - val_loss: 0.8630 - val_acc: 0.5437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5913 - acc: 0.6937 - val_loss: 0.9491 - val_acc: 0.5344\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5661 - acc: 0.7334 - val_loss: 0.8575 - val_acc: 0.5406\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5329 - acc: 0.7604 - val_loss: 0.8892 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5058 - acc: 0.7793 - val_loss: 0.9827 - val_acc: 0.5437\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4796 - acc: 0.7998 - val_loss: 1.0141 - val_acc: 0.5500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4414 - acc: 0.8349 - val_loss: 0.9703 - val_acc: 0.5844\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4214 - acc: 0.8526 - val_loss: 1.0620 - val_acc: 0.5781\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3954 - acc: 0.8611 - val_loss: 1.0646 - val_acc: 0.5844\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3783 - acc: 0.8762 - val_loss: 1.0593 - val_acc: 0.5906\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3692 - acc: 0.8831 - val_loss: 1.1153 - val_acc: 0.5688\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3438 - acc: 0.8997 - val_loss: 1.0172 - val_acc: 0.6187\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3404 - acc: 0.8958 - val_loss: 1.1682 - val_acc: 0.5875\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7258 - acc: 0.5406\n",
      "Test eval is  [0.7258334755897522, 0.5406249761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:57:49.161213: Finished Train Fold #133/500 - thus far subj acc is 0.4421052631578947 and regular acc is0.45326597708508487\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #134\n",
      "A1 :  2022-04-07 22:58:08.214389\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7867 - acc: 0.5270 - val_loss: 0.7648 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7382 - acc: 0.5309 - val_loss: 0.7392 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7110 - acc: 0.5309 - val_loss: 0.7257 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6892 - acc: 0.5309 - val_loss: 0.7374 - val_acc: 0.4000\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6736 - acc: 0.5309 - val_loss: 0.7519 - val_acc: 0.4000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6526 - acc: 0.6011 - val_loss: 0.7791 - val_acc: 0.4250\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6395 - acc: 0.6752 - val_loss: 0.8077 - val_acc: 0.4313\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6106 - acc: 0.6952 - val_loss: 0.8947 - val_acc: 0.4594\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5979 - acc: 0.7188 - val_loss: 0.8093 - val_acc: 0.4750\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5818 - acc: 0.7353 - val_loss: 0.9511 - val_acc: 0.4531\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5759 - acc: 0.7415 - val_loss: 0.9254 - val_acc: 0.5188\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5554 - acc: 0.7596 - val_loss: 0.8961 - val_acc: 0.4938\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5485 - acc: 0.7620 - val_loss: 0.9043 - val_acc: 0.5094\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5251 - acc: 0.7793 - val_loss: 0.9252 - val_acc: 0.5094\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5170 - acc: 0.7982 - val_loss: 0.9209 - val_acc: 0.5094\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5026 - acc: 0.7963 - val_loss: 1.0566 - val_acc: 0.4781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4911 - acc: 0.8164 - val_loss: 1.1863 - val_acc: 0.4531\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4723 - acc: 0.8233 - val_loss: 1.1730 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4732 - acc: 0.8260 - val_loss: 1.2620 - val_acc: 0.4844\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7070 - acc: 0.6000\n",
      "Test eval is  [0.7070468664169312, 0.6000000238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:58:19.295946: Finished Train Fold #134/500 - thus far subj acc is 0.4432835820895522 and regular acc is0.4539179099139883\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #135\n",
      "A1 :  2022-04-07 22:58:38.376048\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7818 - acc: 0.5343 - val_loss: 0.7588 - val_acc: 0.4844\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7307 - acc: 0.5513 - val_loss: 0.7278 - val_acc: 0.5312\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7018 - acc: 0.5710 - val_loss: 0.7161 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6730 - acc: 0.6065 - val_loss: 0.7296 - val_acc: 0.4719\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6461 - acc: 0.6489 - val_loss: 0.7554 - val_acc: 0.5156\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6160 - acc: 0.6840 - val_loss: 0.7817 - val_acc: 0.5500\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5946 - acc: 0.7045 - val_loss: 0.8737 - val_acc: 0.5250\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5400 - acc: 0.7546 - val_loss: 0.9066 - val_acc: 0.4906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5229 - acc: 0.7697 - val_loss: 0.9574 - val_acc: 0.5156\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4871 - acc: 0.8044 - val_loss: 0.9573 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4523 - acc: 0.8252 - val_loss: 1.1161 - val_acc: 0.5188\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4437 - acc: 0.8287 - val_loss: 1.0641 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4117 - acc: 0.8445 - val_loss: 1.0944 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3811 - acc: 0.8765 - val_loss: 1.1843 - val_acc: 0.5219\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3601 - acc: 0.8873 - val_loss: 1.1662 - val_acc: 0.5406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3351 - acc: 0.9039 - val_loss: 1.2669 - val_acc: 0.5250\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3259 - acc: 0.9035 - val_loss: 1.3503 - val_acc: 0.4969\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3260 - acc: 0.9066 - val_loss: 1.4029 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3037 - acc: 0.9159 - val_loss: 1.4797 - val_acc: 0.4812\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7527 - acc: 0.3594\n",
      "Test eval is  [0.7527095675468445, 0.359375]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:58:49.415068: Finished Train Fold #135/500 - thus far subj acc is 0.4444444444444444 and regular acc is0.4549999996467873\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #136\n",
      "A1 :  2022-04-07 22:59:08.431866\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7925 - acc: 0.5181 - val_loss: 0.7638 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7409 - acc: 0.5185 - val_loss: 0.7296 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7081 - acc: 0.5660 - val_loss: 0.7013 - val_acc: 0.5531\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6863 - acc: 0.5868 - val_loss: 0.7058 - val_acc: 0.5594\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6684 - acc: 0.6084 - val_loss: 0.7016 - val_acc: 0.5719\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6452 - acc: 0.6478 - val_loss: 0.7137 - val_acc: 0.5969\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6250 - acc: 0.6744 - val_loss: 0.7373 - val_acc: 0.5469\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6046 - acc: 0.6952 - val_loss: 0.7134 - val_acc: 0.5531\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5879 - acc: 0.7153 - val_loss: 0.7537 - val_acc: 0.5719\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5651 - acc: 0.7299 - val_loss: 0.7698 - val_acc: 0.5500\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5542 - acc: 0.7427 - val_loss: 0.7586 - val_acc: 0.5562\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5199 - acc: 0.7843 - val_loss: 0.8146 - val_acc: 0.5156\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5200 - acc: 0.7801 - val_loss: 0.8036 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5013 - acc: 0.7924 - val_loss: 0.8011 - val_acc: 0.5531\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4693 - acc: 0.8179 - val_loss: 1.0879 - val_acc: 0.5625\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4641 - acc: 0.8233 - val_loss: 0.9487 - val_acc: 0.5656\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4351 - acc: 0.8418 - val_loss: 0.9069 - val_acc: 0.5625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4190 - acc: 0.8519 - val_loss: 0.9865 - val_acc: 0.5906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4130 - acc: 0.8565 - val_loss: 0.9104 - val_acc: 0.5688\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7313 - acc: 0.5719\n",
      "Test eval is  [0.7313200235366821, 0.5718749761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:59:19.528201: Finished Train Fold #136/500 - thus far subj acc is 0.4441176470588235 and regular acc is0.45429687464938445\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #137\n",
      "A1 :  2022-04-07 22:59:38.544382\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7978 - acc: 0.5193 - val_loss: 0.7684 - val_acc: 0.4812\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7447 - acc: 0.5575 - val_loss: 0.7354 - val_acc: 0.4906\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7084 - acc: 0.5814 - val_loss: 0.7311 - val_acc: 0.4563\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6763 - acc: 0.6296 - val_loss: 0.7514 - val_acc: 0.4781\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6370 - acc: 0.6871 - val_loss: 0.8045 - val_acc: 0.4437\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5954 - acc: 0.7157 - val_loss: 0.8783 - val_acc: 0.4344\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5509 - acc: 0.7670 - val_loss: 0.9345 - val_acc: 0.4406\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5068 - acc: 0.8029 - val_loss: 0.9837 - val_acc: 0.4531\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4678 - acc: 0.8329 - val_loss: 1.1058 - val_acc: 0.4750\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4480 - acc: 0.8441 - val_loss: 1.0778 - val_acc: 0.4938\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4096 - acc: 0.8650 - val_loss: 1.1637 - val_acc: 0.4437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3886 - acc: 0.8711 - val_loss: 1.1813 - val_acc: 0.4625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3619 - acc: 0.8893 - val_loss: 1.2911 - val_acc: 0.4781\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3320 - acc: 0.9097 - val_loss: 1.3170 - val_acc: 0.4750\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3402 - acc: 0.9051 - val_loss: 1.4035 - val_acc: 0.4812\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3238 - acc: 0.9186 - val_loss: 1.3695 - val_acc: 0.4688\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2927 - acc: 0.9321 - val_loss: 1.5376 - val_acc: 0.4906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.2929 - acc: 0.9290 - val_loss: 1.4558 - val_acc: 0.4625\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2867 - acc: 0.9282 - val_loss: 1.5808 - val_acc: 0.4406\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7456 - acc: 0.5031\n",
      "Test eval is  [0.7455518245697021, 0.503125011920929]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 22:59:49.671614: Finished Train Fold #137/500 - thus far subj acc is 0.44525547445255476 and regular acc is0.4551551089669666\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #138\n",
      "A1 :  2022-04-07 23:00:08.637705\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7975 - acc: 0.5432 - val_loss: 0.7730 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7448 - acc: 0.5432 - val_loss: 0.7395 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7088 - acc: 0.5478 - val_loss: 0.7304 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6860 - acc: 0.5826 - val_loss: 0.7249 - val_acc: 0.4656\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6616 - acc: 0.6130 - val_loss: 0.7174 - val_acc: 0.6000\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6353 - acc: 0.6474 - val_loss: 0.8175 - val_acc: 0.4938\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6008 - acc: 0.6964 - val_loss: 0.8597 - val_acc: 0.5063\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5674 - acc: 0.7272 - val_loss: 0.9417 - val_acc: 0.5063\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5321 - acc: 0.7596 - val_loss: 0.9516 - val_acc: 0.4812\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5026 - acc: 0.7801 - val_loss: 0.9947 - val_acc: 0.4375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4723 - acc: 0.7967 - val_loss: 1.0799 - val_acc: 0.4500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4490 - acc: 0.8206 - val_loss: 1.0834 - val_acc: 0.4781\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4318 - acc: 0.8434 - val_loss: 1.1166 - val_acc: 0.5156\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4074 - acc: 0.8530 - val_loss: 1.2190 - val_acc: 0.4656\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3911 - acc: 0.8681 - val_loss: 1.3297 - val_acc: 0.4656\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3640 - acc: 0.8746 - val_loss: 1.2368 - val_acc: 0.4656\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3486 - acc: 0.8858 - val_loss: 1.4407 - val_acc: 0.4531\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3365 - acc: 0.8947 - val_loss: 1.4116 - val_acc: 0.4500\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3392 - acc: 0.8958 - val_loss: 1.4574 - val_acc: 0.4875\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3068 - acc: 0.9101 - val_loss: 1.4929 - val_acc: 0.4844\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4463 - acc: 0.5125\n",
      "Test eval is  [1.446346402168274, 0.512499988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:00:20.261630: Finished Train Fold #138/500 - thus far subj acc is 0.4463768115942029 and regular acc is0.45550271695938666\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #139\n",
      "A1 :  2022-04-07 23:00:39.282172\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7967 - acc: 0.5228 - val_loss: 0.7654 - val_acc: 0.5531\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7429 - acc: 0.5791 - val_loss: 0.7485 - val_acc: 0.4688\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7071 - acc: 0.5972 - val_loss: 0.8349 - val_acc: 0.4219\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6835 - acc: 0.6080 - val_loss: 0.8029 - val_acc: 0.4563\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6606 - acc: 0.6370 - val_loss: 0.8892 - val_acc: 0.4469\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6468 - acc: 0.6617 - val_loss: 0.8950 - val_acc: 0.4219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6218 - acc: 0.6813 - val_loss: 0.9798 - val_acc: 0.4313\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6013 - acc: 0.7091 - val_loss: 1.0401 - val_acc: 0.4469\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5656 - acc: 0.7504 - val_loss: 1.0140 - val_acc: 0.4437\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5399 - acc: 0.7616 - val_loss: 1.0861 - val_acc: 0.4969\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5027 - acc: 0.7921 - val_loss: 1.2381 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4763 - acc: 0.8137 - val_loss: 1.0206 - val_acc: 0.5031\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4535 - acc: 0.8275 - val_loss: 1.5429 - val_acc: 0.4219\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4463 - acc: 0.8299 - val_loss: 1.3275 - val_acc: 0.4906\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4255 - acc: 0.8418 - val_loss: 1.2773 - val_acc: 0.4688\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3851 - acc: 0.8785 - val_loss: 1.2272 - val_acc: 0.5063\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3779 - acc: 0.8877 - val_loss: 1.3589 - val_acc: 0.4656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3677 - acc: 0.8827 - val_loss: 1.5136 - val_acc: 0.4500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7410 - acc: 0.4875\n",
      "Test eval is  [0.7409900426864624, 0.48750001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:00:49.970328: Finished Train Fold #139/500 - thus far subj acc is 0.4474820143884892 and regular acc is0.45591276926960017\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #140\n",
      "A1 :  2022-04-07 23:01:08.971264\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7860 - acc: 0.5390 - val_loss: 0.7683 - val_acc: 0.3656\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7339 - acc: 0.5664 - val_loss: 0.7724 - val_acc: 0.3281\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6971 - acc: 0.5976 - val_loss: 0.7847 - val_acc: 0.3531\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6730 - acc: 0.6223 - val_loss: 0.8305 - val_acc: 0.3281\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6527 - acc: 0.6539 - val_loss: 0.8542 - val_acc: 0.3875\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6140 - acc: 0.7002 - val_loss: 0.8758 - val_acc: 0.4625\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5766 - acc: 0.7373 - val_loss: 0.9140 - val_acc: 0.4656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5411 - acc: 0.7693 - val_loss: 1.1050 - val_acc: 0.4437\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5028 - acc: 0.7982 - val_loss: 1.0855 - val_acc: 0.3844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4753 - acc: 0.8187 - val_loss: 1.1925 - val_acc: 0.4344\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4531 - acc: 0.8337 - val_loss: 1.1962 - val_acc: 0.4344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4125 - acc: 0.8638 - val_loss: 1.2652 - val_acc: 0.4281\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4037 - acc: 0.8654 - val_loss: 1.2137 - val_acc: 0.4062\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3975 - acc: 0.8688 - val_loss: 1.2760 - val_acc: 0.4500\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3613 - acc: 0.8897 - val_loss: 1.4560 - val_acc: 0.4406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3469 - acc: 0.8993 - val_loss: 1.4992 - val_acc: 0.4406\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3171 - acc: 0.9155 - val_loss: 1.6414 - val_acc: 0.4187\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7591 - acc: 0.5781\n",
      "Test eval is  [0.7591174840927124, 0.578125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:01:19.095096: Finished Train Fold #140/500 - thus far subj acc is 0.4478571428571429 and regular acc is0.45613839243139537\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #141\n",
      "A1 :  2022-04-07 23:01:38.093080\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7832 - acc: 0.5285 - val_loss: 0.7566 - val_acc: 0.4719\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7361 - acc: 0.5637 - val_loss: 0.7248 - val_acc: 0.5531\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7041 - acc: 0.6042 - val_loss: 0.7093 - val_acc: 0.5750\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6809 - acc: 0.6200 - val_loss: 0.6981 - val_acc: 0.5844\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6624 - acc: 0.6397 - val_loss: 0.6934 - val_acc: 0.5969\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6433 - acc: 0.6617 - val_loss: 0.7042 - val_acc: 0.5656\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6331 - acc: 0.6821 - val_loss: 0.7053 - val_acc: 0.5656\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6048 - acc: 0.7141 - val_loss: 0.7314 - val_acc: 0.5375\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5792 - acc: 0.7319 - val_loss: 0.7645 - val_acc: 0.5469\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5599 - acc: 0.7585 - val_loss: 0.7659 - val_acc: 0.5281\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.7689 - val_loss: 0.8145 - val_acc: 0.5437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5198 - acc: 0.7824 - val_loss: 0.8279 - val_acc: 0.5344\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4826 - acc: 0.8148 - val_loss: 0.8788 - val_acc: 0.5312\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4636 - acc: 0.8260 - val_loss: 0.8671 - val_acc: 0.5750\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4444 - acc: 0.8461 - val_loss: 0.9651 - val_acc: 0.5469\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4146 - acc: 0.8634 - val_loss: 0.9149 - val_acc: 0.5437\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4041 - acc: 0.8630 - val_loss: 1.0535 - val_acc: 0.5344\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4045 - acc: 0.8700 - val_loss: 1.0221 - val_acc: 0.5469\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3842 - acc: 0.8800 - val_loss: 1.1085 - val_acc: 0.5188\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3522 - acc: 0.8997 - val_loss: 1.0751 - val_acc: 0.5500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6593 - acc: 0.2812\n",
      "Test eval is  [1.6592521667480469, 0.28125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:01:49.808295: Finished Train Fold #141/500 - thus far subj acc is 0.448936170212766 and regular acc is0.4570035456765628\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #142\n",
      "A1 :  2022-04-07 23:02:08.873584\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7847 - acc: 0.5282 - val_loss: 0.7621 - val_acc: 0.3656\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7360 - acc: 0.5390 - val_loss: 0.7340 - val_acc: 0.3656\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7106 - acc: 0.5675 - val_loss: 0.7227 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6882 - acc: 0.6057 - val_loss: 0.7255 - val_acc: 0.4375\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6683 - acc: 0.6316 - val_loss: 0.7254 - val_acc: 0.4969\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6444 - acc: 0.6497 - val_loss: 0.7833 - val_acc: 0.4437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6278 - acc: 0.6852 - val_loss: 0.7778 - val_acc: 0.4187\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5969 - acc: 0.7199 - val_loss: 0.7710 - val_acc: 0.4781\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5591 - acc: 0.7589 - val_loss: 0.8440 - val_acc: 0.4938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5311 - acc: 0.7762 - val_loss: 0.9256 - val_acc: 0.5188\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4972 - acc: 0.8021 - val_loss: 1.0879 - val_acc: 0.4500\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4765 - acc: 0.8117 - val_loss: 0.9070 - val_acc: 0.5312\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4533 - acc: 0.8422 - val_loss: 0.9809 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4226 - acc: 0.8519 - val_loss: 1.0428 - val_acc: 0.5219\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4024 - acc: 0.8735 - val_loss: 1.1760 - val_acc: 0.4406\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3763 - acc: 0.8870 - val_loss: 1.0265 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3641 - acc: 0.8885 - val_loss: 1.2265 - val_acc: 0.5375\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3296 - acc: 0.9101 - val_loss: 1.3092 - val_acc: 0.5031\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3046 - acc: 0.9244 - val_loss: 1.3044 - val_acc: 0.5344\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7147 - acc: 0.6125\n",
      "Test eval is  [0.714703381061554, 0.612500011920929]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:02:20.386931: Finished Train Fold #142/500 - thus far subj acc is 0.44577464788732396 and regular acc is0.4557658446506715\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #143\n",
      "A1 :  2022-04-07 23:02:41.066554\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7893 - acc: 0.5212 - val_loss: 0.7578 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7404 - acc: 0.5421 - val_loss: 0.7243 - val_acc: 0.5688\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.5667 - val_loss: 0.7551 - val_acc: 0.5281\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6899 - acc: 0.5910 - val_loss: 0.7938 - val_acc: 0.4750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.6015 - val_loss: 0.8008 - val_acc: 0.4750\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6641 - acc: 0.6254 - val_loss: 0.9057 - val_acc: 0.4375\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6526 - acc: 0.6416 - val_loss: 0.9203 - val_acc: 0.4219\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6377 - acc: 0.6620 - val_loss: 0.9350 - val_acc: 0.4219\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6192 - acc: 0.6840 - val_loss: 0.9761 - val_acc: 0.4281\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5947 - acc: 0.7172 - val_loss: 1.2496 - val_acc: 0.3531\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5773 - acc: 0.7373 - val_loss: 1.1123 - val_acc: 0.4031\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5526 - acc: 0.7569 - val_loss: 1.2431 - val_acc: 0.4094\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5405 - acc: 0.7677 - val_loss: 1.1797 - val_acc: 0.4344\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5056 - acc: 0.7978 - val_loss: 1.4196 - val_acc: 0.4062\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4904 - acc: 0.8067 - val_loss: 1.5504 - val_acc: 0.4000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4642 - acc: 0.8306 - val_loss: 1.3487 - val_acc: 0.4250\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4653 - acc: 0.8291 - val_loss: 1.4072 - val_acc: 0.4375\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4507 - acc: 0.8380 - val_loss: 1.3869 - val_acc: 0.4156\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7356 - acc: 0.3969\n",
      "Test eval is  [0.7355841398239136, 0.3968749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:02:51.563366: Finished Train Fold #143/500 - thus far subj acc is 0.4461538461538462 and regular acc is0.45686188777843556\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #144\n",
      "A1 :  2022-04-07 23:03:10.626472\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7829 - acc: 0.5154 - val_loss: 0.7597 - val_acc: 0.3750\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7353 - acc: 0.5486 - val_loss: 0.7423 - val_acc: 0.3469\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7098 - acc: 0.5621 - val_loss: 0.7257 - val_acc: 0.3844\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6834 - acc: 0.5864 - val_loss: 0.7955 - val_acc: 0.3313\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6682 - acc: 0.5980 - val_loss: 0.9212 - val_acc: 0.4219\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6439 - acc: 0.6289 - val_loss: 0.9251 - val_acc: 0.4219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6230 - acc: 0.6597 - val_loss: 0.9262 - val_acc: 0.4594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5939 - acc: 0.6937 - val_loss: 0.9583 - val_acc: 0.4781\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5661 - acc: 0.7215 - val_loss: 1.0566 - val_acc: 0.4719\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5398 - acc: 0.7419 - val_loss: 1.0704 - val_acc: 0.4594\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5019 - acc: 0.7843 - val_loss: 1.1622 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4772 - acc: 0.7932 - val_loss: 1.2581 - val_acc: 0.3719\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4588 - acc: 0.8056 - val_loss: 1.2069 - val_acc: 0.4531\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4168 - acc: 0.8380 - val_loss: 1.2705 - val_acc: 0.4406\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4024 - acc: 0.8522 - val_loss: 1.3838 - val_acc: 0.4031\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3802 - acc: 0.8634 - val_loss: 1.2531 - val_acc: 0.4875\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3663 - acc: 0.8684 - val_loss: 1.4582 - val_acc: 0.4656\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3429 - acc: 0.8866 - val_loss: 1.5943 - val_acc: 0.4656\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3385 - acc: 0.8873 - val_loss: 1.5978 - val_acc: 0.4469\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6963 - acc: 0.7219\n",
      "Test eval is  [0.6963068246841431, 0.721875011920929]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:03:22.570657: Finished Train Fold #144/500 - thus far subj acc is 0.44583333333333325 and regular acc is0.45644531212747097\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #145\n",
      "A1 :  2022-04-07 23:03:42.598525\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7988 - acc: 0.5228 - val_loss: 0.7689 - val_acc: 0.4719\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7457 - acc: 0.5613 - val_loss: 0.7402 - val_acc: 0.4750\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7072 - acc: 0.5961 - val_loss: 0.7756 - val_acc: 0.4812\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6737 - acc: 0.6258 - val_loss: 0.7601 - val_acc: 0.4594\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6454 - acc: 0.6698 - val_loss: 0.7779 - val_acc: 0.5719\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6080 - acc: 0.7087 - val_loss: 0.8255 - val_acc: 0.5156\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5707 - acc: 0.7461 - val_loss: 0.8499 - val_acc: 0.5094\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5387 - acc: 0.7720 - val_loss: 0.8802 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5043 - acc: 0.7982 - val_loss: 0.9242 - val_acc: 0.4969\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4797 - acc: 0.8268 - val_loss: 1.0375 - val_acc: 0.5125\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4432 - acc: 0.8422 - val_loss: 1.0357 - val_acc: 0.4781\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4137 - acc: 0.8592 - val_loss: 1.1107 - val_acc: 0.4875\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3771 - acc: 0.8873 - val_loss: 1.1971 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3546 - acc: 0.8974 - val_loss: 1.3043 - val_acc: 0.4844\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3357 - acc: 0.9008 - val_loss: 1.2784 - val_acc: 0.4938\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3068 - acc: 0.9182 - val_loss: 1.3541 - val_acc: 0.4812\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2910 - acc: 0.9360 - val_loss: 1.4050 - val_acc: 0.5031\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2906 - acc: 0.9336 - val_loss: 1.3623 - val_acc: 0.5156\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7478 - acc: 0.4688\n",
      "Test eval is  [0.7478228211402893, 0.46875]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:03:53.632632: Finished Train Fold #145/500 - thus far subj acc is 0.44758620689655176 and regular acc is0.45827586178121893\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #146\n",
      "A1 :  2022-04-07 23:04:13.081418\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7919 - acc: 0.5401 - val_loss: 0.7641 - val_acc: 0.5094\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7376 - acc: 0.5606 - val_loss: 0.7394 - val_acc: 0.5188\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7075 - acc: 0.5733 - val_loss: 0.7301 - val_acc: 0.5094\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6713 - acc: 0.5976 - val_loss: 0.7775 - val_acc: 0.5188\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6508 - acc: 0.6292 - val_loss: 0.8576 - val_acc: 0.5312\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.6640 - val_loss: 0.8808 - val_acc: 0.4625\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6021 - acc: 0.7168 - val_loss: 0.8671 - val_acc: 0.4875\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5676 - acc: 0.7350 - val_loss: 0.8991 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5319 - acc: 0.7608 - val_loss: 0.8837 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4998 - acc: 0.7851 - val_loss: 1.0021 - val_acc: 0.4844\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4517 - acc: 0.8175 - val_loss: 1.1079 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4334 - acc: 0.8472 - val_loss: 1.0973 - val_acc: 0.4688\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3906 - acc: 0.8611 - val_loss: 1.2207 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3635 - acc: 0.8785 - val_loss: 1.3133 - val_acc: 0.4969\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3568 - acc: 0.8831 - val_loss: 1.2185 - val_acc: 0.5156\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3473 - acc: 0.8854 - val_loss: 1.3922 - val_acc: 0.4781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3170 - acc: 0.9035 - val_loss: 1.4019 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2990 - acc: 0.9159 - val_loss: 1.4736 - val_acc: 0.4844\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2908 - acc: 0.9120 - val_loss: 1.5093 - val_acc: 0.5219\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.4688\n",
      "Test eval is  [0.7389122247695923, 0.46875]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:04:24.127571: Finished Train Fold #146/500 - thus far subj acc is 0.4472602739726027 and regular acc is0.45834760245395034\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #147\n",
      "A1 :  2022-04-07 23:04:43.304922\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7848 - acc: 0.5150 - val_loss: 0.7580 - val_acc: 0.4406\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7372 - acc: 0.5355 - val_loss: 0.7345 - val_acc: 0.4500\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7077 - acc: 0.5702 - val_loss: 0.7357 - val_acc: 0.4625\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6857 - acc: 0.5876 - val_loss: 0.7406 - val_acc: 0.4375\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6691 - acc: 0.6092 - val_loss: 0.8466 - val_acc: 0.5031\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6481 - acc: 0.6389 - val_loss: 0.7918 - val_acc: 0.4938\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6240 - acc: 0.6771 - val_loss: 0.8459 - val_acc: 0.5344\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5880 - acc: 0.7222 - val_loss: 0.8116 - val_acc: 0.5094\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5590 - acc: 0.7473 - val_loss: 0.8491 - val_acc: 0.5531\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5303 - acc: 0.7724 - val_loss: 0.9418 - val_acc: 0.4844\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4997 - acc: 0.7897 - val_loss: 0.9431 - val_acc: 0.4906\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4711 - acc: 0.8206 - val_loss: 0.8306 - val_acc: 0.5781\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4319 - acc: 0.8403 - val_loss: 1.0260 - val_acc: 0.5469\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4056 - acc: 0.8553 - val_loss: 1.0516 - val_acc: 0.5219\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3897 - acc: 0.8696 - val_loss: 1.0802 - val_acc: 0.5531\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3849 - acc: 0.8719 - val_loss: 1.1740 - val_acc: 0.5188\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3566 - acc: 0.8819 - val_loss: 1.1733 - val_acc: 0.5719\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3510 - acc: 0.8843 - val_loss: 1.2884 - val_acc: 0.5188\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7249 - acc: 0.5375\n",
      "Test eval is  [0.7248762845993042, 0.5375000238418579]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:04:53.929175: Finished Train Fold #147/500 - thus far subj acc is 0.446938775510204 and regular acc is0.4584183670631071\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #148\n",
      "A1 :  2022-04-07 23:05:13.079438\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7986 - acc: 0.5529 - val_loss: 0.7735 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7430 - acc: 0.5559 - val_loss: 0.7410 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7083 - acc: 0.5849 - val_loss: 0.7257 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6780 - acc: 0.6049 - val_loss: 0.7916 - val_acc: 0.4156\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6596 - acc: 0.6404 - val_loss: 0.8088 - val_acc: 0.5063\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6269 - acc: 0.6732 - val_loss: 0.8100 - val_acc: 0.4719\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6004 - acc: 0.7049 - val_loss: 0.8400 - val_acc: 0.4812\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5628 - acc: 0.7434 - val_loss: 0.8969 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5327 - acc: 0.7720 - val_loss: 0.9100 - val_acc: 0.5063\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4851 - acc: 0.8075 - val_loss: 1.0127 - val_acc: 0.5437\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4551 - acc: 0.8225 - val_loss: 1.0461 - val_acc: 0.4906\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4430 - acc: 0.8445 - val_loss: 1.0924 - val_acc: 0.4531\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3993 - acc: 0.8580 - val_loss: 1.2334 - val_acc: 0.4719\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3905 - acc: 0.8665 - val_loss: 1.1747 - val_acc: 0.4688\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3665 - acc: 0.8881 - val_loss: 1.2447 - val_acc: 0.4531\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3386 - acc: 0.8993 - val_loss: 1.2166 - val_acc: 0.4938\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3315 - acc: 0.8985 - val_loss: 1.3608 - val_acc: 0.5063\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3040 - acc: 0.9171 - val_loss: 1.3173 - val_acc: 0.4938\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3067 - acc: 0.9198 - val_loss: 1.4111 - val_acc: 0.4938\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7800 - acc: 0.2656\n",
      "Test eval is  [0.7799908518791199, 0.265625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:05:24.089670: Finished Train Fold #148/500 - thus far subj acc is 0.44797297297297295 and regular acc is0.4589527025818825\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #149\n",
      "A1 :  2022-04-07 23:05:43.185174\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7823 - acc: 0.5089 - val_loss: 0.7551 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7342 - acc: 0.5197 - val_loss: 0.7258 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7050 - acc: 0.5459 - val_loss: 0.7239 - val_acc: 0.4656\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6856 - acc: 0.5714 - val_loss: 0.7103 - val_acc: 0.4906\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.6690 - acc: 0.6084 - val_loss: 0.7024 - val_acc: 0.5406\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6527 - acc: 0.6481 - val_loss: 0.7200 - val_acc: 0.5281\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6342 - acc: 0.6790 - val_loss: 0.7263 - val_acc: 0.4906\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6119 - acc: 0.7037 - val_loss: 0.7632 - val_acc: 0.5375\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5825 - acc: 0.7377 - val_loss: 0.7632 - val_acc: 0.5344\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5563 - acc: 0.7566 - val_loss: 0.7724 - val_acc: 0.5594\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5223 - acc: 0.7874 - val_loss: 0.8408 - val_acc: 0.5219\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5037 - acc: 0.8067 - val_loss: 0.9610 - val_acc: 0.5063\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4887 - acc: 0.8187 - val_loss: 0.8600 - val_acc: 0.5031\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4498 - acc: 0.8426 - val_loss: 0.9551 - val_acc: 0.5125\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4454 - acc: 0.8438 - val_loss: 0.9750 - val_acc: 0.5031\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4176 - acc: 0.8696 - val_loss: 1.0443 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4026 - acc: 0.8723 - val_loss: 1.0398 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3916 - acc: 0.8785 - val_loss: 1.1299 - val_acc: 0.4906\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3753 - acc: 0.8904 - val_loss: 1.0213 - val_acc: 0.5469\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3633 - acc: 0.8966 - val_loss: 1.1083 - val_acc: 0.5188\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9817 - acc: 0.5781\n",
      "Test eval is  [0.9817202687263489, 0.578125]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:05:54.744275: Finished Train Fold #149/500 - thus far subj acc is 0.44697986577181203 and regular acc is0.45765520122227255\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #150\n",
      "A1 :  2022-04-07 23:06:13.736811\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7981 - acc: 0.5328 - val_loss: 0.7784 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7416 - acc: 0.5409 - val_loss: 0.7470 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7069 - acc: 0.5448 - val_loss: 0.7311 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6847 - acc: 0.5590 - val_loss: 0.7153 - val_acc: 0.3875\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6700 - acc: 0.5945 - val_loss: 0.7260 - val_acc: 0.4469\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6504 - acc: 0.6335 - val_loss: 0.7329 - val_acc: 0.4781\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6203 - acc: 0.6721 - val_loss: 0.7409 - val_acc: 0.5437\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5943 - acc: 0.7195 - val_loss: 0.7645 - val_acc: 0.5688\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.5588 - acc: 0.7407 - val_loss: 0.9396 - val_acc: 0.4938\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5248 - acc: 0.7689 - val_loss: 0.8282 - val_acc: 0.5656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5073 - acc: 0.7863 - val_loss: 0.9273 - val_acc: 0.5188\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4625 - acc: 0.8252 - val_loss: 0.9002 - val_acc: 0.5437\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4459 - acc: 0.8341 - val_loss: 0.9367 - val_acc: 0.5344\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4244 - acc: 0.8445 - val_loss: 1.0254 - val_acc: 0.5813\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4103 - acc: 0.8580 - val_loss: 1.1224 - val_acc: 0.5250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3727 - acc: 0.8762 - val_loss: 1.0579 - val_acc: 0.5844\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3811 - acc: 0.8769 - val_loss: 1.0824 - val_acc: 0.5719\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3556 - acc: 0.8912 - val_loss: 1.1793 - val_acc: 0.5344\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3289 - acc: 0.9120 - val_loss: 1.1984 - val_acc: 0.5406\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3229 - acc: 0.9059 - val_loss: 1.2268 - val_acc: 0.5562\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8115 - acc: 0.4875\n",
      "Test eval is  [0.8114627599716187, 0.48750001192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:06:26.783064: Finished Train Fold #150/500 - thus far subj acc is 0.44933333333333325 and regular acc is0.45845833321412405\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #151\n",
      "A1 :  2022-04-07 23:06:47.238406\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7863 - acc: 0.5583 - val_loss: 0.7623 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7333 - acc: 0.5721 - val_loss: 0.7354 - val_acc: 0.4875\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7008 - acc: 0.5799 - val_loss: 0.7486 - val_acc: 0.4688\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6799 - acc: 0.6026 - val_loss: 0.7513 - val_acc: 0.4625\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6599 - acc: 0.6161 - val_loss: 0.7671 - val_acc: 0.4500\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6382 - acc: 0.6547 - val_loss: 0.8358 - val_acc: 0.4219\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6108 - acc: 0.6991 - val_loss: 0.8592 - val_acc: 0.4625\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5813 - acc: 0.7188 - val_loss: 0.8360 - val_acc: 0.4906\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5463 - acc: 0.7504 - val_loss: 0.8994 - val_acc: 0.5562\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5084 - acc: 0.7870 - val_loss: 0.9363 - val_acc: 0.5063\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4864 - acc: 0.8032 - val_loss: 0.9254 - val_acc: 0.5531\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4559 - acc: 0.8283 - val_loss: 0.9899 - val_acc: 0.5562\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4353 - acc: 0.8414 - val_loss: 1.0450 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3977 - acc: 0.8642 - val_loss: 1.0939 - val_acc: 0.5437\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3837 - acc: 0.8731 - val_loss: 1.1384 - val_acc: 0.4938\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3569 - acc: 0.8904 - val_loss: 1.1165 - val_acc: 0.5750\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3435 - acc: 0.8916 - val_loss: 1.2418 - val_acc: 0.5437\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3313 - acc: 0.9086 - val_loss: 1.2756 - val_acc: 0.5188\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7802 - acc: 0.2094\n",
      "Test eval is  [0.7801753282546997, 0.20937499403953552]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:06:57.535546: Finished Train Fold #151/500 - thus far subj acc is 0.4496688741721854 and regular acc is0.45865066221218237\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #152\n",
      "A1 :  2022-04-07 23:07:16.611295\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7908 - acc: 0.5147 - val_loss: 0.7623 - val_acc: 0.4969\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7410 - acc: 0.5598 - val_loss: 0.7311 - val_acc: 0.4812\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7099 - acc: 0.5899 - val_loss: 0.7250 - val_acc: 0.4844\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6837 - acc: 0.6019 - val_loss: 0.7342 - val_acc: 0.4750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6602 - acc: 0.6354 - val_loss: 0.7579 - val_acc: 0.5437\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6324 - acc: 0.6640 - val_loss: 0.7642 - val_acc: 0.5469\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6029 - acc: 0.6995 - val_loss: 0.8465 - val_acc: 0.5406\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5671 - acc: 0.7276 - val_loss: 0.9207 - val_acc: 0.5344\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5314 - acc: 0.7681 - val_loss: 0.9150 - val_acc: 0.5125\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.5013 - acc: 0.7870 - val_loss: 1.0002 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4553 - acc: 0.8264 - val_loss: 1.1495 - val_acc: 0.5344\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4371 - acc: 0.8299 - val_loss: 1.0832 - val_acc: 0.5281\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4260 - acc: 0.8445 - val_loss: 1.1684 - val_acc: 0.5281\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3902 - acc: 0.8665 - val_loss: 1.2310 - val_acc: 0.5000\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3705 - acc: 0.8677 - val_loss: 1.2802 - val_acc: 0.5125\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3607 - acc: 0.8893 - val_loss: 1.1645 - val_acc: 0.4938\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3333 - acc: 0.8939 - val_loss: 1.2421 - val_acc: 0.4875\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3216 - acc: 0.9028 - val_loss: 1.2684 - val_acc: 0.5594\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3116 - acc: 0.9101 - val_loss: 1.4737 - val_acc: 0.5188\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7235 - acc: 0.3844\n",
      "Test eval is  [0.7235258221626282, 0.3843750059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:07:27.312258: Finished Train Fold #152/500 - thus far subj acc is 0.44802631578947366 and regular acc is0.4570106907110465\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #153\n",
      "A1 :  2022-04-07 23:07:46.407227\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7856 - acc: 0.5355 - val_loss: 0.7620 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7328 - acc: 0.5598 - val_loss: 0.7412 - val_acc: 0.4563\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6982 - acc: 0.5752 - val_loss: 0.7352 - val_acc: 0.4875\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6774 - acc: 0.5999 - val_loss: 0.7970 - val_acc: 0.4156\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6498 - acc: 0.6215 - val_loss: 0.8147 - val_acc: 0.4375\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6281 - acc: 0.6597 - val_loss: 0.8436 - val_acc: 0.5031\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6012 - acc: 0.6898 - val_loss: 0.7751 - val_acc: 0.4969\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5771 - acc: 0.7033 - val_loss: 0.8418 - val_acc: 0.4969\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5481 - acc: 0.7396 - val_loss: 0.8872 - val_acc: 0.4875\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5174 - acc: 0.7562 - val_loss: 0.8845 - val_acc: 0.5312\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5007 - acc: 0.7716 - val_loss: 1.0122 - val_acc: 0.4563\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4738 - acc: 0.8013 - val_loss: 1.0169 - val_acc: 0.4563\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4368 - acc: 0.8167 - val_loss: 1.0947 - val_acc: 0.5031\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4159 - acc: 0.8302 - val_loss: 0.9818 - val_acc: 0.5031\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3914 - acc: 0.8596 - val_loss: 1.1717 - val_acc: 0.4844\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3711 - acc: 0.8654 - val_loss: 1.1901 - val_acc: 0.5219\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3596 - acc: 0.8711 - val_loss: 1.1838 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3472 - acc: 0.8808 - val_loss: 1.3265 - val_acc: 0.5031\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3455 - acc: 0.8881 - val_loss: 1.3776 - val_acc: 0.4688\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7581 - acc: 0.3906\n",
      "Test eval is  [0.7580605745315552, 0.390625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:07:57.340560: Finished Train Fold #153/500 - thus far subj acc is 0.44901960784313716 and regular acc is0.456535947673461\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #154\n",
      "A1 :  2022-04-07 23:08:16.406106\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7933 - acc: 0.5509 - val_loss: 0.7687 - val_acc: 0.4875\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7389 - acc: 0.5594 - val_loss: 0.7383 - val_acc: 0.4938\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7047 - acc: 0.5864 - val_loss: 0.7357 - val_acc: 0.5125\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.6238 - val_loss: 0.7154 - val_acc: 0.5562\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6455 - acc: 0.6620 - val_loss: 0.7338 - val_acc: 0.5562\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6039 - acc: 0.7052 - val_loss: 0.7337 - val_acc: 0.5938\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5747 - acc: 0.7407 - val_loss: 0.8036 - val_acc: 0.5844\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5366 - acc: 0.7697 - val_loss: 0.8337 - val_acc: 0.5562\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4790 - acc: 0.8029 - val_loss: 0.8317 - val_acc: 0.5906\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4651 - acc: 0.8214 - val_loss: 0.8832 - val_acc: 0.5938\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4384 - acc: 0.8418 - val_loss: 0.9885 - val_acc: 0.5719\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4053 - acc: 0.8573 - val_loss: 1.0556 - val_acc: 0.5844\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3900 - acc: 0.8785 - val_loss: 1.0167 - val_acc: 0.5938\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3677 - acc: 0.8835 - val_loss: 0.9606 - val_acc: 0.5938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3617 - acc: 0.8862 - val_loss: 1.0012 - val_acc: 0.6250\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3220 - acc: 0.8935 - val_loss: 1.0577 - val_acc: 0.6094\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3143 - acc: 0.9059 - val_loss: 1.1001 - val_acc: 0.5813\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3207 - acc: 0.9070 - val_loss: 1.1336 - val_acc: 0.5719\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2818 - acc: 0.9240 - val_loss: 1.1756 - val_acc: 0.5844\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2903 - acc: 0.9259 - val_loss: 1.1773 - val_acc: 0.6000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8288 - acc: 0.3156\n",
      "Test eval is  [0.8288164138793945, 0.31562501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:08:27.527014: Finished Train Fold #154/500 - thus far subj acc is 0.44870129870129866 and regular acc is0.45610795450675023\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #155\n",
      "A1 :  2022-04-07 23:08:46.560085\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7894 - acc: 0.5336 - val_loss: 0.7626 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7387 - acc: 0.5309 - val_loss: 0.7292 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7096 - acc: 0.5529 - val_loss: 0.7193 - val_acc: 0.4656\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6878 - acc: 0.5922 - val_loss: 0.7145 - val_acc: 0.4844\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6622 - acc: 0.6184 - val_loss: 0.7287 - val_acc: 0.5031\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6340 - acc: 0.6481 - val_loss: 0.7523 - val_acc: 0.5344\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6027 - acc: 0.6748 - val_loss: 0.7352 - val_acc: 0.5594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5641 - acc: 0.7342 - val_loss: 0.7804 - val_acc: 0.5406\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5297 - acc: 0.7716 - val_loss: 0.8201 - val_acc: 0.5312\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4976 - acc: 0.8017 - val_loss: 0.9323 - val_acc: 0.5250\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4756 - acc: 0.8198 - val_loss: 0.9680 - val_acc: 0.4781\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4488 - acc: 0.8445 - val_loss: 0.9412 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4054 - acc: 0.8738 - val_loss: 1.0421 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3766 - acc: 0.8850 - val_loss: 1.0516 - val_acc: 0.5281\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3654 - acc: 0.8927 - val_loss: 1.1262 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3390 - acc: 0.9039 - val_loss: 1.1384 - val_acc: 0.5406\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3391 - acc: 0.9012 - val_loss: 1.0871 - val_acc: 0.5719\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3103 - acc: 0.9225 - val_loss: 1.1834 - val_acc: 0.5312\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2951 - acc: 0.9336 - val_loss: 1.2869 - val_acc: 0.5281\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2941 - acc: 0.9259 - val_loss: 1.2899 - val_acc: 0.5406\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7108 - acc: 0.5156\n",
      "Test eval is  [0.7107876539230347, 0.515625]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:08:57.627066: Finished Train Fold #155/500 - thus far subj acc is 0.4464516129032257 and regular acc is0.45520161294168043\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #156\n",
      "A1 :  2022-04-07 23:09:16.689351\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7966 - acc: 0.5193 - val_loss: 0.7673 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7428 - acc: 0.5505 - val_loss: 0.7411 - val_acc: 0.4656\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7085 - acc: 0.5849 - val_loss: 0.7992 - val_acc: 0.4125\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6712 - acc: 0.6235 - val_loss: 1.0930 - val_acc: 0.4875\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6460 - acc: 0.6578 - val_loss: 0.9441 - val_acc: 0.4469\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6178 - acc: 0.6883 - val_loss: 0.9531 - val_acc: 0.4375\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5830 - acc: 0.7168 - val_loss: 1.0027 - val_acc: 0.4313\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5504 - acc: 0.7346 - val_loss: 1.1043 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5240 - acc: 0.7797 - val_loss: 1.0206 - val_acc: 0.4688\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4825 - acc: 0.8017 - val_loss: 1.2056 - val_acc: 0.4656\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4528 - acc: 0.8341 - val_loss: 1.1230 - val_acc: 0.5094\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4165 - acc: 0.8561 - val_loss: 1.1099 - val_acc: 0.5094\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3775 - acc: 0.8808 - val_loss: 1.2166 - val_acc: 0.4906\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3794 - acc: 0.8835 - val_loss: 1.1856 - val_acc: 0.4938\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3537 - acc: 0.8943 - val_loss: 1.4309 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3298 - acc: 0.9051 - val_loss: 1.3556 - val_acc: 0.4563\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3211 - acc: 0.9136 - val_loss: 1.3161 - val_acc: 0.4969\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3083 - acc: 0.9155 - val_loss: 1.3730 - val_acc: 0.5094\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7434 - acc: 0.4031\n",
      "Test eval is  [0.7433621883392334, 0.40312498807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:09:26.899080: Finished Train Fold #156/500 - thus far subj acc is 0.4467948717948717 and regular acc is0.4555889423459004\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #157\n",
      "A1 :  2022-04-07 23:09:45.987878\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 9ms/step - loss: 0.7963 - acc: 0.5293 - val_loss: 0.7728 - val_acc: 0.3406\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7422 - acc: 0.5529 - val_loss: 0.7575 - val_acc: 0.3562\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.7078 - acc: 0.5760 - val_loss: 0.7703 - val_acc: 0.3438\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6865 - acc: 0.5910 - val_loss: 0.8020 - val_acc: 0.3656\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6669 - acc: 0.6215 - val_loss: 0.8406 - val_acc: 0.3812\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6517 - acc: 0.6265 - val_loss: 0.8230 - val_acc: 0.4094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6363 - acc: 0.6501 - val_loss: 0.8843 - val_acc: 0.4375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.6171 - acc: 0.6713 - val_loss: 0.8459 - val_acc: 0.4625\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5955 - acc: 0.6991 - val_loss: 0.8778 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5722 - acc: 0.7330 - val_loss: 0.8671 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5457 - acc: 0.7450 - val_loss: 0.8865 - val_acc: 0.5281\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5130 - acc: 0.7797 - val_loss: 0.9626 - val_acc: 0.5219\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4850 - acc: 0.8079 - val_loss: 0.9551 - val_acc: 0.5469\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4628 - acc: 0.8248 - val_loss: 0.9876 - val_acc: 0.5031\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4455 - acc: 0.8364 - val_loss: 0.9349 - val_acc: 0.5688\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.4158 - acc: 0.8492 - val_loss: 1.2216 - val_acc: 0.5437\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3918 - acc: 0.8681 - val_loss: 1.1245 - val_acc: 0.5844\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.3749 - acc: 0.8750 - val_loss: 1.1448 - val_acc: 0.5813\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7360 - acc: 0.5719\n",
      "Test eval is  [0.7359951734542847, 0.5718749761581421]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:09:56.298627: Finished Train Fold #157/500 - thus far subj acc is 0.44649681528662416 and regular acc is0.45525477703209893\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #158\n",
      "A1 :  2022-04-07 23:10:15.917373\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7840 - acc: 0.5228 - val_loss: 0.7577 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7348 - acc: 0.5436 - val_loss: 0.7282 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7063 - acc: 0.5440 - val_loss: 0.7227 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6831 - acc: 0.5783 - val_loss: 0.7120 - val_acc: 0.5156\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6565 - acc: 0.6154 - val_loss: 0.7204 - val_acc: 0.5125\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6306 - acc: 0.6501 - val_loss: 0.7206 - val_acc: 0.5656\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6015 - acc: 0.6875 - val_loss: 0.8036 - val_acc: 0.5375\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5697 - acc: 0.7172 - val_loss: 0.8030 - val_acc: 0.5625\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5314 - acc: 0.7562 - val_loss: 0.9553 - val_acc: 0.5094\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5153 - acc: 0.7743 - val_loss: 0.8920 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4713 - acc: 0.8021 - val_loss: 0.9129 - val_acc: 0.5531\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4459 - acc: 0.8140 - val_loss: 1.0556 - val_acc: 0.4938\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4365 - acc: 0.8268 - val_loss: 0.9948 - val_acc: 0.5156\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3916 - acc: 0.8681 - val_loss: 0.9871 - val_acc: 0.5625\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4023 - acc: 0.8607 - val_loss: 1.2868 - val_acc: 0.4688\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3528 - acc: 0.8981 - val_loss: 1.1367 - val_acc: 0.5375\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3381 - acc: 0.9039 - val_loss: 1.1789 - val_acc: 0.5500\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3225 - acc: 0.9117 - val_loss: 1.2239 - val_acc: 0.5125\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3189 - acc: 0.9178 - val_loss: 1.2149 - val_acc: 0.5375\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2980 - acc: 0.9309 - val_loss: 1.1674 - val_acc: 0.5375\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7409 - acc: 0.3875\n",
      "Test eval is  [0.7408952116966248, 0.38749998807907104]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:10:29.458685: Finished Train Fold #158/500 - thus far subj acc is 0.4468354430379746 and regular acc is0.45599287955821316\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #159\n",
      "A1 :  2022-04-07 23:10:54.365802\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7808 - acc: 0.5363 - val_loss: 0.7530 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7317 - acc: 0.5436 - val_loss: 0.7233 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.7078 - acc: 0.5536 - val_loss: 0.7064 - val_acc: 0.5125\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6908 - acc: 0.5752 - val_loss: 0.7051 - val_acc: 0.5094\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6772 - acc: 0.5864 - val_loss: 0.7175 - val_acc: 0.4812\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6569 - acc: 0.6119 - val_loss: 0.6989 - val_acc: 0.5406\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6383 - acc: 0.6466 - val_loss: 0.7412 - val_acc: 0.5156\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6044 - acc: 0.6863 - val_loss: 0.7889 - val_acc: 0.5125\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5846 - acc: 0.7083 - val_loss: 0.7838 - val_acc: 0.5063\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5502 - acc: 0.7450 - val_loss: 0.7979 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5148 - acc: 0.7832 - val_loss: 0.9361 - val_acc: 0.4625\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4714 - acc: 0.8029 - val_loss: 1.0159 - val_acc: 0.4844\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4493 - acc: 0.8291 - val_loss: 0.9256 - val_acc: 0.5188\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.4279 - acc: 0.8492 - val_loss: 1.0930 - val_acc: 0.4594\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3708 - acc: 0.8785 - val_loss: 1.2075 - val_acc: 0.4656\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3531 - acc: 0.8843 - val_loss: 1.2915 - val_acc: 0.4781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3421 - acc: 0.8947 - val_loss: 1.3249 - val_acc: 0.4812\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3241 - acc: 0.9035 - val_loss: 1.3824 - val_acc: 0.5094\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3025 - acc: 0.9105 - val_loss: 1.3779 - val_acc: 0.5312\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3024 - acc: 0.9186 - val_loss: 1.3877 - val_acc: 0.5031\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1808 - acc: 0.5344\n",
      "Test eval is  [1.1807764768600464, 0.534375011920929]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:11:08.224312: Finished Train Fold #159/500 - thus far subj acc is 0.44591194968553455 and regular acc is0.4555621066558286\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #160\n",
      "A1 :  2022-04-07 23:11:32.244475\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.8065 - acc: 0.5289 - val_loss: 0.7745 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7471 - acc: 0.5590 - val_loss: 0.7424 - val_acc: 0.4812\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7085 - acc: 0.5741 - val_loss: 0.7803 - val_acc: 0.4594\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6815 - acc: 0.6127 - val_loss: 0.7509 - val_acc: 0.4750\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6525 - acc: 0.6489 - val_loss: 0.8487 - val_acc: 0.4625\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6232 - acc: 0.6844 - val_loss: 0.7808 - val_acc: 0.4563\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5932 - acc: 0.7029 - val_loss: 0.8830 - val_acc: 0.4594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5592 - acc: 0.7431 - val_loss: 0.8836 - val_acc: 0.4656\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5232 - acc: 0.7685 - val_loss: 0.9289 - val_acc: 0.4625\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4963 - acc: 0.7994 - val_loss: 1.0274 - val_acc: 0.4906\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.4707 - acc: 0.8164 - val_loss: 1.0993 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4425 - acc: 0.8387 - val_loss: 1.0948 - val_acc: 0.4625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4270 - acc: 0.8522 - val_loss: 1.2023 - val_acc: 0.4625\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3987 - acc: 0.8669 - val_loss: 1.1212 - val_acc: 0.4719\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 0.3930 - acc: 0.8723 - val_loss: 1.2629 - val_acc: 0.4563\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3512 - acc: 0.8947 - val_loss: 1.2621 - val_acc: 0.4781\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3426 - acc: 0.8978 - val_loss: 1.4601 - val_acc: 0.4625\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3386 - acc: 0.8985 - val_loss: 1.4360 - val_acc: 0.4375\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7571 - acc: 0.4094\n",
      "Test eval is  [0.7571440935134888, 0.40937501192092896]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:11:44.297150: Finished Train Fold #160/500 - thus far subj acc is 0.446875 and regular acc is0.4560546873137355\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #161\n",
      "A1 :  2022-04-07 23:12:07.979394\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7896 - acc: 0.5216 - val_loss: 0.7600 - val_acc: 0.5063\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7390 - acc: 0.5332 - val_loss: 0.7268 - val_acc: 0.5031\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7118 - acc: 0.5617 - val_loss: 0.7183 - val_acc: 0.4781\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6933 - acc: 0.5741 - val_loss: 0.7133 - val_acc: 0.4469\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6822 - acc: 0.5926 - val_loss: 0.7271 - val_acc: 0.4719\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6728 - acc: 0.5949 - val_loss: 0.7590 - val_acc: 0.4531\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6625 - acc: 0.6192 - val_loss: 0.7620 - val_acc: 0.4625\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6496 - acc: 0.6285 - val_loss: 0.8207 - val_acc: 0.4656\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6365 - acc: 0.6485 - val_loss: 0.8223 - val_acc: 0.4844\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6280 - acc: 0.6721 - val_loss: 0.8447 - val_acc: 0.4781\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6071 - acc: 0.6929 - val_loss: 0.9035 - val_acc: 0.5156\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5881 - acc: 0.7137 - val_loss: 0.8568 - val_acc: 0.4625\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5640 - acc: 0.7346 - val_loss: 0.8721 - val_acc: 0.5063\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5459 - acc: 0.7469 - val_loss: 0.9967 - val_acc: 0.4719\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5319 - acc: 0.7689 - val_loss: 0.9521 - val_acc: 0.4812\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4965 - acc: 0.7955 - val_loss: 1.1184 - val_acc: 0.4875\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4740 - acc: 0.8175 - val_loss: 1.2144 - val_acc: 0.4688\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4583 - acc: 0.8167 - val_loss: 1.0761 - val_acc: 0.4844\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4503 - acc: 0.8329 - val_loss: 1.1052 - val_acc: 0.4719\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4112 - acc: 0.8600 - val_loss: 1.2616 - val_acc: 0.4719\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7030 - acc: 0.4938\n",
      "Test eval is  [0.7030240297317505, 0.4937500059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:12:21.325633: Finished Train Fold #161/500 - thus far subj acc is 0.44658385093167696 and regular acc is0.45576475144173045\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #162\n",
      "A1 :  2022-04-07 23:12:45.317164\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7883 - acc: 0.5374 - val_loss: 0.7643 - val_acc: 0.4000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7403 - acc: 0.5340 - val_loss: 0.7349 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7148 - acc: 0.5517 - val_loss: 0.7190 - val_acc: 0.4219\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6912 - acc: 0.5822 - val_loss: 0.7452 - val_acc: 0.3812\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6721 - acc: 0.6030 - val_loss: 0.7639 - val_acc: 0.3812\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6530 - acc: 0.6235 - val_loss: 0.7691 - val_acc: 0.4094\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6325 - acc: 0.6543 - val_loss: 0.8740 - val_acc: 0.3594\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6038 - acc: 0.6794 - val_loss: 0.8278 - val_acc: 0.4187\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5717 - acc: 0.7222 - val_loss: 0.9568 - val_acc: 0.4406\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5305 - acc: 0.7589 - val_loss: 0.9063 - val_acc: 0.4938\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5136 - acc: 0.7650 - val_loss: 1.0781 - val_acc: 0.4437\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4850 - acc: 0.7959 - val_loss: 1.1718 - val_acc: 0.4688\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4568 - acc: 0.8179 - val_loss: 1.2496 - val_acc: 0.4656\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4326 - acc: 0.8218 - val_loss: 1.2513 - val_acc: 0.4719\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4043 - acc: 0.8522 - val_loss: 1.1074 - val_acc: 0.4906\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3827 - acc: 0.8650 - val_loss: 1.2237 - val_acc: 0.4594\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3662 - acc: 0.8688 - val_loss: 1.1865 - val_acc: 0.4906\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3549 - acc: 0.8812 - val_loss: 1.3990 - val_acc: 0.4656\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3227 - acc: 0.8962 - val_loss: 1.5783 - val_acc: 0.4875\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7188 - acc: 0.5594\n",
      "Test eval is  [0.7188364267349243, 0.559374988079071]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:12:58.320838: Finished Train Fold #162/500 - thus far subj acc is 0.4469135802469135 and regular acc is0.45599922832147577\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #163\n",
      "A1 :  2022-04-07 23:13:21.724800\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 10ms/step - loss: 0.7963 - acc: 0.5475 - val_loss: 0.7710 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7410 - acc: 0.5556 - val_loss: 0.7348 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.7088 - acc: 0.5556 - val_loss: 0.7205 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6877 - acc: 0.5660 - val_loss: 0.7162 - val_acc: 0.4812\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6678 - acc: 0.5814 - val_loss: 0.7090 - val_acc: 0.5188\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6540 - acc: 0.6238 - val_loss: 0.7153 - val_acc: 0.5125\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6290 - acc: 0.6663 - val_loss: 0.7642 - val_acc: 0.5406\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5972 - acc: 0.7110 - val_loss: 0.8309 - val_acc: 0.5031\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5588 - acc: 0.7500 - val_loss: 0.8210 - val_acc: 0.5656\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5176 - acc: 0.7917 - val_loss: 0.8687 - val_acc: 0.5594\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4905 - acc: 0.8198 - val_loss: 1.0182 - val_acc: 0.5531\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4578 - acc: 0.8407 - val_loss: 0.9522 - val_acc: 0.5656\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4330 - acc: 0.8584 - val_loss: 0.9738 - val_acc: 0.5531\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.3942 - acc: 0.8773 - val_loss: 1.0426 - val_acc: 0.5250\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.3927 - acc: 0.8723 - val_loss: 1.1401 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3476 - acc: 0.9047 - val_loss: 1.1974 - val_acc: 0.5594\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3578 - acc: 0.8920 - val_loss: 1.2127 - val_acc: 0.5375\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3277 - acc: 0.9093 - val_loss: 1.1735 - val_acc: 0.5688\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3039 - acc: 0.9232 - val_loss: 1.3138 - val_acc: 0.5375\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.2937 - acc: 0.9259 - val_loss: 1.2517 - val_acc: 0.5656\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8237 - acc: 0.3969\n",
      "Test eval is  [1.8236560821533203, 0.3968749940395355]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:13:35.454409: Finished Train Fold #163/500 - thus far subj acc is 0.44723926380368095 and regular acc is0.456633435436553\n",
      " Randomize Labels = False\n",
      "a\n",
      " Train Fold #164\n",
      "A1 :  2022-04-07 23:13:59.582828\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - 2s 11ms/step - loss: 0.7885 - acc: 0.5285 - val_loss: 0.7607 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7380 - acc: 0.5459 - val_loss: 0.7289 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.7113 - acc: 0.5463 - val_loss: 0.7117 - val_acc: 0.4969\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6884 - acc: 0.5714 - val_loss: 0.7554 - val_acc: 0.4437\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6765 - acc: 0.5930 - val_loss: 0.7798 - val_acc: 0.4156\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6580 - acc: 0.6331 - val_loss: 0.7833 - val_acc: 0.5437\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.6423 - acc: 0.6416 - val_loss: 0.7930 - val_acc: 0.5125\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.6195 - acc: 0.6628 - val_loss: 0.7557 - val_acc: 0.5312\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 0.5969 - acc: 0.6948 - val_loss: 0.8341 - val_acc: 0.5063\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5703 - acc: 0.7245 - val_loss: 0.8624 - val_acc: 0.5281\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.5401 - acc: 0.7434 - val_loss: 0.9262 - val_acc: 0.5125\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.5188 - acc: 0.7600 - val_loss: 0.9349 - val_acc: 0.5312\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4955 - acc: 0.7882 - val_loss: 0.9409 - val_acc: 0.5344\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 0.4638 - acc: 0.8206 - val_loss: 0.9830 - val_acc: 0.5469\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4288 - acc: 0.8403 - val_loss: 1.0525 - val_acc: 0.4906\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.4340 - acc: 0.8345 - val_loss: 1.0254 - val_acc: 0.5250\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3938 - acc: 0.8627 - val_loss: 1.1635 - val_acc: 0.5219\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3682 - acc: 0.8812 - val_loss: 1.3113 - val_acc: 0.5219\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 0.3682 - acc: 0.8769 - val_loss: 1.1472 - val_acc: 0.5250\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7342 - acc: 0.4000\n",
      "Test eval is  [0.7341930866241455, 0.4000000059604645]\n",
      "Shape of pred is  (320, 1)\n",
      "Shape of per_subject_mean_pred (10,)\n",
      "2022-04-07 23:14:12.846857: Finished Train Fold #164/500 - thus far subj acc is 0.4451219512195122 and regular acc is0.4562690546963273\n",
      " Randomize Labels = False\n",
      "a\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/39/88clnp910zlg54lrgy0d7qm40000gn/T/ipykernel_1746/211339046.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel_res_dict_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/39/88clnp910zlg54lrgy0d7qm40000gn/T/ipykernel_1746/3375296032.py\u001B[0m in \u001B[0;36mrun_model\u001B[0;34m(df, randomize_labels)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0;31m# val_df = tmp_df.iloc[val_index]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;31m# break\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m         \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerate_3d_ds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m         \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerate_3d_ds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0mX_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerate_3d_ds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/39/88clnp910zlg54lrgy0d7qm40000gn/T/ipykernel_1746/3323902908.py\u001B[0m in \u001B[0;36mgenerate_3d_ds\u001B[0;34m(df, feats)\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0ml\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mcol\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfeats\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m             \u001B[0ml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoded_cond'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0mdata_3d\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"phq_binary_label\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/PhD/Aim1/Aim1/venv/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    940\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    941\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mkey_is_scalar\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 942\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    943\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    944\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_hashable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/PhD/Aim1/Aim1/venv/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36m_get_value\u001B[0;34m(self, label, takeable)\u001B[0m\n\u001B[1;32m   1050\u001B[0m         \u001B[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1051\u001B[0m         \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1052\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_values_for_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1053\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1054\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__setitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/PhD/Aim1/Aim1/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m_get_values_for_loc\u001B[0;34m(self, series, loc, key)\u001B[0m\n\u001B[1;32m   5182\u001B[0m         \"\"\"\n\u001B[1;32m   5183\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5184\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mseries\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5185\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5186\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mseries\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/PhD/Aim1/Aim1/venv/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36m_values\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexternal_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 674\u001B[0;31m     \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    675\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    676\u001B[0m         \"\"\"\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_res_dict_new = run_model(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45234375132620336\n",
      "0.4528\n",
      "Saved to  /Users/orenkobo/Desktop/PhD/Aim1/Aim1/OutputsAnalyser/ZZZ_notebooks/Notebooks __For_Paper/Trained_models/LSTM_cond_embed_output_object_1649356410.032912\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "out_dir = \"/Users/orenkobo/Desktop/PhD/Aim1/Aim1/OutputsAnalyser/ZZZ_notebooks/Notebooks __For_Paper/Trained_models/\"\n",
    "ts = datetime.datetime.timestamp(datetime.datetime.now())\n",
    "\n",
    "out_fn = f\"{out_dir}LSTM_cond_embed_output_object_{ts}\"\n",
    "print(np.mean([random_model_res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([random_model_res_dict[i]['subj_level_acc'] for i in range(num_iters)]))\n",
    "\n",
    "random_dict_to_save = {\"res_dict\" : random_model_res_dict, f\"details\" : f\"LSTM + cond embed, {num_iters} iters, \"\n",
    "                                                                 f\"{100-2*n_test_subjs}/{n_test_subjs}/{n_test_subjs} split\"}\n",
    "joblib.dump(random_dict_to_save, out_fn + \"_RANDOM_FINAL.jbl\")\n",
    "print(\"Saved to \", out_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_res_dict = run_model(df, randomize_labels = False)\n",
    "print(np.mean([model_res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([model_res_dict[i]['subj_level_acc'] for i in range(num_iters)]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-05 21:07:09.097180\n",
      "10 subjects : \n",
      "0.5169312510490417\n",
      "0.6327999999999999\n",
      "0.5183187496662139\n",
      "0.679\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "print(f\"{n_test_subjs} subjects : \")\n",
    "print(np.mean([model_res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([model_res_dict[i]['subj_level_acc'] for i in range(num_iters)]))\n",
    "\n",
    "print(np.mean([random_model_res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([random_model_res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#This is around 10 mins local CPU time\n",
    "# tf.keras.utils.plot_model(fold_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "['/Users/orenkobo/Desktop/PhD/Aim1/Aim1/OutputsAnalyser/ZZZ_notebooks/Notebooks __For_Paper/Trained_models/LSTM_cond_embed_output_object_1649259787.042902_RANDOM_.jbl']"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# out_dir = \"/export/home/orenkobo/Aim1/paper_analysis/Trained_models/\"\n",
    "out_dir = \"/Users/orenkobo/Desktop/PhD/Aim1/Aim1/OutputsAnalyser/ZZZ_notebooks/Notebooks __For_Paper/Trained_models/\"\n",
    "ts = datetime.timestamp(datetime.now())\n",
    "\n",
    "out_fn = f\"{out_dir}LSTM_cond_embed_output_object_{ts}\"\n",
    "model_dict_to_save = {\"res_dict\" : model_res_dict, f\"details\" : f\"LSTM + cond embed, {num_iters} iters, \"\n",
    "                                                                                  f\"{100-2*n_test_subjs}/{n_test_subjs}/{n_test_subjs} split\"}\n",
    "\n",
    "random_dict_to_save = {\"res_dict\" : model_res_dict, f\"details\" : f\"LSTM + cond embed, {num_iters} iters, \"\n",
    "                                                                f\"{100-2*n_test_subjs}/{n_test_subjs}/{n_test_subjs} split\"}\n",
    "joblib.dump(model_dict_to_save, out_fn + \".jbl\")\n",
    "joblib.dump(random_dict_to_save, out_fn + \"_RANDOM_.jbl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subjects : \n",
      "0.5257812511175871\n",
      "0.5910000000000001\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.LineCollection at 0x7f96c7e27880>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot([model_res_dict[i]['subj_level_acc'] for i in range(num_iters)])\n",
    "plt.hlines(y= 0.5, xmin=-0.5, xmax=2.5, color='r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "accs_l = [res_dict[i]['subj_level_acc'] for i in range(num_iters)]\n",
    "iter_idx = np.argmax(accs_l)\n",
    "max_acc = accs_l[iter_idx]\n",
    "max_entry = res_dict[iter_idx]\n",
    "me_pred = max_entry['test_pred']\n",
    "me_true = max_entry['test_true']\n",
    "# pr_curve ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6, 0.5, 0.3, 0.5, 0.2, 0.5, 0.5, 0.4, 0.5, 0.4, 0.2, 0.4, 0.6, 0.5, 0.4]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'eval': 0.565625011920929,\n 'test_subjects': [42, 46, 71, 72, 77, 87, 112, 113, 115, 118],\n 'test_pred': [0.48230875,\n  0.48124906,\n  0.4820729,\n  0.4774221,\n  0.4886419,\n  0.49888575,\n  0.4848336,\n  0.48713756,\n  0.5021649,\n  0.49008733,\n  0.48217878,\n  0.48918596,\n  0.4774221,\n  0.49001223,\n  0.49471372,\n  0.4763323,\n  0.48249832,\n  0.4937589,\n  0.49548006,\n  0.4894247,\n  0.48209438,\n  0.48737174,\n  0.48167762,\n  0.4811987,\n  0.4939257,\n  0.50071406,\n  0.48660085,\n  0.5049589,\n  0.48219803,\n  0.48782516,\n  0.5036337,\n  0.49095315,\n  0.475376,\n  0.48002985,\n  0.4829871,\n  0.4935801,\n  0.4958365,\n  0.49074212,\n  0.4758829,\n  0.5036206,\n  0.49155834,\n  0.477399,\n  0.48827544,\n  0.48351577,\n  0.483939,\n  0.48498943,\n  0.48361513,\n  0.49613386,\n  0.48224726,\n  0.4795423,\n  0.47612494,\n  0.4733184,\n  0.47716707,\n  0.48361415,\n  0.4815199,\n  0.4815635,\n  0.49106902,\n  0.4732568,\n  0.49880135,\n  0.48180696,\n  0.4776491,\n  0.4795455,\n  0.49229872,\n  0.4784392,\n  0.4732043,\n  0.47201592,\n  0.488331,\n  0.5054103,\n  0.48875058,\n  0.49342012,\n  0.48596498,\n  0.47788778,\n  0.50257945,\n  0.4844146,\n  0.48497453,\n  0.48466265,\n  0.49854633,\n  0.48571402,\n  0.50100857,\n  0.48480546,\n  0.5034465,\n  0.48627958,\n  0.48273125,\n  0.48367602,\n  0.48668393,\n  0.4849492,\n  0.49858028,\n  0.49764863,\n  0.50031894,\n  0.48499683,\n  0.48583853,\n  0.48586506,\n  0.49802616,\n  0.51021683,\n  0.506544,\n  0.48498672,\n  0.48632842,\n  0.4901346,\n  0.4922105,\n  0.48570123,\n  0.4889403,\n  0.51075506,\n  0.49294257,\n  0.49466628,\n  0.47707176,\n  0.5050449,\n  0.49412766,\n  0.4997727,\n  0.4833842,\n  0.47357237,\n  0.48794803,\n  0.4769453,\n  0.48784947,\n  0.49354607,\n  0.4860317,\n  0.48999557,\n  0.50496465,\n  0.47707176,\n  0.51039827,\n  0.48876607,\n  0.47633934,\n  0.51262,\n  0.50157607,\n  0.48722553,\n  0.48873404,\n  0.5081606,\n  0.49265882,\n  0.49773145,\n  0.5074755,\n  0.48705676,\n  0.4928708,\n  0.48458388,\n  0.49593765,\n  0.4852991,\n  0.4840878,\n  0.4798686,\n  0.48193014,\n  0.47656193,\n  0.4901395,\n  0.48273972,\n  0.4773846,\n  0.4776046,\n  0.47000748,\n  0.47820878,\n  0.4765949,\n  0.4848379,\n  0.48147595,\n  0.479517,\n  0.4823241,\n  0.48014754,\n  0.4901395,\n  0.48339653,\n  0.46988952,\n  0.47798985,\n  0.4805526,\n  0.47899508,\n  0.48057908,\n  0.48059916,\n  0.47894222,\n  0.4747141,\n  0.47876516,\n  0.48678118,\n  0.49053946,\n  0.492726,\n  0.48204553,\n  0.49063677,\n  0.48845828,\n  0.48137882,\n  0.48106498,\n  0.4802593,\n  0.48750234,\n  0.47328314,\n  0.48368615,\n  0.5136601,\n  0.49624917,\n  0.48818445,\n  0.4830051,\n  0.48501885,\n  0.50418675,\n  0.5058413,\n  0.47736257,\n  0.48060971,\n  0.50546455,\n  0.5032695,\n  0.4994911,\n  0.49086496,\n  0.4914956,\n  0.513138,\n  0.5007253,\n  0.48542085,\n  0.48760357,\n  0.47796896,\n  0.484346,\n  0.4906584,\n  0.4984269,\n  0.48407704,\n  0.48384997,\n  0.47964108,\n  0.48688138,\n  0.48052028,\n  0.48981896,\n  0.4673558,\n  0.48474777,\n  0.49405894,\n  0.4763546,\n  0.4964295,\n  0.48181474,\n  0.4897514,\n  0.4876657,\n  0.46610224,\n  0.48384997,\n  0.47968403,\n  0.48739567,\n  0.49815753,\n  0.49281806,\n  0.4871039,\n  0.4824712,\n  0.49604216,\n  0.49177557,\n  0.4906584,\n  0.4984269,\n  0.4950157,\n  0.48688138,\n  0.46707773,\n  0.48230132,\n  0.48718566,\n  0.4658619,\n  0.4703002,\n  0.48603734,\n  0.46511662,\n  0.48942044,\n  0.46811512,\n  0.48250288,\n  0.47304487,\n  0.49304706,\n  0.45881703,\n  0.4703847,\n  0.48016736,\n  0.47975743,\n  0.47827205,\n  0.46438274,\n  0.47225404,\n  0.46997195,\n  0.46979564,\n  0.4808451,\n  0.47766522,\n  0.4685812,\n  0.47304487,\n  0.46610948,\n  0.4790378,\n  0.46892327,\n  0.46342996,\n  0.4898885,\n  0.47746646,\n  0.48213154,\n  0.48442936,\n  0.48258853,\n  0.5005225,\n  0.47824022,\n  0.4784556,\n  0.48897865,\n  0.4864698,\n  0.49900013,\n  0.49283817,\n  0.47982246,\n  0.48762912,\n  0.4959353,\n  0.47825944,\n  0.47570553,\n  0.4890004,\n  0.49026322,\n  0.48980156,\n  0.47864294,\n  0.48707196,\n  0.48130304,\n  0.49695793,\n  0.48431078,\n  0.4937241,\n  0.48670378,\n  0.48374724,\n  0.49318424,\n  0.482395,\n  0.49685052,\n  0.48454776,\n  0.48199615,\n  0.49258235,\n  0.49304911,\n  0.48121968,\n  0.50248754,\n  0.48618567,\n  0.48862606,\n  0.47255588,\n  0.4820713,\n  0.47652918,\n  0.47294265,\n  0.4830223,\n  0.49885306,\n  0.4876536,\n  0.47574827,\n  0.48870766,\n  0.4803148,\n  0.4873088,\n  0.4866209,\n  0.4822581,\n  0.46712577,\n  0.4762179,\n  0.46676537,\n  0.47574827,\n  0.47732982,\n  0.48469472,\n  0.47788352,\n  0.48158747,\n  0.47561225,\n  0.474367,\n  0.4822581,\n  0.479443,\n  0.48339844,\n  0.48069665,\n  0.48300704,\n  0.47295743],\n 'test_true': [0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0],\n 'per_subject_mean_pred': 0    0.488405\n 1    0.484233\n 2    0.490390\n 3    0.491975\n 4    0.482264\n 5    0.490209\n 6    0.486246\n 7    0.475572\n 8    0.487244\n 9    0.480968\n dtype: float32,\n 'per_subject_mean_label': 0    0.0\n 1    0.0\n 2    1.0\n 3    0.0\n 4    0.0\n 5    0.0\n 6    1.0\n 7    0.0\n 8    1.0\n 9    1.0\n dtype: float64,\n 'per_subject_is_success': [True,\n  True,\n  False,\n  True,\n  True,\n  True,\n  False,\n  True,\n  False,\n  False],\n 'subj_level_acc': 0.6}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_entry"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 subjects : \n",
      "0.47236111561457317\n",
      "0.4400000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f\"{n_test_subjs} subjects : \")\n",
    "print(np.mean([res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 subjects : \n",
      "0.47236111561457317\n",
      "0.4400000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f\"{n_test_subjs} subjects : \")\n",
    "print(np.mean([res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47236111561457317\n",
      "0.4400000000000001\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.42000000000000004"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = [res_dict[i]['subj_level_acc'] for i in range(num_iters)]\n",
    "np.mean(accs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(accs).plot.box()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydev_jupyter_utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-68-62abb52f74bc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpydev_jupyter_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mremove_imported_pydev_package\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0mremove_imported_pydev_package\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpydev_jupyter_utils\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pydev_jupyter_utils'"
     ]
    }
   ],
   "source": [
    "my_list = res_dict[0][\"test_pred\"]\n",
    "n=32\n",
    "c = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]\n",
    "# pd.DataFrame(c).mean(axis=1)\n",
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "{'trained_model': <keras.engine.functional.Functional at 0x7f05c3565e50>,\n 'eval': [2.9418864250183105, 0.5062500238418579],\n 'test_subjects': [3, 4, 5, 7, 8, 10, 11, 12, 14, 17],\n 'test_pred': [0.9801324,\n  0.18567377,\n  0.0018174648,\n  0.98344004,\n  0.007769376,\n  0.99987125,\n  0.034465462,\n  0.99916315,\n  1.0,\n  0.007850051,\n  0.9815106,\n  0.0023913085,\n  0.21883637,\n  0.99998915,\n  0.6335065,\n  0.7504558,\n  0.020567805,\n  0.99987125,\n  0.9999963,\n  0.99977696,\n  0.9954214,\n  0.99954927,\n  0.26483133,\n  0.99998915,\n  0.0026150048,\n  0.0004156232,\n  0.71710795,\n  0.045108587,\n  0.061918616,\n  7.490967e-09,\n  0.99999964,\n  0.9920317,\n  0.99999976,\n  0.99999833,\n  0.99928653,\n  0.99998736,\n  0.9987761,\n  0.99719024,\n  0.9999993,\n  0.53705937,\n  0.036192656,\n  0.8326241,\n  0.0036028922,\n  0.5821448,\n  0.00085666776,\n  0.67734444,\n  0.9996289,\n  0.0023396313,\n  0.5051429,\n  0.033452243,\n  0.7457353,\n  0.9498471,\n  0.9971754,\n  0.9999963,\n  0.63609505,\n  0.99969304,\n  0.98896587,\n  0.0006534457,\n  0.9999908,\n  0.5233997,\n  0.968349,\n  0.6054912,\n  0.03691238,\n  0.74573535,\n  0.999701,\n  0.9997564,\n  0.9969161,\n  0.274947,\n  0.0018679798,\n  0.07722896,\n  0.99982905,\n  0.085458905,\n  0.99997795,\n  0.035645455,\n  0.99999285,\n  0.6160025,\n  0.32140398,\n  0.9863262,\n  0.94472545,\n  0.9573395,\n  0.19028708,\n  0.4892574,\n  0.999733,\n  0.07933128,\n  0.99996006,\n  0.14967573,\n  0.10993263,\n  0.0055030286,\n  0.031367898,\n  0.8931748,\n  0.7026036,\n  0.9447391,\n  0.8103008,\n  0.77614844,\n  0.085458994,\n  0.9999822,\n  0.0037069023,\n  0.068009764,\n  0.99973476,\n  0.027101964,\n  1.6471871e-08,\n  0.02696374,\n  4.1846334e-08,\n  0.6309891,\n  0.011080176,\n  0.99947953,\n  0.9999457,\n  0.5983407,\n  2.384456e-11,\n  0.012065589,\n  0.15720925,\n  2.820633e-10,\n  0.989777,\n  0.00085270405,\n  0.9997668,\n  0.9997441,\n  0.0002246201,\n  0.49983642,\n  1.3557671e-05,\n  7.755166e-07,\n  0.9997961,\n  6.2909616e-10,\n  0.9810597,\n  0.9994713,\n  0.0403302,\n  0.9795563,\n  0.9993936,\n  0.83732045,\n  0.5149658,\n  0.9707134,\n  0.9383167,\n  0.3658008,\n  0.9504558,\n  0.1090723,\n  0.74374557,\n  6.0364244e-05,\n  0.9963341,\n  0.9999997,\n  5.869744e-05,\n  0.39029014,\n  0.0124489665,\n  9.301647e-09,\n  0.80719763,\n  0.014493525,\n  0.0021675527,\n  0.071979076,\n  3.384942e-05,\n  0.12851816,\n  8.395677e-06,\n  0.274376,\n  0.0012303293,\n  6.7625434e-09,\n  2.0520141e-09,\n  0.99721456,\n  0.9735439,\n  0.998803,\n  0.07344738,\n  0.999694,\n  0.7221203,\n  0.9355161,\n  0.9759085,\n  0.99979246,\n  0.88360035,\n  0.95419157,\n  0.99976957,\n  0.93853915,\n  0.5346833,\n  0.99771774,\n  0.965706,\n  0.9501334,\n  4.420206e-09,\n  0.119834214,\n  0.9860524,\n  0.9235605,\n  0.052019358,\n  0.9993585,\n  0.7681324,\n  0.11863342,\n  0.99984944,\n  0.16903383,\n  0.9872371,\n  0.2071617,\n  0.978025,\n  0.96972674,\n  0.9235605,\n  0.99965423,\n  0.9995961,\n  0.4871004,\n  0.11551094,\n  0.78877217,\n  0.14360097,\n  0.9586873,\n  0.18107373,\n  1.7445771e-07,\n  0.97127026,\n  0.99321425,\n  0.13028258,\n  0.086019695,\n  1.8830134e-08,\n  0.5134758,\n  0.9999944,\n  0.9244572,\n  0.1892274,\n  0.0229882,\n  0.44906348,\n  0.01527223,\n  0.03086397,\n  0.34538943,\n  0.5142803,\n  0.5011304,\n  0.7173055,\n  0.99832004,\n  0.92420256,\n  0.06060502,\n  2.1625728e-07,\n  0.97127026,\n  0.9964851,\n  0.92918956,\n  0.027336538,\n  0.44894165,\n  0.31738156,\n  0.99995863,\n  0.75981784,\n  0.9999243,\n  0.99999094,\n  0.9960226,\n  0.1108332,\n  0.99978745,\n  0.9932109,\n  0.6522354,\n  0.694059,\n  0.9954833,\n  0.23979908,\n  5.648685e-05,\n  2.7259173e-07,\n  0.83045983,\n  0.72428256,\n  0.30973077,\n  0.31357628,\n  0.9999987,\n  0.002714336,\n  0.10126439,\n  0.9984703,\n  0.14954582,\n  0.7833077,\n  0.08445951,\n  0.11293936,\n  0.99990433,\n  0.048840433,\n  0.00038802624,\n  0.035523772,\n  0.6853896,\n  0.03871125,\n  0.87549144,\n  0.9993501,\n  0.63993317,\n  0.99938244,\n  0.99891615,\n  0.15217388,\n  0.9994515,\n  0.00034448504,\n  0.90060186,\n  3.474953e-07,\n  0.9968425,\n  0.9949793,\n  0.069060266,\n  0.043775022,\n  0.00014066696,\n  0.18709695,\n  0.66105217,\n  0.9963473,\n  0.68009573,\n  0.27564734,\n  0.14582309,\n  0.9998625,\n  0.9721713,\n  0.042434067,\n  0.73436785,\n  0.99145544,\n  0.8718113,\n  1.0,\n  0.057273507,\n  0.5108621,\n  1.49174075e-05,\n  6.0494083e-05,\n  0.96805215,\n  0.9958149,\n  0.9803576,\n  0.25034404,\n  0.8983911,\n  0.8996597,\n  0.08358303,\n  0.02809143,\n  0.86578995,\n  0.05619663,\n  0.5673759,\n  0.9045757,\n  0.23617417,\n  0.021097034,\n  0.94122803,\n  0.10407141,\n  0.037298143,\n  0.08692181,\n  0.032458603,\n  0.054324448,\n  0.08710319,\n  0.998289,\n  1.5917949e-05,\n  0.99999857,\n  0.97904515,\n  0.060103178,\n  0.10892564,\n  0.032458603,\n  0.9982019,\n  0.01183179,\n  0.0051885545,\n  0.43058574,\n  0.043004036,\n  0.9756099,\n  0.9999988],\n 'X_test': array([[[ 1.24926451,  1.2432584 ,  1.25126655, ..., -0.55056716,\n          -0.54656309, -0.54656309],\n         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n           0.        ,  0.        ]],\n \n        [[-0.60561646, -0.60461544, -0.60261341, ..., -0.00901142,\n           0.00500279,  0.01200989],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]],\n \n        [[ 0.12717453,  0.1331847 ,  0.12116436, ..., -0.00901142,\n           0.00500279,  0.01200989],\n         [ 3.        ,  3.        ,  3.        , ...,  3.        ,\n           3.        ,  3.        ]],\n \n        ...,\n \n        [[-2.07897276, -2.07797085, -2.10101481, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]],\n \n        [[-0.71174154, -0.70272505, -0.69370856, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n           2.        ,  2.        ]],\n \n        [[-0.22535605, -0.25039771, -0.20231773, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]]]),\n 'y_test': [0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0]}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'trained_model': <keras.engine.functional.Functional at 0x7f05c3f7b490>,\n 'eval': [2.7362866401672363, 0.5062500238418579],\n 'test_subjects': [3, 4, 5, 7, 8, 10, 11, 12, 14, 17],\n 'test_pred': array([[5.53763807e-02],\n        [2.45020866e-01],\n        [8.00483048e-01],\n        [9.99991000e-01],\n        [9.65194285e-01],\n        [9.99998510e-01],\n        [8.68622899e-01],\n        [4.84111935e-01],\n        [9.89645600e-01],\n        [2.20747322e-01],\n        [2.84206271e-02],\n        [3.55777025e-01],\n        [3.58823329e-01],\n        [9.95826960e-01],\n        [5.38711011e-01],\n        [9.99875784e-01],\n        [4.73260880e-04],\n        [9.99998510e-01],\n        [7.09101021e-01],\n        [2.48587936e-01],\n        [9.99034524e-01],\n        [9.90540504e-01],\n        [2.76880741e-01],\n        [9.95826960e-01],\n        [6.65986538e-02],\n        [6.61595881e-01],\n        [9.98688817e-01],\n        [3.21209431e-04],\n        [9.15743053e-01],\n        [2.11732537e-01],\n        [9.97453213e-01],\n        [9.99933362e-01],\n        [9.99997973e-01],\n        [9.99870658e-01],\n        [9.99992490e-01],\n        [9.99712467e-01],\n        [1.00000000e+00],\n        [1.00000000e+00],\n        [1.00000000e+00],\n        [9.99997139e-01],\n        [1.12853050e-02],\n        [9.66007352e-01],\n        [5.28841197e-01],\n        [9.97154891e-01],\n        [1.59441590e-01],\n        [8.92526329e-01],\n        [9.98229146e-01],\n        [2.85630107e-01],\n        [9.99997973e-01],\n        [1.64874792e-02],\n        [9.34563279e-01],\n        [9.22675014e-01],\n        [9.99913275e-01],\n        [9.99838591e-01],\n        [9.46871817e-01],\n        [9.72783983e-01],\n        [9.22565877e-01],\n        [5.46057105e-01],\n        [9.99854445e-01],\n        [6.17492855e-01],\n        [9.95988846e-01],\n        [9.99999046e-01],\n        [1.47632062e-02],\n        [9.34563398e-01],\n        [3.31695974e-01],\n        [9.91586804e-01],\n        [2.78097391e-02],\n        [9.99242544e-01],\n        [2.10012794e-02],\n        [6.15811348e-02],\n        [5.49923599e-01],\n        [6.00247085e-02],\n        [9.98310566e-01],\n        [5.73024154e-02],\n        [7.80411243e-01],\n        [9.82731462e-01],\n        [9.96803880e-01],\n        [1.67727768e-02],\n        [9.95242476e-01],\n        [1.42720491e-01],\n        [9.91127253e-01],\n        [9.99421597e-01],\n        [4.74636853e-01],\n        [9.64091718e-02],\n        [5.25285363e-01],\n        [9.88200307e-03],\n        [8.43799412e-02],\n        [9.85769153e-01],\n        [3.63544226e-02],\n        [1.66498423e-02],\n        [9.99674618e-01],\n        [9.93245363e-01],\n        [9.72829223e-01],\n        [9.99995351e-01],\n        [6.00246489e-02],\n        [9.99311149e-01],\n        [9.87208128e-01],\n        [9.99967992e-01],\n        [9.98751402e-01],\n        [9.88633752e-01],\n        [9.99490261e-01],\n        [3.04285288e-02],\n        [9.99999046e-01],\n        [9.98131454e-01],\n        [9.99152422e-01],\n        [9.99962330e-01],\n        [9.91450608e-01],\n        [9.99719143e-01],\n        [9.99999762e-01],\n        [9.98411179e-01],\n        [9.99994218e-01],\n        [9.99392927e-01],\n        [8.33461583e-01],\n        [9.96691585e-01],\n        [9.99999642e-01],\n        [9.99787688e-01],\n        [9.90904272e-01],\n        [9.99979019e-01],\n        [9.96844411e-01],\n        [1.00000000e+00],\n        [9.99998808e-01],\n        [9.99998629e-01],\n        [9.95211840e-01],\n        [9.99967933e-01],\n        [3.00142884e-01],\n        [2.27808028e-01],\n        [9.22336221e-01],\n        [7.26937950e-02],\n        [1.61625445e-01],\n        [4.72862840e-01],\n        [6.49190485e-01],\n        [9.31529701e-01],\n        [9.84686375e-01],\n        [9.86329556e-01],\n        [1.65252924e-01],\n        [1.52063167e-05],\n        [1.14254177e-01],\n        [9.96710658e-01],\n        [5.94601879e-05],\n        [2.20653415e-03],\n        [1.06511652e-01],\n        [3.65491474e-06],\n        [9.61144924e-01],\n        [7.09652901e-04],\n        [4.61418331e-02],\n        [9.98742223e-01],\n        [4.01803591e-05],\n        [1.73195392e-01],\n        [9.82574582e-01],\n        [2.55304575e-03],\n        [2.17505395e-02],\n        [4.26866827e-05],\n        [2.62901187e-03],\n        [5.99786460e-01],\n        [3.98774147e-01],\n        [8.87250602e-01],\n        [3.22487950e-01],\n        [9.98567462e-01],\n        [9.72486734e-01],\n        [9.99011040e-01],\n        [9.99999583e-01],\n        [9.99997973e-01],\n        [9.99502897e-01],\n        [9.99582529e-01],\n        [9.99959826e-01],\n        [9.99976635e-01],\n        [1.26256287e-01],\n        [2.79522955e-01],\n        [8.91214073e-01],\n        [9.99839902e-01],\n        [1.21685863e-03],\n        [9.41291213e-01],\n        [9.99500096e-01],\n        [9.99218345e-01],\n        [4.65497375e-03],\n        [9.93198276e-01],\n        [9.99958992e-01],\n        [5.08140922e-02],\n        [4.40052211e-01],\n        [1.14468647e-04],\n        [1.68799102e-01],\n        [8.85311604e-01],\n        [9.97421920e-01],\n        [8.72758031e-03],\n        [9.99218345e-01],\n        [9.99168754e-01],\n        [9.99982059e-01],\n        [9.99983311e-01],\n        [3.40656340e-02],\n        [8.95567298e-01],\n        [1.49725974e-02],\n        [2.19754755e-01],\n        [9.99991179e-01],\n        [9.06915545e-01],\n        [9.93644714e-01],\n        [9.35452878e-01],\n        [7.22874999e-02],\n        [5.55586815e-03],\n        [6.82801008e-04],\n        [4.12821770e-04],\n        [1.82473660e-03],\n        [6.02010296e-05],\n        [1.60857111e-01],\n        [3.77174020e-02],\n        [9.80820537e-01],\n        [4.71546471e-01],\n        [9.99289274e-01],\n        [2.73167491e-02],\n        [6.98247194e-01],\n        [9.99085367e-01],\n        [7.18152821e-02],\n        [2.43527830e-01],\n        [4.86445725e-02],\n        [9.99368429e-01],\n        [1.19221462e-04],\n        [9.93644714e-01],\n        [9.21942055e-01],\n        [6.08352721e-02],\n        [2.54025161e-01],\n        [9.97700930e-01],\n        [9.89178300e-01],\n        [9.99872267e-01],\n        [8.40501308e-01],\n        [9.97318268e-01],\n        [1.00000000e+00],\n        [9.98280942e-01],\n        [1.77750587e-02],\n        [9.85787094e-01],\n        [2.04291344e-02],\n        [9.14383650e-01],\n        [9.37721014e-01],\n        [2.72004902e-01],\n        [4.43062961e-01],\n        [2.20130086e-02],\n        [9.95936096e-01],\n        [1.61093473e-03],\n        [9.99988854e-01],\n        [9.67378974e-01],\n        [7.83385634e-02],\n        [9.99988258e-01],\n        [3.50210071e-03],\n        [1.66231394e-03],\n        [9.62000966e-01],\n        [1.80310011e-01],\n        [9.99976397e-01],\n        [1.04306042e-01],\n        [3.67864966e-03],\n        [9.99742270e-01],\n        [3.71471643e-02],\n        [1.36197180e-01],\n        [1.03020370e-02],\n        [4.96528447e-02],\n        [3.41964364e-02],\n        [1.23935044e-02],\n        [6.84033632e-01],\n        [9.99989867e-01],\n        [9.99999583e-01],\n        [8.69522929e-01],\n        [7.26667047e-03],\n        [9.99842525e-01],\n        [1.22264028e-03],\n        [9.91621971e-01],\n        [8.43409538e-01],\n        [7.25269318e-04],\n        [3.26576829e-03],\n        [5.52085042e-03],\n        [5.40857017e-01],\n        [2.07653642e-03],\n        [9.71754074e-01],\n        [8.45037699e-02],\n        [8.26772988e-01],\n        [9.98818994e-01],\n        [7.97382176e-01],\n        [9.16201472e-01],\n        [9.95360136e-01],\n        [9.89801884e-02],\n        [1.09585255e-01],\n        [1.06399298e-01],\n        [1.35976076e-03],\n        [9.10164475e-01],\n        [9.99611795e-01],\n        [9.75620866e-01],\n        [9.09662545e-02],\n        [9.90268826e-01],\n        [1.17259920e-02],\n        [9.22680199e-01],\n        [1.39057636e-03],\n        [2.70507932e-02],\n        [3.73753607e-02],\n        [9.13546979e-01],\n        [2.40048766e-03],\n        [9.99868512e-01],\n        [9.99886930e-01],\n        [4.11540270e-03],\n        [1.26566476e-06],\n        [6.52896901e-08],\n        [6.51466846e-03],\n        [9.98391747e-01],\n        [9.90798354e-01],\n        [4.18066978e-04],\n        [9.95705128e-01],\n        [2.33301520e-03],\n        [5.21063805e-04],\n        [9.97658610e-01],\n        [9.99971986e-01],\n        [9.99993563e-01],\n        [9.99999225e-01],\n        [2.24228263e-01],\n        [9.99984503e-01],\n        [1.00000000e+00],\n        [9.98105228e-01],\n        [3.73314142e-01],\n        [9.97658610e-01],\n        [9.99997735e-01],\n        [4.84207213e-01],\n        [2.93007731e-01],\n        [4.61889803e-02],\n        [1.56893134e-02],\n        [9.98518467e-01],\n        [9.99618232e-01]], dtype=float32),\n 'X_test': array([[[ 1.24926451,  1.2432584 ,  1.25126655, ..., -0.55056716,\n          -0.54656309, -0.54656309],\n         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n           0.        ,  0.        ]],\n \n        [[-0.60561646, -0.60461544, -0.60261341, ..., -0.00901142,\n           0.00500279,  0.01200989],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]],\n \n        [[ 0.12717453,  0.1331847 ,  0.12116436, ..., -0.00901142,\n           0.00500279,  0.01200989],\n         [ 3.        ,  3.        ,  3.        , ...,  3.        ,\n           3.        ,  3.        ]],\n \n        ...,\n \n        [[-2.07897276, -2.07797085, -2.10101481, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]],\n \n        [[-0.71174154, -0.70272505, -0.69370856, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n           2.        ,  2.        ]],\n \n        [[-0.22535605, -0.25039771, -0.20231773, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]]]),\n 'y_test': [0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0]}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = res_dict[0]\n",
    "d\n",
    "# [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'trained_model': <keras.engine.functional.Functional at 0x7f05c3f7b490>,\n 'eval': [2.7362866401672363, 0.5062500238418579],\n 'test_subjects': [3, 4, 5, 7, 8, 10, 11, 12, 14, 17],\n 'test_pred': array([[5.53763807e-02],\n        [2.45020866e-01],\n        [8.00483048e-01],\n        [9.99991000e-01],\n        [9.65194285e-01],\n        [9.99998510e-01],\n        [8.68622899e-01],\n        [4.84111935e-01],\n        [9.89645600e-01],\n        [2.20747322e-01],\n        [2.84206271e-02],\n        [3.55777025e-01],\n        [3.58823329e-01],\n        [9.95826960e-01],\n        [5.38711011e-01],\n        [9.99875784e-01],\n        [4.73260880e-04],\n        [9.99998510e-01],\n        [7.09101021e-01],\n        [2.48587936e-01],\n        [9.99034524e-01],\n        [9.90540504e-01],\n        [2.76880741e-01],\n        [9.95826960e-01],\n        [6.65986538e-02],\n        [6.61595881e-01],\n        [9.98688817e-01],\n        [3.21209431e-04],\n        [9.15743053e-01],\n        [2.11732537e-01],\n        [9.97453213e-01],\n        [9.99933362e-01],\n        [9.99997973e-01],\n        [9.99870658e-01],\n        [9.99992490e-01],\n        [9.99712467e-01],\n        [1.00000000e+00],\n        [1.00000000e+00],\n        [1.00000000e+00],\n        [9.99997139e-01],\n        [1.12853050e-02],\n        [9.66007352e-01],\n        [5.28841197e-01],\n        [9.97154891e-01],\n        [1.59441590e-01],\n        [8.92526329e-01],\n        [9.98229146e-01],\n        [2.85630107e-01],\n        [9.99997973e-01],\n        [1.64874792e-02],\n        [9.34563279e-01],\n        [9.22675014e-01],\n        [9.99913275e-01],\n        [9.99838591e-01],\n        [9.46871817e-01],\n        [9.72783983e-01],\n        [9.22565877e-01],\n        [5.46057105e-01],\n        [9.99854445e-01],\n        [6.17492855e-01],\n        [9.95988846e-01],\n        [9.99999046e-01],\n        [1.47632062e-02],\n        [9.34563398e-01],\n        [3.31695974e-01],\n        [9.91586804e-01],\n        [2.78097391e-02],\n        [9.99242544e-01],\n        [2.10012794e-02],\n        [6.15811348e-02],\n        [5.49923599e-01],\n        [6.00247085e-02],\n        [9.98310566e-01],\n        [5.73024154e-02],\n        [7.80411243e-01],\n        [9.82731462e-01],\n        [9.96803880e-01],\n        [1.67727768e-02],\n        [9.95242476e-01],\n        [1.42720491e-01],\n        [9.91127253e-01],\n        [9.99421597e-01],\n        [4.74636853e-01],\n        [9.64091718e-02],\n        [5.25285363e-01],\n        [9.88200307e-03],\n        [8.43799412e-02],\n        [9.85769153e-01],\n        [3.63544226e-02],\n        [1.66498423e-02],\n        [9.99674618e-01],\n        [9.93245363e-01],\n        [9.72829223e-01],\n        [9.99995351e-01],\n        [6.00246489e-02],\n        [9.99311149e-01],\n        [9.87208128e-01],\n        [9.99967992e-01],\n        [9.98751402e-01],\n        [9.88633752e-01],\n        [9.99490261e-01],\n        [3.04285288e-02],\n        [9.99999046e-01],\n        [9.98131454e-01],\n        [9.99152422e-01],\n        [9.99962330e-01],\n        [9.91450608e-01],\n        [9.99719143e-01],\n        [9.99999762e-01],\n        [9.98411179e-01],\n        [9.99994218e-01],\n        [9.99392927e-01],\n        [8.33461583e-01],\n        [9.96691585e-01],\n        [9.99999642e-01],\n        [9.99787688e-01],\n        [9.90904272e-01],\n        [9.99979019e-01],\n        [9.96844411e-01],\n        [1.00000000e+00],\n        [9.99998808e-01],\n        [9.99998629e-01],\n        [9.95211840e-01],\n        [9.99967933e-01],\n        [3.00142884e-01],\n        [2.27808028e-01],\n        [9.22336221e-01],\n        [7.26937950e-02],\n        [1.61625445e-01],\n        [4.72862840e-01],\n        [6.49190485e-01],\n        [9.31529701e-01],\n        [9.84686375e-01],\n        [9.86329556e-01],\n        [1.65252924e-01],\n        [1.52063167e-05],\n        [1.14254177e-01],\n        [9.96710658e-01],\n        [5.94601879e-05],\n        [2.20653415e-03],\n        [1.06511652e-01],\n        [3.65491474e-06],\n        [9.61144924e-01],\n        [7.09652901e-04],\n        [4.61418331e-02],\n        [9.98742223e-01],\n        [4.01803591e-05],\n        [1.73195392e-01],\n        [9.82574582e-01],\n        [2.55304575e-03],\n        [2.17505395e-02],\n        [4.26866827e-05],\n        [2.62901187e-03],\n        [5.99786460e-01],\n        [3.98774147e-01],\n        [8.87250602e-01],\n        [3.22487950e-01],\n        [9.98567462e-01],\n        [9.72486734e-01],\n        [9.99011040e-01],\n        [9.99999583e-01],\n        [9.99997973e-01],\n        [9.99502897e-01],\n        [9.99582529e-01],\n        [9.99959826e-01],\n        [9.99976635e-01],\n        [1.26256287e-01],\n        [2.79522955e-01],\n        [8.91214073e-01],\n        [9.99839902e-01],\n        [1.21685863e-03],\n        [9.41291213e-01],\n        [9.99500096e-01],\n        [9.99218345e-01],\n        [4.65497375e-03],\n        [9.93198276e-01],\n        [9.99958992e-01],\n        [5.08140922e-02],\n        [4.40052211e-01],\n        [1.14468647e-04],\n        [1.68799102e-01],\n        [8.85311604e-01],\n        [9.97421920e-01],\n        [8.72758031e-03],\n        [9.99218345e-01],\n        [9.99168754e-01],\n        [9.99982059e-01],\n        [9.99983311e-01],\n        [3.40656340e-02],\n        [8.95567298e-01],\n        [1.49725974e-02],\n        [2.19754755e-01],\n        [9.99991179e-01],\n        [9.06915545e-01],\n        [9.93644714e-01],\n        [9.35452878e-01],\n        [7.22874999e-02],\n        [5.55586815e-03],\n        [6.82801008e-04],\n        [4.12821770e-04],\n        [1.82473660e-03],\n        [6.02010296e-05],\n        [1.60857111e-01],\n        [3.77174020e-02],\n        [9.80820537e-01],\n        [4.71546471e-01],\n        [9.99289274e-01],\n        [2.73167491e-02],\n        [6.98247194e-01],\n        [9.99085367e-01],\n        [7.18152821e-02],\n        [2.43527830e-01],\n        [4.86445725e-02],\n        [9.99368429e-01],\n        [1.19221462e-04],\n        [9.93644714e-01],\n        [9.21942055e-01],\n        [6.08352721e-02],\n        [2.54025161e-01],\n        [9.97700930e-01],\n        [9.89178300e-01],\n        [9.99872267e-01],\n        [8.40501308e-01],\n        [9.97318268e-01],\n        [1.00000000e+00],\n        [9.98280942e-01],\n        [1.77750587e-02],\n        [9.85787094e-01],\n        [2.04291344e-02],\n        [9.14383650e-01],\n        [9.37721014e-01],\n        [2.72004902e-01],\n        [4.43062961e-01],\n        [2.20130086e-02],\n        [9.95936096e-01],\n        [1.61093473e-03],\n        [9.99988854e-01],\n        [9.67378974e-01],\n        [7.83385634e-02],\n        [9.99988258e-01],\n        [3.50210071e-03],\n        [1.66231394e-03],\n        [9.62000966e-01],\n        [1.80310011e-01],\n        [9.99976397e-01],\n        [1.04306042e-01],\n        [3.67864966e-03],\n        [9.99742270e-01],\n        [3.71471643e-02],\n        [1.36197180e-01],\n        [1.03020370e-02],\n        [4.96528447e-02],\n        [3.41964364e-02],\n        [1.23935044e-02],\n        [6.84033632e-01],\n        [9.99989867e-01],\n        [9.99999583e-01],\n        [8.69522929e-01],\n        [7.26667047e-03],\n        [9.99842525e-01],\n        [1.22264028e-03],\n        [9.91621971e-01],\n        [8.43409538e-01],\n        [7.25269318e-04],\n        [3.26576829e-03],\n        [5.52085042e-03],\n        [5.40857017e-01],\n        [2.07653642e-03],\n        [9.71754074e-01],\n        [8.45037699e-02],\n        [8.26772988e-01],\n        [9.98818994e-01],\n        [7.97382176e-01],\n        [9.16201472e-01],\n        [9.95360136e-01],\n        [9.89801884e-02],\n        [1.09585255e-01],\n        [1.06399298e-01],\n        [1.35976076e-03],\n        [9.10164475e-01],\n        [9.99611795e-01],\n        [9.75620866e-01],\n        [9.09662545e-02],\n        [9.90268826e-01],\n        [1.17259920e-02],\n        [9.22680199e-01],\n        [1.39057636e-03],\n        [2.70507932e-02],\n        [3.73753607e-02],\n        [9.13546979e-01],\n        [2.40048766e-03],\n        [9.99868512e-01],\n        [9.99886930e-01],\n        [4.11540270e-03],\n        [1.26566476e-06],\n        [6.52896901e-08],\n        [6.51466846e-03],\n        [9.98391747e-01],\n        [9.90798354e-01],\n        [4.18066978e-04],\n        [9.95705128e-01],\n        [2.33301520e-03],\n        [5.21063805e-04],\n        [9.97658610e-01],\n        [9.99971986e-01],\n        [9.99993563e-01],\n        [9.99999225e-01],\n        [2.24228263e-01],\n        [9.99984503e-01],\n        [1.00000000e+00],\n        [9.98105228e-01],\n        [3.73314142e-01],\n        [9.97658610e-01],\n        [9.99997735e-01],\n        [4.84207213e-01],\n        [2.93007731e-01],\n        [4.61889803e-02],\n        [1.56893134e-02],\n        [9.98518467e-01],\n        [9.99618232e-01]], dtype=float32),\n 'X_test': array([[[ 1.24926451,  1.2432584 ,  1.25126655, ..., -0.55056716,\n          -0.54656309, -0.54656309],\n         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n           0.        ,  0.        ]],\n \n        [[-0.60561646, -0.60461544, -0.60261341, ..., -0.00901142,\n           0.00500279,  0.01200989],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]],\n \n        [[ 0.12717453,  0.1331847 ,  0.12116436, ..., -0.00901142,\n           0.00500279,  0.01200989],\n         [ 3.        ,  3.        ,  3.        , ...,  3.        ,\n           3.        ,  3.        ]],\n \n        ...,\n \n        [[-2.07897276, -2.07797085, -2.10101481, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]],\n \n        [[-0.71174154, -0.70272505, -0.69370856, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n           2.        ,  2.        ]],\n \n        [[-0.22535605, -0.25039771, -0.20231773, ...,  0.12546769,\n           0.09836716,  0.0913411 ],\n         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n           1.        ,  1.        ]]]),\n 'y_test': [0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0]}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}