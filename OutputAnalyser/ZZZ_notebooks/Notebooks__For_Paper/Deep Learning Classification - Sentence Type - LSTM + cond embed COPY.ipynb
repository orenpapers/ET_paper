{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-15 12:07:20.941956\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.4.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (3.4.0)\r\n",
      "Requirement already satisfied: tensorflow==1.5.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.5.0)\r\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.1.1)\r\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.19.5)\r\n",
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.0.post1)\r\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.1.5)\r\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (3.3.4)\r\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.11.2)\r\n",
      "Requirement already satisfied: six>=1.9 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from protobuf==3.4.0) (1.16.0)\r\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from protobuf==3.4.0) (39.0.1)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow==1.5.0) (0.37.1)\r\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow==1.5.0) (1.3.0)\r\n",
      "Requirement already satisfied: tensorflow-tensorboard<1.6.0,>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow==1.5.0) (1.5.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas) (2022.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (3.0.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (8.4.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from seaborn) (1.5.4)\r\n",
      "Requirement already satisfied: html5lib==0.9999999 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (0.9999999)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (2.0.3)\r\n",
      "Requirement already satisfied: bleach==1.5.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (1.5.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (3.3.7)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (4.8.3)\r\n",
      "Requirement already satisfied: dataclasses in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from werkzeug>=0.11.10->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (0.8)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (3.6.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install protobuf==3.4.0 tensorflow==1.5.0 joblib numpy sklearn pandas matplotlib seaborn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.1.1)\r\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.19.5)\r\n",
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.0.post1)\r\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.1.5)\r\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (3.3.4)\r\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.11.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas) (2022.6)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (8.4.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (3.0.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from seaborn) (1.5.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install joblib numpy sklearn pandas matplotlib seaborn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-5ebe97fccdcf>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Num GPUs Available: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist_physical_devices\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'GPU'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_available_gpus\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.keras import backend as K\n",
    "print(K._get_available_gpus())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/bin/pip3\r\n"
     ]
    }
   ],
   "source": [
    "!which pip3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "scale_col = \"x_gaze_location_standard_scaled\"\n",
    "\n",
    "def apply_phq_cutoff(df , neg_phq_cutoff, pos_phq_cutoff):\n",
    "    df[\"phq_binary_label\"] = [0.0 if x <= neg_phq_cutoff else 1.0 if x >= pos_phq_cutoff else \"other\" for x in df.phq_score]\n",
    "    df = df[df.phq_binary_label!= 'other']\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_timecols_df_for_DL(fn =\"/Users/orenkobo/Desktop/PhD_new/repos/HebLingStudy/notebooks/df.csv\",\n",
    "                           scale_col = scale_col):\n",
    "\n",
    "    import string, re\n",
    "    print(f\"{datetime.datetime.now()} Reading csv from {fn}\")\n",
    "    df = pd.read_csv(fn,\n",
    "                     index_col=None,\n",
    "                     converters={#'alephbert_enc': eval,\n",
    "                         scale_col : eval,\n",
    "                         # 'x_gaze_location_minmax_scaled' : eval,\n",
    "                         # 'x_gaze_location_standard_scaled' : eval,\n",
    "                         # 'target_word_x_range' : eval\n",
    "                         # 'phq_label': bool\n",
    "                     })\n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "    df = df[df.Sentence_type != 'F'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    id_cols = [\"phq_score\",\"phq_group\",\"Subject\", \"Sentence_type\",\n",
    "               \"sentence_pupil_diameter_mean\",\"set_num\"]\n",
    "    # vec_size = 3500\n",
    "    # new_colname = f\"x_gaze_location_{vec_size}\"\n",
    "    cols = [f\"timepoint#{i}\" for i in range(875)]\n",
    "    # df[new_colname] = df[\"x_gaze_location_standard_scaled\"].apply(lambda x : x[:vec_size])\n",
    "    timeseries_df = pd.DataFrame(data = df[scale_col].to_list() , columns = cols)\n",
    "    timeseries_df[id_cols] = df[id_cols]\n",
    "    timeseries_df = timeseries_df.iloc[:,200:]\n",
    "    cols = [x for x in timeseries_df.columns if \"timepoint\" in x]\n",
    "    return timeseries_df, cols"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 09:21:12.751801 Reading csv from /export/home/orenkobo/Aim1/paper_analysis/Artifacts/df_new_full__unsegmented_alldata_new_FINAL_paparanalysis.csv\n",
      "(9696, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      timepoint#200  timepoint#201  timepoint#202  timepoint#203  \\\n0          1.248853       1.242846       1.250856       1.257864   \n1         -0.605603      -0.604602      -0.602600      -0.590588   \n2          0.127316       0.133326       0.121306       0.099268   \n3         -1.144312      -1.155340      -1.149325      -1.117245   \n4         -1.554332      -1.571359      -1.577369      -1.608418   \n...             ...            ...            ...            ...   \n3227      -1.686416      -1.706449      -1.697434      -2.352531   \n3228       0.985337       0.997349       0.986338       0.976329   \n3229       1.002969       1.014985       0.504330       0.345126   \n3230       1.745621       1.753631       1.758638       1.737610   \n3231       0.597177       0.605189       0.584156       0.580149   \n\n      timepoint#204  timepoint#205  timepoint#206  timepoint#207  \\\n0          1.246851       1.239843       1.238841       1.250856   \n1         -1.061065      -1.648661      -1.700713      -1.695708   \n2          0.104277       0.115296       0.122307       0.124311   \n3         -1.106217      -1.129275      -1.135290      -1.111230   \n4         -1.600405      -1.571359      -1.558338      -1.560341   \n...             ...            ...            ...            ...   \n3227      -2.500779      -2.447690      -2.421646      -2.419643   \n3228       0.983335       0.991343       0.990342       0.994346   \n3229       0.339118       0.340120       0.351134       0.363149   \n3230       1.736609       1.735608       1.736609       1.741616   \n3231       0.589164       0.593170       0.607193       0.593170   \n\n      timepoint#208  timepoint#209  ...  Subject  Sentence_type  \\\n0          1.242846       1.239843  ...        3              A   \n1         -1.703717      -1.710724  ...        3              B   \n2          0.135330       0.161374  ...        3              D   \n3         -1.109224      -1.127270  ...        3              A   \n4         -1.565349      -1.573362  ...        3              B   \n...             ...            ...  ...      ...            ...   \n3227      -2.425653      -2.450695  ...      139              D   \n3228       0.975328       0.977330  ...      139              D   \n3229       0.364150       0.377167  ...      139              A   \n3230       1.322060       1.367120  ...      139              C   \n3231       0.599180       0.602185  ...      139              C   \n\n      sentence_pupil_diameter_mean  set_num  phq_binary_label  A  B  C  D  \\\n0                      5110.630668       17               0.0  1  0  0  0   \n1                      4974.146741        5               0.0  0  1  0  0   \n2                      4739.278462       12               0.0  0  0  0  1   \n3                      4775.260020        6               0.0  1  0  0  0   \n4                      4746.720839       26               0.0  0  1  0  0   \n...                            ...      ...               ... .. .. .. ..   \n3227                   5117.994088        0               1.0  0  0  0  1   \n3228                   4995.187626       15               1.0  0  0  0  1   \n3229                   4934.199434       27               1.0  1  0  0  0   \n3230                   5056.427875        4               1.0  0  0  1  0   \n3231                   5069.907967       13               1.0  0  0  1  0   \n\n      encoded_cond  \n0                0  \n1                1  \n2                3  \n3                0  \n4                1  \n...            ...  \n3227             3  \n3228             3  \n3229             0  \n3230             2  \n3231             2  \n\n[3232 rows x 687 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timepoint#200</th>\n      <th>timepoint#201</th>\n      <th>timepoint#202</th>\n      <th>timepoint#203</th>\n      <th>timepoint#204</th>\n      <th>timepoint#205</th>\n      <th>timepoint#206</th>\n      <th>timepoint#207</th>\n      <th>timepoint#208</th>\n      <th>timepoint#209</th>\n      <th>...</th>\n      <th>Subject</th>\n      <th>Sentence_type</th>\n      <th>sentence_pupil_diameter_mean</th>\n      <th>set_num</th>\n      <th>phq_binary_label</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>encoded_cond</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.248853</td>\n      <td>1.242846</td>\n      <td>1.250856</td>\n      <td>1.257864</td>\n      <td>1.246851</td>\n      <td>1.239843</td>\n      <td>1.238841</td>\n      <td>1.250856</td>\n      <td>1.242846</td>\n      <td>1.239843</td>\n      <td>...</td>\n      <td>3</td>\n      <td>A</td>\n      <td>5110.630668</td>\n      <td>17</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.605603</td>\n      <td>-0.604602</td>\n      <td>-0.602600</td>\n      <td>-0.590588</td>\n      <td>-1.061065</td>\n      <td>-1.648661</td>\n      <td>-1.700713</td>\n      <td>-1.695708</td>\n      <td>-1.703717</td>\n      <td>-1.710724</td>\n      <td>...</td>\n      <td>3</td>\n      <td>B</td>\n      <td>4974.146741</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.127316</td>\n      <td>0.133326</td>\n      <td>0.121306</td>\n      <td>0.099268</td>\n      <td>0.104277</td>\n      <td>0.115296</td>\n      <td>0.122307</td>\n      <td>0.124311</td>\n      <td>0.135330</td>\n      <td>0.161374</td>\n      <td>...</td>\n      <td>3</td>\n      <td>D</td>\n      <td>4739.278462</td>\n      <td>12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.144312</td>\n      <td>-1.155340</td>\n      <td>-1.149325</td>\n      <td>-1.117245</td>\n      <td>-1.106217</td>\n      <td>-1.129275</td>\n      <td>-1.135290</td>\n      <td>-1.111230</td>\n      <td>-1.109224</td>\n      <td>-1.127270</td>\n      <td>...</td>\n      <td>3</td>\n      <td>A</td>\n      <td>4775.260020</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.554332</td>\n      <td>-1.571359</td>\n      <td>-1.577369</td>\n      <td>-1.608418</td>\n      <td>-1.600405</td>\n      <td>-1.571359</td>\n      <td>-1.558338</td>\n      <td>-1.560341</td>\n      <td>-1.565349</td>\n      <td>-1.573362</td>\n      <td>...</td>\n      <td>3</td>\n      <td>B</td>\n      <td>4746.720839</td>\n      <td>26</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3227</th>\n      <td>-1.686416</td>\n      <td>-1.706449</td>\n      <td>-1.697434</td>\n      <td>-2.352531</td>\n      <td>-2.500779</td>\n      <td>-2.447690</td>\n      <td>-2.421646</td>\n      <td>-2.419643</td>\n      <td>-2.425653</td>\n      <td>-2.450695</td>\n      <td>...</td>\n      <td>139</td>\n      <td>D</td>\n      <td>5117.994088</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3228</th>\n      <td>0.985337</td>\n      <td>0.997349</td>\n      <td>0.986338</td>\n      <td>0.976329</td>\n      <td>0.983335</td>\n      <td>0.991343</td>\n      <td>0.990342</td>\n      <td>0.994346</td>\n      <td>0.975328</td>\n      <td>0.977330</td>\n      <td>...</td>\n      <td>139</td>\n      <td>D</td>\n      <td>4995.187626</td>\n      <td>15</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3229</th>\n      <td>1.002969</td>\n      <td>1.014985</td>\n      <td>0.504330</td>\n      <td>0.345126</td>\n      <td>0.339118</td>\n      <td>0.340120</td>\n      <td>0.351134</td>\n      <td>0.363149</td>\n      <td>0.364150</td>\n      <td>0.377167</td>\n      <td>...</td>\n      <td>139</td>\n      <td>A</td>\n      <td>4934.199434</td>\n      <td>27</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3230</th>\n      <td>1.745621</td>\n      <td>1.753631</td>\n      <td>1.758638</td>\n      <td>1.737610</td>\n      <td>1.736609</td>\n      <td>1.735608</td>\n      <td>1.736609</td>\n      <td>1.741616</td>\n      <td>1.322060</td>\n      <td>1.367120</td>\n      <td>...</td>\n      <td>139</td>\n      <td>C</td>\n      <td>5056.427875</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3231</th>\n      <td>0.597177</td>\n      <td>0.605189</td>\n      <td>0.584156</td>\n      <td>0.580149</td>\n      <td>0.589164</td>\n      <td>0.593170</td>\n      <td>0.607193</td>\n      <td>0.593170</td>\n      <td>0.599180</td>\n      <td>0.602185</td>\n      <td>...</td>\n      <td>139</td>\n      <td>C</td>\n      <td>5069.907967</td>\n      <td>13</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>3232 rows × 687 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {}\n",
    "df_fn = \"/export/home/orenkobo/Aim1/paper_analysis/Artifacts/df_new_full__unsegmented_alldata_new_FINAL_paparanalysis.csv\"\n",
    "# df_fn = \"/Users/orenkobo/Desktop/PhD/HebLingStudy/ts_data/Artifacts2/df_new_full__unsegmented_alldata_new_FINAL.csv\"\n",
    "# et_scale_col = \"x_gaze_location_rescaled\"\n",
    "et_scale_col = \"x_gaze_location_standard_scaled\"\n",
    "override_cutoff = [7,8]\n",
    "df, timepoint_cols = get_timecols_df_for_DL(fn =df_fn, scale_col = scale_col)\n",
    "df = apply_phq_cutoff(df,\n",
    "                      neg_phq_cutoff = override_cutoff[0],\n",
    "                      pos_phq_cutoff = override_cutoff[1])\n",
    "\n",
    "\n",
    "cond_df = pd.get_dummies(df['Sentence_type'])\n",
    "cond_cols = cond_df.columns.tolist()\n",
    "df = pd.concat([df, cond_df],axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df['encoded_cond'] = LabelEncoder().fit_transform(df['Sentence_type'])\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3232, 675)\n",
      "(1427, 675)\n",
      "(3232, 675)\n"
     ]
    }
   ],
   "source": [
    "print(df[timepoint_cols].shape)\n",
    "print(df[timepoint_cols].dropna().shape)\n",
    "df[timepoint_cols] = df[timepoint_cols].ffill()\n",
    "print(df[timepoint_cols].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def generate_3d_ds(df, feats = timepoint_cols):\n",
    "    data_3d = []\n",
    "\n",
    "    labels = []\n",
    "    # print(f\"{datetime.datetime.now()} - DS generated Start\")\n",
    "    for idx , row in df.iterrows():\n",
    "        # if (idx % 500) == 0:\n",
    "        #     print(idx)\n",
    "        l = []\n",
    "        for col in feats:\n",
    "            l.append([row[col]] + [row['encoded_cond']])\n",
    "        data_3d.append(l)\n",
    "        labels.append(row[\"phq_binary_label\"])\n",
    "    X_input = np.asarray(data_3d)\n",
    "    X_input_reshaped = np.swapaxes(X_input,1,2)\n",
    "    # print(f\"{datetime.datetime.now()} - DS generated Done\")\n",
    "\n",
    "    return X_input_reshaped, labels\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def calc_per_subj_pred(pred, n=32):\n",
    "    if type(pred) != list:\n",
    "        pred = [x[0] for x in pred]\n",
    "    c = [pred[i * n:(i + 1) * n] for i in range((len(pred) + n - 1) // n )]\n",
    "    l = pd.DataFrame(c).mean(axis=1)\n",
    "    return l"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=16, restore_best_weights=True)]\n",
    "\n",
    "def train_fold(X_train, y_train, X_val, y_val, voc_size=4, nepochs=20):\n",
    "\n",
    "    inp1 = layers.Input(shape=(1, 675))  # TensorShape([None, 2, 100])\n",
    "    inp2 = layers.Input(shape=(1, 675))  # TensorShape([None, 1, 100])\n",
    "    x2 = layers.Embedding(input_dim=voc_size, output_dim=8)(inp2)  # TensorShape([None, 1, 100, 8])\n",
    "    x2_reshaped = tf.transpose(tf.squeeze(x2, axis=1), [0, 2, 1])  # TensorShape([None, 8, 100])\n",
    "    x = layers.concatenate([inp1, x2_reshaped], axis=1)\n",
    "    x = layers.LSTM(32, activation='tanh',\n",
    "                    # kernel_regularizer=tf.keras.regularizers.l1(0.001),\n",
    "                    activity_regularizer=tf.keras.regularizers.l1(0.01)\n",
    "                    )(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(8, activation='tanh',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                    activity_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "                    )(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=[x])\n",
    "\n",
    "    # print(\"A1 : \", datetime.datetime.now())\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['acc']\n",
    "    )\n",
    "\n",
    "    train_inp_gaze = X_train[:, :1, :]\n",
    "    train_inp_cond = X_train[:, 1:, :]\n",
    "    val_inp_gaze = X_val[:, :1, :]\n",
    "    val_inp_cond = X_val[:, 1:, :]\n",
    "\n",
    "\n",
    "\n",
    "    his = model.fit(epochs=nepochs, verbose=0,\n",
    "              x=[train_inp_gaze, train_inp_cond], y=np.array(y_train).astype('float'),\n",
    "              validation_data = ([val_inp_gaze, val_inp_cond], np.array(y_val).astype('float')),\n",
    "                    callbacks = callbacks)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "df[\"Is_congruent\"] = [True if x in ['A','C'] else False for x in df[\"Sentence_type\"]]\n",
    "df[\"Is_pos\"] = [True if x in ['A','B'] else False for x in df[\"Sentence_type\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 12:05:49.377008\n",
      "2022-07-10 12:05:49.395406 : Start - c = 1/4 (epochs, iters, n_tests, shuffled) = (20, 20, 10, False)\n",
      "2022-07-10 12:05:49.410940: Iter 0 (c=1)\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8064 - acc: 0.7000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7993 - acc: 0.6000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7799 - acc: 0.4000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7922 - acc: 0.4781\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8665 - acc: 0.3000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7606 - acc: 0.3000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7552 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8161 - acc: 0.6000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7809 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8928 - acc: 0.3000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7177 - acc: 0.6562\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7789 - acc: 0.4938\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7575 - acc: 0.4000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7980 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7495 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6695 - acc: 0.8000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7668 - acc: 0.4500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7734 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8490 - acc: 0.4500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8116 - acc: 0.4000\n",
      "2022-07-10 12:16:00.857047 - c = 1 , accs are 0.49140625447034836\n",
      "2022-07-10 12:16:00.857233 : Start - c = 2/4 (epochs, iters, n_tests, shuffled) = (30, 20, 10, False)\n",
      "2022-07-10 12:16:00.870082: Iter 0 (c=2)\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7887 - acc: 0.3156\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8228 - acc: 0.4000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8224 - acc: 0.3000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7321 - acc: 0.4000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8153 - acc: 0.3000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7775 - acc: 0.7000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8210 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8064 - acc: 0.6000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7366 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7406 - acc: 0.3000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8519 - acc: 0.3000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9407 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8358 - acc: 0.4500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7332 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8262 - acc: 0.5000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7205 - acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeavePGroupsOut, GroupShuffleSplit\n",
    "import random\n",
    "\n",
    "def train_loop(df, nepochs, niters, ntests, shuffles):\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    tf.random.set_seed(3)\n",
    "    # from tensorflow.keras.utils import set_random_seed\n",
    "    # set_random_seed(2)\n",
    "    c = 0\n",
    "    # num_iters = 2\n",
    "    groups1 = df['Subject']\n",
    "    # lpgo1 = LeavePGroupsOut(n_groups=10)\n",
    "    res_dict = {}\n",
    "    i = 0\n",
    "    d = []\n",
    "    total = len(shuffles) * len(nepochs) * len(niters) * len(ntests)\n",
    "    for target in [\"Is_congruent\", \"Is_pos\"]:\n",
    "        for to_shuffle in shuffles:\n",
    "            for ne in nepochs:\n",
    "                # if 1==1:\n",
    "                for num_iters in niters:#,200]:#310,15,20,25,30,50,100]:\n",
    "                    for n_test_subjs in ntests:#,10,15,20]:# [4,8,12,15,20]:\n",
    "\n",
    "                        c+=1\n",
    "                        lpgo1 = GroupShuffleSplit(n_splits=num_iters, test_size=n_test_subjs, random_state = 7)\n",
    "                        print(f\"{datetime.datetime.now()} : Start - c = {c}/{total} (epochs, iters, n_tests, shuffled) = {ne, num_iters, n_test_subjs, to_shuffle}\")\n",
    "                        i = 0\n",
    "                        for tmp_index, test_index in lpgo1.split(X = df[timepoint_cols] , y = df[target], groups = groups1):\n",
    "                            if i % 50 == 0:\n",
    "                                print(f\"{datetime.datetime.now()}: Iter {i} (c={c})\")\n",
    "                            if i==num_iters:\n",
    "                                break\n",
    "                            res_dict[i] = {}\n",
    "                            # lpgo2 = LeavePGroupsOut(n_groups=10)\n",
    "                            lpgo2 = GroupShuffleSplit(n_splits=num_iters, test_size=n_test_subjs, random_state = 7)\n",
    "                            test_subjects = list(np.unique(groups1.iloc[test_index]))\n",
    "                            test_df = df.iloc[test_index]\n",
    "                            tmp_df = df.iloc[tmp_index]\n",
    "                            groups2 = tmp_df['Subject']\n",
    "                            for train_index, val_index in lpgo2.split(X = tmp_df[timepoint_cols] ,\n",
    "                                                                      y = tmp_df[target],\n",
    "                                                                      groups = groups2):\n",
    "\n",
    "                                train_df = tmp_df.iloc[train_index]\n",
    "                                val_df = tmp_df.iloc[val_index]\n",
    "                                break\n",
    "                            X_train, y_train = generate_3d_ds(train_df)\n",
    "                            X_test, y_test = generate_3d_ds(test_df)\n",
    "                            X_val, y_val = generate_3d_ds(val_df)\n",
    "\n",
    "                            if to_shuffle:\n",
    "                                y_train = random.sample(y_train, len(y_train))\n",
    "                                y_test = random.sample(y_test, len(y_test))\n",
    "                                y_val = random.sample(y_val, len(y_val))\n",
    "\n",
    "                            fold_model = train_fold(X_train, y_train, X_val, y_val , nepochs=ne)\n",
    "                            fold_eval = fold_model.evaluate([X_test[:, :1, :], X_test[:, 1:, :]], np.array(y_test).astype('float'))\n",
    "                            fold_test_pred = fold_model.predict([X_test[:, :1, :], X_test[:, 1:, :]])\n",
    "\n",
    "                            res_dict[i][\"eval\"] = fold_eval[1]\n",
    "                            res_dict[i][\"test_subjects\"] = test_subjects\n",
    "                            res_dict[i][\"test_pred\"] = [x[0] for x in fold_test_pred]\n",
    "\n",
    "                            i+=1\n",
    "\n",
    "                        conf_acc_1 = np.mean([res_dict[x]['eval'] for x in range(num_iters)])\n",
    "                        print(f\"{datetime.datetime.now()} - c = {c} , accs are {conf_acc_1}\")\n",
    "\n",
    "                        d.append([target, num_iters, ne, n_test_subjs, conf_acc_1, to_shuffle])\n",
    "    print(f\"{datetime.datetime.now()} Done\")\n",
    "    print(d)\n",
    "    df = pd.DataFrame(d , columns=[\"num_iters\",\"num_epochs\",\"num_test_subjs\",\"eval\", \"is_shuffled_iter\"])\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "train_loop(df, nepochs = [20, 30], ntests = [10], niters = [20], shuffles = [False, True])\n",
    "print(datetime.datetime.now())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in"
     ]
    },
    {
     "data": {
      "text/plain": "      timepoint#200  timepoint#201  timepoint#202  timepoint#203  \\\n0          1.248853       1.242846       1.250856       1.257864   \n1         -0.605603      -0.604602      -0.602600      -0.590588   \n2          0.127316       0.133326       0.121306       0.099268   \n3         -1.144312      -1.155340      -1.149325      -1.117245   \n4         -1.554332      -1.571359      -1.577369      -1.608418   \n...             ...            ...            ...            ...   \n3227      -1.686416      -1.706449      -1.697434      -2.352531   \n3228       0.985337       0.997349       0.986338       0.976329   \n3229       1.002969       1.014985       0.504330       0.345126   \n3230       1.745621       1.753631       1.758638       1.737610   \n3231       0.597177       0.605189       0.584156       0.580149   \n\n      timepoint#204  timepoint#205  timepoint#206  timepoint#207  \\\n0          1.246851       1.239843       1.238841       1.250856   \n1         -1.061065      -1.648661      -1.700713      -1.695708   \n2          0.104277       0.115296       0.122307       0.124311   \n3         -1.106217      -1.129275      -1.135290      -1.111230   \n4         -1.600405      -1.571359      -1.558338      -1.560341   \n...             ...            ...            ...            ...   \n3227      -2.500779      -2.447690      -2.421646      -2.419643   \n3228       0.983335       0.991343       0.990342       0.994346   \n3229       0.339118       0.340120       0.351134       0.363149   \n3230       1.736609       1.735608       1.736609       1.741616   \n3231       0.589164       0.593170       0.607193       0.593170   \n\n      timepoint#208  timepoint#209  ...  sentence_pupil_diameter_mean  \\\n0          1.242846       1.239843  ...                   5110.630668   \n1         -1.703717      -1.710724  ...                   4974.146741   \n2          0.135330       0.161374  ...                   4739.278462   \n3         -1.109224      -1.127270  ...                   4775.260020   \n4         -1.565349      -1.573362  ...                   4746.720839   \n...             ...            ...  ...                           ...   \n3227      -2.425653      -2.450695  ...                   5117.994088   \n3228       0.975328       0.977330  ...                   4995.187626   \n3229       0.364150       0.377167  ...                   4934.199434   \n3230       1.322060       1.367120  ...                   5056.427875   \n3231       0.599180       0.602185  ...                   5069.907967   \n\n      set_num  phq_binary_label  A  B  C  D  encoded_cond  Is_congruent  \\\n0          17               0.0  1  0  0  0             0          True   \n1           5               0.0  0  1  0  0             1         False   \n2          12               0.0  0  0  0  1             3         False   \n3           6               0.0  1  0  0  0             0          True   \n4          26               0.0  0  1  0  0             1         False   \n...       ...               ... .. .. .. ..           ...           ...   \n3227        0               1.0  0  0  0  1             3         False   \n3228       15               1.0  0  0  0  1             3         False   \n3229       27               1.0  1  0  0  0             0          True   \n3230        4               1.0  0  0  1  0             2          True   \n3231       13               1.0  0  0  1  0             2          True   \n\n      Is_pos  \n0       True  \n1       True  \n2      False  \n3       True  \n4       True  \n...      ...  \n3227   False  \n3228   False  \n3229    True  \n3230   False  \n3231   False  \n\n[3232 rows x 689 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timepoint#200</th>\n      <th>timepoint#201</th>\n      <th>timepoint#202</th>\n      <th>timepoint#203</th>\n      <th>timepoint#204</th>\n      <th>timepoint#205</th>\n      <th>timepoint#206</th>\n      <th>timepoint#207</th>\n      <th>timepoint#208</th>\n      <th>timepoint#209</th>\n      <th>...</th>\n      <th>sentence_pupil_diameter_mean</th>\n      <th>set_num</th>\n      <th>phq_binary_label</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>encoded_cond</th>\n      <th>Is_congruent</th>\n      <th>Is_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.248853</td>\n      <td>1.242846</td>\n      <td>1.250856</td>\n      <td>1.257864</td>\n      <td>1.246851</td>\n      <td>1.239843</td>\n      <td>1.238841</td>\n      <td>1.250856</td>\n      <td>1.242846</td>\n      <td>1.239843</td>\n      <td>...</td>\n      <td>5110.630668</td>\n      <td>17</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.605603</td>\n      <td>-0.604602</td>\n      <td>-0.602600</td>\n      <td>-0.590588</td>\n      <td>-1.061065</td>\n      <td>-1.648661</td>\n      <td>-1.700713</td>\n      <td>-1.695708</td>\n      <td>-1.703717</td>\n      <td>-1.710724</td>\n      <td>...</td>\n      <td>4974.146741</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.127316</td>\n      <td>0.133326</td>\n      <td>0.121306</td>\n      <td>0.099268</td>\n      <td>0.104277</td>\n      <td>0.115296</td>\n      <td>0.122307</td>\n      <td>0.124311</td>\n      <td>0.135330</td>\n      <td>0.161374</td>\n      <td>...</td>\n      <td>4739.278462</td>\n      <td>12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.144312</td>\n      <td>-1.155340</td>\n      <td>-1.149325</td>\n      <td>-1.117245</td>\n      <td>-1.106217</td>\n      <td>-1.129275</td>\n      <td>-1.135290</td>\n      <td>-1.111230</td>\n      <td>-1.109224</td>\n      <td>-1.127270</td>\n      <td>...</td>\n      <td>4775.260020</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.554332</td>\n      <td>-1.571359</td>\n      <td>-1.577369</td>\n      <td>-1.608418</td>\n      <td>-1.600405</td>\n      <td>-1.571359</td>\n      <td>-1.558338</td>\n      <td>-1.560341</td>\n      <td>-1.565349</td>\n      <td>-1.573362</td>\n      <td>...</td>\n      <td>4746.720839</td>\n      <td>26</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3227</th>\n      <td>-1.686416</td>\n      <td>-1.706449</td>\n      <td>-1.697434</td>\n      <td>-2.352531</td>\n      <td>-2.500779</td>\n      <td>-2.447690</td>\n      <td>-2.421646</td>\n      <td>-2.419643</td>\n      <td>-2.425653</td>\n      <td>-2.450695</td>\n      <td>...</td>\n      <td>5117.994088</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3228</th>\n      <td>0.985337</td>\n      <td>0.997349</td>\n      <td>0.986338</td>\n      <td>0.976329</td>\n      <td>0.983335</td>\n      <td>0.991343</td>\n      <td>0.990342</td>\n      <td>0.994346</td>\n      <td>0.975328</td>\n      <td>0.977330</td>\n      <td>...</td>\n      <td>4995.187626</td>\n      <td>15</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3229</th>\n      <td>1.002969</td>\n      <td>1.014985</td>\n      <td>0.504330</td>\n      <td>0.345126</td>\n      <td>0.339118</td>\n      <td>0.340120</td>\n      <td>0.351134</td>\n      <td>0.363149</td>\n      <td>0.364150</td>\n      <td>0.377167</td>\n      <td>...</td>\n      <td>4934.199434</td>\n      <td>27</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3230</th>\n      <td>1.745621</td>\n      <td>1.753631</td>\n      <td>1.758638</td>\n      <td>1.737610</td>\n      <td>1.736609</td>\n      <td>1.735608</td>\n      <td>1.736609</td>\n      <td>1.741616</td>\n      <td>1.322060</td>\n      <td>1.367120</td>\n      <td>...</td>\n      <td>5056.427875</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3231</th>\n      <td>0.597177</td>\n      <td>0.605189</td>\n      <td>0.584156</td>\n      <td>0.580149</td>\n      <td>0.589164</td>\n      <td>0.593170</td>\n      <td>0.607193</td>\n      <td>0.593170</td>\n      <td>0.599180</td>\n      <td>0.602185</td>\n      <td>...</td>\n      <td>5069.907967</td>\n      <td>13</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>3232 rows × 689 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " database. History logging moved to new session 105\n"
     ]
    }
   ],
   "source": [
    "res_df = df.copy()\n",
    "res_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "    num_iters  num_epochs  num_test_subjs      eval  subj_acc\n0          50          10               1  0.480625     0.380\n1          50          10               5  0.453625     0.392\n2         100          10               1  0.462500     0.420\n3         100          10               5  0.471750     0.416\n4          50          15               1  0.422500     0.320\n5          50          15               5  0.477125     0.408\n6         100          15               1  0.485000     0.510\n7         100          15               5  0.480125     0.434\n8          50          20               1  0.438125     0.380\n9          50          20               5  0.446625     0.436\n10        100          20               1  0.471875     0.460\n11        100          20               5  0.446000     0.420\n12         50          30               1  0.460625     0.320\n13         50          30               5  0.453250     0.464\n14        100          30               1  0.467500     0.370\n15        100          30               5  0.448625     0.418\n16         50          50               1  0.440625     0.440\n17         50          50               5  0.427500     0.436\n18        100          50               1  0.458750     0.390\n19        100          50               5  0.414125     0.416\n20         50         100               1  0.488125     0.440\n21         50         100               5  0.455000     0.436\n22        100         100               1  0.444063     0.350\n23        100         100               5  0.433625     0.412",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_iters</th>\n      <th>num_epochs</th>\n      <th>num_test_subjs</th>\n      <th>eval</th>\n      <th>subj_acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0.480625</td>\n      <td>0.380</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>10</td>\n      <td>5</td>\n      <td>0.453625</td>\n      <td>0.392</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0.462500</td>\n      <td>0.420</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>10</td>\n      <td>5</td>\n      <td>0.471750</td>\n      <td>0.416</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>15</td>\n      <td>1</td>\n      <td>0.422500</td>\n      <td>0.320</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50</td>\n      <td>15</td>\n      <td>5</td>\n      <td>0.477125</td>\n      <td>0.408</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100</td>\n      <td>15</td>\n      <td>1</td>\n      <td>0.485000</td>\n      <td>0.510</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100</td>\n      <td>15</td>\n      <td>5</td>\n      <td>0.480125</td>\n      <td>0.434</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>50</td>\n      <td>20</td>\n      <td>1</td>\n      <td>0.438125</td>\n      <td>0.380</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>50</td>\n      <td>20</td>\n      <td>5</td>\n      <td>0.446625</td>\n      <td>0.436</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>100</td>\n      <td>20</td>\n      <td>1</td>\n      <td>0.471875</td>\n      <td>0.460</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100</td>\n      <td>20</td>\n      <td>5</td>\n      <td>0.446000</td>\n      <td>0.420</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>50</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.460625</td>\n      <td>0.320</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>50</td>\n      <td>30</td>\n      <td>5</td>\n      <td>0.453250</td>\n      <td>0.464</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>100</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.467500</td>\n      <td>0.370</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>100</td>\n      <td>30</td>\n      <td>5</td>\n      <td>0.448625</td>\n      <td>0.418</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>50</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0.440625</td>\n      <td>0.440</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>50</td>\n      <td>50</td>\n      <td>5</td>\n      <td>0.427500</td>\n      <td>0.436</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>100</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0.458750</td>\n      <td>0.390</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>100</td>\n      <td>50</td>\n      <td>5</td>\n      <td>0.414125</td>\n      <td>0.416</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>50</td>\n      <td>100</td>\n      <td>1</td>\n      <td>0.488125</td>\n      <td>0.440</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>50</td>\n      <td>100</td>\n      <td>5</td>\n      <td>0.455000</td>\n      <td>0.436</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>100</td>\n      <td>100</td>\n      <td>1</td>\n      <td>0.444063</td>\n      <td>0.350</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>100</td>\n      <td>100</td>\n      <td>5</td>\n      <td>0.433625</td>\n      <td>0.412</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(d , columns=[\"num_iters\",\"num_epochs\",\"num_test_subjs\",\"eval\",\"subj_acc\"])\n",
    "res_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "   num_iters  num_epochs  num_test_subjs      eval  subj_acc\n5         50          15               5  0.477125     0.408\n7        100          15               5  0.480125     0.434",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_iters</th>\n      <th>num_epochs</th>\n      <th>num_test_subjs</th>\n      <th>eval</th>\n      <th>subj_acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>50</td>\n      <td>15</td>\n      <td>5</td>\n      <td>0.477125</td>\n      <td>0.408</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100</td>\n      <td>15</td>\n      <td>5</td>\n      <td>0.480125</td>\n      <td>0.434</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[(res_df.num_epochs == 15) & (res_df.num_test_subjs == 5) ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import  matplotlib.pyplot as plt\n",
    "sns.catplot(data = res_df, x = 'num_iters', y='subj_acc', kind='box')\n",
    "plt.show()\n",
    "\n",
    "sns.catplot(data = res_df, x = 'num_epochs', y='subj_acc', kind='box')\n",
    "plt.show()\n",
    "\n",
    "sns.catplot(data = res_df, x = 'num_test_subjs', y='subj_acc', kind='box')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "[[100, 1, 0.481875, 0.43],\n [100, 5, 0.481875, 0.43],\n [100, 10, 0.481875, 0.43],\n [100, 15, 0.481875, 0.43],\n [100, 20, 0.481875, 0.43],\n [100, 1, 0.481875, 0.43],\n [100, 5, 0.481875, 0.43],\n [100, 10, 0.481875, 0.43],\n [100, 15, 0.481875, 0.43],\n [100, 20, 0.481875, 0.43],\n [100, 1, 0.481875, 0.43],\n [100, 5, 0.481875, 0.43],\n [100, 10, 0.481875, 0.43],\n [100, 15, 0.481875, 0.43],\n [100, 20, 0.481875, 0.43],\n [100, 1, 0.481875, 0.43],\n [100, 5, 0.481875, 0.43],\n [100, 10, 0.481875, 0.43],\n [100, 15, 0.481875, 0.43],\n [100, 20, 0.481875, 0.43],\n [100, 1, 0.481875, 0.43],\n [100, 5, 0.481875, 0.43],\n [100, 10, 0.481875, 0.43],\n [100, 15, 0.481875, 0.43],\n [100, 20, 0.481875, 0.43],\n [100, 1, 0.481875, 0.43],\n [100, 5, 0.481875, 0.43],\n [100, 10, 0.481875, 0.43],\n [100, 15, 0.481875, 0.43],\n [100, 20, 0.481875, 0.43]]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 subjects : \n",
      "0.44244791666666666\n",
      "0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"{n_test_subjs} subjects : \")\n",
    "print(np.mean([res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 subjects : \n",
      "0.44736111362775166\n",
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(f\"{n_test_subjs} subjects : \")\n",
    "print(np.mean([res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 subjects : \n",
      "0.44736111362775166\n",
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(f\"{n_test_subjs} subjects : \")\n",
    "print(np.mean([res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44736111362775166\n",
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([res_dict[i]['eval'] for i in range(num_iters)]))\n",
    "print(np.mean([res_dict[i]['subj_level_acc'] for i in range(num_iters)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4444444444444444"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = [res_dict[i]['subj_level_acc'] for i in range(num_iters)]\n",
    "np.mean(accs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(accs).plot.box()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.5070113,\n  0.16465992,\n  0.48122215,\n  0.4486994,\n  0.39266095,\n  0.45569283,\n  0.453677,\n  0.51846486,\n  0.4452508,\n  0.39522156,\n  0.39622372,\n  0.31888562,\n  0.51943463,\n  0.4699189,\n  0.5236134,\n  0.3891532,\n  0.46924448,\n  0.4759156,\n  0.4244978,\n  0.46768498,\n  0.3690222,\n  0.52378327,\n  0.29376075,\n  0.48122215,\n  0.44827297,\n  0.45631793,\n  0.44238904,\n  0.39716274,\n  0.50464594,\n  0.50514555,\n  0.4544356,\n  0.39651972],\n [0.29022944,\n  0.4834538,\n  0.45982715,\n  0.41394088,\n  0.3710991,\n  0.3714983,\n  0.42909554,\n  0.44294304,\n  0.43772668,\n  0.43834448,\n  0.38749528,\n  0.39391112,\n  0.42815793,\n  0.25977758,\n  0.45978463,\n  0.34069023,\n  0.3845086,\n  0.43672225,\n  0.3992129,\n  0.4446404,\n  0.45459804,\n  0.38521647,\n  0.4246188,\n  0.3567533,\n  0.40212372,\n  0.4191378,\n  0.3984646,\n  0.4484913,\n  0.454309,\n  0.32566705,\n  0.40597767,\n  0.46851805],\n [0.2826801,\n  0.30107045,\n  0.403914,\n  0.35224962,\n  0.41288137,\n  0.46687198,\n  0.2266157,\n  0.3381206,\n  0.35454595,\n  0.3346986,\n  0.16839445,\n  0.2951103,\n  0.4058677,\n  0.48065034,\n  0.5202276,\n  0.29177105,\n  0.32821336,\n  0.3641464,\n  0.45922253,\n  0.42642522,\n  0.13685635,\n  0.49819824,\n  0.50385374,\n  0.4056515,\n  0.49574593,\n  0.3964137,\n  0.45873654,\n  0.48325843,\n  0.39935964,\n  0.45572308,\n  0.4628353,\n  0.3641464],\n [0.41990942,\n  0.41099444,\n  0.3970545,\n  0.5153355,\n  0.47803172,\n  0.366794,\n  0.52878934,\n  0.44783393,\n  0.46160844,\n  0.46367654,\n  0.4101106,\n  0.47472724,\n  0.48809308,\n  0.473207,\n  0.46505967,\n  0.53171104,\n  0.48591942,\n  0.47962162,\n  0.32618368,\n  0.3544265,\n  0.44694185,\n  0.40239736,\n  0.47472724,\n  0.48809308,\n  0.473207,\n  0.46772552,\n  0.4729234,\n  0.49558076,\n  0.49411964,\n  0.5208483,\n  0.49865156,\n  0.41011062],\n [0.47956595,\n  0.49692693,\n  0.31800023,\n  0.48356575,\n  0.39717567,\n  0.4134399,\n  0.4593123,\n  0.36719412,\n  0.3772143,\n  0.40850267,\n  0.3432356,\n  0.32037252,\n  0.41472644,\n  0.39987463,\n  0.4254524,\n  0.3812989,\n  0.4187559,\n  0.46299112,\n  0.36719412,\n  0.53206027,\n  0.5198852,\n  0.36956286,\n  0.34999788,\n  0.43975168,\n  0.4187559,\n  0.5326503,\n  0.5248319,\n  0.36956286,\n  0.46805027,\n  0.45513886,\n  0.45123506,\n  0.4617387],\n [0.45769298,\n  0.44342476,\n  0.46925852,\n  0.44349825,\n  0.28472716,\n  0.4646088,\n  0.35269105,\n  0.5322312,\n  0.5315718,\n  0.48321393,\n  0.45579532,\n  0.44913632,\n  0.41732383,\n  0.46925852,\n  0.2861094,\n  0.4529837,\n  0.36468783,\n  0.31639823,\n  0.4685877,\n  0.466975,\n  0.44913632,\n  0.44651204,\n  0.51881844,\n  0.46872455,\n  0.28676397,\n  0.4646088,\n  0.3468667,\n  0.46937302,\n  0.40241623,\n  0.4599863,\n  0.35612082,\n  0.5322312],\n [0.4779493,\n  0.48903227,\n  0.47851372,\n  0.51884025,\n  0.4556686,\n  0.5154278,\n  0.4845911,\n  0.47166958,\n  0.47856316,\n  0.5156349,\n  0.50042117,\n  0.5147929,\n  0.48318782,\n  0.4956654,\n  0.4936564,\n  0.5042234,\n  0.4776384,\n  0.5112588,\n  0.4564723,\n  0.46847978,\n  0.46336013,\n  0.48024032,\n  0.45656407,\n  0.46768486,\n  0.47887728,\n  0.48342577,\n  0.5162822,\n  0.5115248,\n  0.4780484,\n  0.5063404,\n  0.43872765,\n  0.51141095],\n [0.12690851,\n  0.46829122,\n  0.4819842,\n  0.495933,\n  0.515267,\n  0.5289979,\n  0.4993296,\n  0.46391684,\n  0.41100135,\n  0.51222557,\n  0.4637119,\n  0.51886845,\n  0.5071986,\n  0.489869,\n  0.4764404,\n  0.515267,\n  0.29806387,\n  0.29271603,\n  0.28063264,\n  0.35241097,\n  0.44301778,\n  0.5146883,\n  0.12449172,\n  0.4659228,\n  0.45882225,\n  0.49775523,\n  0.51590055,\n  0.5300032,\n  0.48014918,\n  0.51222557,\n  0.48554072,\n  0.54414934],\n [0.36462188,\n  0.44823283,\n  0.4490298,\n  0.45074496,\n  0.49666363,\n  0.5005512,\n  0.5073102,\n  0.48419157,\n  0.45074826,\n  0.45968062,\n  0.45962018,\n  0.36535636,\n  0.50859,\n  0.45069927,\n  0.49670136,\n  0.45920777,\n  0.4597732,\n  0.45491162,\n  0.48390415,\n  0.44142225,\n  0.3975893,\n  0.5284514,\n  0.45962018,\n  0.43079484,\n  0.44070342,\n  0.45607772,\n  0.44991574,\n  0.4843507,\n  0.44306603,\n  0.4807303,\n  0.44899103,\n  0.46129346],\n [0.44701985,\n  0.5167688,\n  0.16170603,\n  0.430497,\n  0.37627,\n  0.45562637,\n  0.1769763,\n  0.5847049,\n  0.49836415,\n  0.47481892,\n  0.47265565,\n  0.4927645,\n  0.4116139,\n  0.31660873,\n  0.5167688,\n  0.55233747,\n  0.26778203,\n  0.4132535,\n  0.5829918,\n  0.4963426,\n  0.47358334,\n  0.47265565,\n  0.44701985,\n  0.4138511,\n  0.48662952,\n  0.37627,\n  0.46420315,\n  0.18225628,\n  0.42704827,\n  0.5318453,\n  0.4997007,\n  0.5150703],\n [0.50446755,\n  0.4512835,\n  0.49936888,\n  0.44050854,\n  0.3965049,\n  0.46084532,\n  0.44657466,\n  0.46583274,\n  0.4493218,\n  0.45252228,\n  0.46939257,\n  0.44024268,\n  0.41012967,\n  0.4077365,\n  0.41435897,\n  0.36104882,\n  0.3362722,\n  0.44183376,\n  0.4100369,\n  0.3876884,\n  0.44875935,\n  0.4640389,\n  0.46945134,\n  0.5195597,\n  0.45057973,\n  0.38423592,\n  0.4690026,\n  0.502347,\n  0.391341,\n  0.45980826,\n  0.41720864,\n  0.45018852],\n [0.45561317,\n  0.38969392,\n  0.46210125,\n  0.45957935,\n  0.43412125,\n  0.4860674,\n  0.42111552,\n  0.46552408,\n  0.5257393,\n  0.51587373,\n  0.53071034,\n  0.4348243,\n  0.46210125,\n  0.46139503,\n  0.4384538,\n  0.47730014,\n  0.48963997,\n  0.36003685,\n  0.46222174,\n  0.24974889,\n  0.5310517,\n  0.39822024,\n  0.47218674,\n  0.39268562,\n  0.46312377,\n  0.46139503,\n  0.48702648,\n  0.47809443,\n  0.48963997,\n  0.45496354,\n  0.53204185,\n  0.39920473],\n [0.43462762,\n  0.4863681,\n  0.49936894,\n  0.49657255,\n  0.48949847,\n  0.48818788,\n  0.52286464,\n  0.43200374,\n  0.4863681,\n  0.4693049,\n  0.47180077,\n  0.5071376,\n  0.503786,\n  0.48664543,\n  0.48342463,\n  0.5123103,\n  0.49395338,\n  0.50800234,\n  0.47844985,\n  0.43433154,\n  0.48329294,\n  0.4775361,\n  0.44117042,\n  0.49931818,\n  0.4880595,\n  0.49269608,\n  0.5074492,\n  0.48721892,\n  0.5105242,\n  0.47862113,\n  0.49243018,\n  0.49020445],\n [0.48656347,\n  0.46955204,\n  0.46199593,\n  0.45492968,\n  0.42279944,\n  0.3571825,\n  0.47960612,\n  0.45656806,\n  0.47660014,\n  0.46167848,\n  0.40677625,\n  0.39706331,\n  0.46955204,\n  0.4601925,\n  0.13648397,\n  0.45640454,\n  0.46917844,\n  0.45656806,\n  0.52539414,\n  0.45906886,\n  0.40557736,\n  0.5169229,\n  0.4868639,\n  0.46155322,\n  0.44996572,\n  0.44537905,\n  0.3894364,\n  0.42245585,\n  0.52783364,\n  0.40885106,\n  0.45771822,\n  0.47696665],\n [0.46959153,\n  0.46212322,\n  0.42096958,\n  0.42703703,\n  0.49876323,\n  0.4523592,\n  0.46429455,\n  0.43368265,\n  0.41265228,\n  0.47717616,\n  0.42787468,\n  0.5197739,\n  0.47240245,\n  0.528947,\n  0.42922628,\n  0.49960166,\n  0.43117464,\n  0.30878478,\n  0.42787468,\n  0.4428499,\n  0.26228553,\n  0.46185184,\n  0.46033514,\n  0.4344188,\n  0.47410056,\n  0.4661708,\n  0.43104273,\n  0.46934375,\n  0.45257825,\n  0.4696274,\n  0.4678827,\n  0.4435584]]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = res_dict[0][\"test_pred\"]\n",
    "n=32\n",
    "c = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]\n",
    "# pd.DataFrame(c).mean(axis=1)\n",
    "c"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_dict[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = res_dict[0]\n",
    "d\n",
    "# [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_dict[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
